{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ayushs9020/understanding-the-competition-kaggle-llm?scriptVersionId=137730620\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"562e1a8c","metadata":{"papermill":{"duration":0.025377,"end_time":"2023-07-24T10:04:12.849597","exception":false,"start_time":"2023-07-24T10:04:12.82422","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#006600; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #003300\">Who wants to be a Millionare ğŸ«</p>\n","\n","<div style=\"border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","<img src = \"https://m.media-amazon.com/images/M/MV5BZDE3YTNhNzctZjdiNy00YjZjLWE4MDMtOGJjODE2YjE3NDllXkEyXkFqcGdeQXVyODAzNzAwOTU@._V1_.jpg\" width = 300>\n","\n","    \n","The $Kaggle - LLM$ $Science$ $Exam$ is a `competition` that challenges to `answer difficult science-based questions` written by a `Large Language Model` $(LLM)$. The `Goal` of the competition is to help `researchers better understand` the `ability of LLMs` to test themselves, and the `potential of LLMs` that can be run in resource-constrained environments.\n","\n","The `dataset` for the competition was generated by giving `gpt3.5 snippets` of text on a range of `scientific topics pulled` from `Wikipedia`, and asking it to `write a multiple choice question` (with a known answer), then `filtering out easy questions`.\n","\n","`Participants` in the competition are asked to `develop an LLM` that can `answer the questions` in the dataset `as accurately as possible`. The competition is scored using the `average precision` at `cutoff k metric`, where $k$ is the `number of predictions` made for each question.\n","\n","An estimations shays that the `largest models` run on `Kaggle` are around $10$ $Billion$ $Parameters$, whereas `gpt3.5 clocks` in at $175$ $Billion$ $Parameters$. If a `question-answering model can ace` a test written by a `question-writing model` more than $10$ `times its size`, this would be a genuinely `interesting result`; on the `other hand` if a `larger model can effectively` `stump a smaller one`, this has `compelling implications` on the `ability of LLMs` to benchmark and test themselves.\n"]},{"cell_type":"markdown","id":"e2008be9","metadata":{"papermill":{"duration":0.02539,"end_time":"2023-07-24T10:04:12.900351","exception":false,"start_time":"2023-07-24T10:04:12.874961","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#0000FF; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #0000FF\">1 | Advisory ğŸ’¡ </p>\n","\n","<div style=\"border-radius:10px; border:#92DFF3 solid; padding: 15px; background-color: #92DFF#; font-size:100%; text-align:left\">\n","\n","* This is a $Multi-Label$ $Classification$ $Problem$\n","* The evaluation will not be done for $1$ value but rather than multiple values. Think this like `predict`/`predict_poba` methods in the `SKlearn Library`. The `predict` method is used to predict the bestest possible result, whereas `predict_proba` gets the probablities of each class. For this competition we are asked to `predict_proba` for the best $3$ classes"]},{"cell_type":"markdown","id":"18b28ebe","metadata":{"papermill":{"duration":0.025118,"end_time":"2023-07-24T10:04:12.951017","exception":false,"start_time":"2023-07-24T10:04:12.925899","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#FFFF00; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #FFFF00\">2 | Data ğŸ“Š</p>\n","\n","<div style=\"border-radius:10px; border:#FFFE87 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","Now lets dive into the data\n"]},{"cell_type":"code","execution_count":1,"id":"2ee8a82e","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-24T10:04:13.003369Z","iopub.status.busy":"2023-07-24T10:04:13.00244Z","iopub.status.idle":"2023-07-24T10:04:13.014132Z","shell.execute_reply":"2023-07-24T10:04:13.012846Z"},"papermill":{"duration":0.040457,"end_time":"2023-07-24T10:04:13.0168","exception":false,"start_time":"2023-07-24T10:04:12.976343","status":"completed"},"tags":[]},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"markdown","id":"f8a55c82","metadata":{"papermill":{"duration":0.025016,"end_time":"2023-07-24T10:04:13.066888","exception":false,"start_time":"2023-07-24T10:04:13.041872","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FFFE87 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","## 2.1 | Train\n","\n","This is a `csv` file that contains our `main training data` "]},{"cell_type":"code","execution_count":2,"id":"21c5b0aa","metadata":{"_kg_hide-input":false,"execution":{"iopub.execute_input":"2023-07-24T10:04:13.118039Z","iopub.status.busy":"2023-07-24T10:04:13.117627Z","iopub.status.idle":"2023-07-24T10:04:13.165885Z","shell.execute_reply":"2023-07-24T10:04:13.164737Z"},"papermill":{"duration":0.077132,"end_time":"2023-07-24T10:04:13.168652","exception":false,"start_time":"2023-07-24T10:04:13.09152","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>prompt</th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","      <th>D</th>\n","      <th>E</th>\n","      <th>answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Which of the following statements accurately d...</td>\n","      <td>MOND is a theory that reduces the observed mis...</td>\n","      <td>MOND is a theory that increases the discrepanc...</td>\n","      <td>MOND is a theory that explains the missing bar...</td>\n","      <td>MOND is a theory that reduces the discrepancy ...</td>\n","      <td>MOND is a theory that eliminates the observed ...</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Which of the following is an accurate definiti...</td>\n","      <td>Dynamic scaling refers to the evolution of sel...</td>\n","      <td>Dynamic scaling refers to the non-evolution of...</td>\n","      <td>Dynamic scaling refers to the evolution of sel...</td>\n","      <td>Dynamic scaling refers to the non-evolution of...</td>\n","      <td>Dynamic scaling refers to the evolution of sel...</td>\n","      <td>A</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Which of the following statements accurately d...</td>\n","      <td>The triskeles symbol was reconstructed as a fe...</td>\n","      <td>The triskeles symbol is a representation of th...</td>\n","      <td>The triskeles symbol is a representation of a ...</td>\n","      <td>The triskeles symbol represents three interloc...</td>\n","      <td>The triskeles symbol is a representation of th...</td>\n","      <td>A</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>What is the significance of regularization in ...</td>\n","      <td>Regularizing the mass-energy of an electron wi...</td>\n","      <td>Regularizing the mass-energy of an electron wi...</td>\n","      <td>Regularizing the mass-energy of an electron wi...</td>\n","      <td>Regularizing the mass-energy of an electron wi...</td>\n","      <td>Regularizing the mass-energy of an electron wi...</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Which of the following statements accurately d...</td>\n","      <td>The angular spacing of features in the diffrac...</td>\n","      <td>The angular spacing of features in the diffrac...</td>\n","      <td>The angular spacing of features in the diffrac...</td>\n","      <td>The angular spacing of features in the diffrac...</td>\n","      <td>The angular spacing of features in the diffrac...</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>195</td>\n","      <td>What is the relation between the three moment ...</td>\n","      <td>The three moment theorem expresses the relatio...</td>\n","      <td>The three moment theorem is used to calculate ...</td>\n","      <td>The three moment theorem describes the relatio...</td>\n","      <td>The three moment theorem is used to calculate ...</td>\n","      <td>The three moment theorem is used to derive the...</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>196</td>\n","      <td>What is the throttling process, and why is it ...</td>\n","      <td>The throttling process is a steady flow of a f...</td>\n","      <td>The throttling process is a steady adiabatic f...</td>\n","      <td>The throttling process is a steady adiabatic f...</td>\n","      <td>The throttling process is a steady flow of a f...</td>\n","      <td>The throttling process is a steady adiabatic f...</td>\n","      <td>B</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>197</td>\n","      <td>What happens to excess base metal as a solutio...</td>\n","      <td>The excess base metal will often solidify, bec...</td>\n","      <td>The excess base metal will often crystallize-o...</td>\n","      <td>The excess base metal will often dissolve, bec...</td>\n","      <td>The excess base metal will often liquefy, beco...</td>\n","      <td>The excess base metal will often evaporate, be...</td>\n","      <td>B</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>198</td>\n","      <td>What is the relationship between mass, force, ...</td>\n","      <td>Mass is a property that determines the weight ...</td>\n","      <td>Mass is an inertial property that determines a...</td>\n","      <td>Mass is an inertial property that determines a...</td>\n","      <td>Mass is an inertial property that determines a...</td>\n","      <td>Mass is a property that determines the size of...</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>199</td>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>C</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>200 rows Ã— 8 columns</p>\n","</div>"],"text/plain":["      id                                             prompt  \\\n","0      0  Which of the following statements accurately d...   \n","1      1  Which of the following is an accurate definiti...   \n","2      2  Which of the following statements accurately d...   \n","3      3  What is the significance of regularization in ...   \n","4      4  Which of the following statements accurately d...   \n","..   ...                                                ...   \n","195  195  What is the relation between the three moment ...   \n","196  196  What is the throttling process, and why is it ...   \n","197  197  What happens to excess base metal as a solutio...   \n","198  198  What is the relationship between mass, force, ...   \n","199  199  What did Arthur Eddington discover about two o...   \n","\n","                                                     A  \\\n","0    MOND is a theory that reduces the observed mis...   \n","1    Dynamic scaling refers to the evolution of sel...   \n","2    The triskeles symbol was reconstructed as a fe...   \n","3    Regularizing the mass-energy of an electron wi...   \n","4    The angular spacing of features in the diffrac...   \n","..                                                 ...   \n","195  The three moment theorem expresses the relatio...   \n","196  The throttling process is a steady flow of a f...   \n","197  The excess base metal will often solidify, bec...   \n","198  Mass is a property that determines the weight ...   \n","199  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                     B  \\\n","0    MOND is a theory that increases the discrepanc...   \n","1    Dynamic scaling refers to the non-evolution of...   \n","2    The triskeles symbol is a representation of th...   \n","3    Regularizing the mass-energy of an electron wi...   \n","4    The angular spacing of features in the diffrac...   \n","..                                                 ...   \n","195  The three moment theorem is used to calculate ...   \n","196  The throttling process is a steady adiabatic f...   \n","197  The excess base metal will often crystallize-o...   \n","198  Mass is an inertial property that determines a...   \n","199  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                     C  \\\n","0    MOND is a theory that explains the missing bar...   \n","1    Dynamic scaling refers to the evolution of sel...   \n","2    The triskeles symbol is a representation of a ...   \n","3    Regularizing the mass-energy of an electron wi...   \n","4    The angular spacing of features in the diffrac...   \n","..                                                 ...   \n","195  The three moment theorem describes the relatio...   \n","196  The throttling process is a steady adiabatic f...   \n","197  The excess base metal will often dissolve, bec...   \n","198  Mass is an inertial property that determines a...   \n","199  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                     D  \\\n","0    MOND is a theory that reduces the discrepancy ...   \n","1    Dynamic scaling refers to the non-evolution of...   \n","2    The triskeles symbol represents three interloc...   \n","3    Regularizing the mass-energy of an electron wi...   \n","4    The angular spacing of features in the diffrac...   \n","..                                                 ...   \n","195  The three moment theorem is used to calculate ...   \n","196  The throttling process is a steady flow of a f...   \n","197  The excess base metal will often liquefy, beco...   \n","198  Mass is an inertial property that determines a...   \n","199  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                     E answer  \n","0    MOND is a theory that eliminates the observed ...      D  \n","1    Dynamic scaling refers to the evolution of sel...      A  \n","2    The triskeles symbol is a representation of th...      A  \n","3    Regularizing the mass-energy of an electron wi...      C  \n","4    The angular spacing of features in the diffrac...      D  \n","..                                                 ...    ...  \n","195  The three moment theorem is used to derive the...      C  \n","196  The throttling process is a steady adiabatic f...      B  \n","197  The excess base metal will often evaporate, be...      B  \n","198  Mass is a property that determines the size of...      D  \n","199  Arthur Eddington showed that two of Einstein's...      C  \n","\n","[200 rows x 8 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["train = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/train.csv\")\n","train"]},{"cell_type":"markdown","id":"5e98bbfe","metadata":{"papermill":{"duration":0.025745,"end_time":"2023-07-24T10:04:13.21994","exception":false,"start_time":"2023-07-24T10:04:13.194195","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FFFE87 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","## 2.2 | Test \n","\n","This is the testing dataset "]},{"cell_type":"code","execution_count":3,"id":"f8b4d7aa","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"execution":{"iopub.execute_input":"2023-07-24T10:04:13.273347Z","iopub.status.busy":"2023-07-24T10:04:13.272869Z","iopub.status.idle":"2023-07-24T10:04:13.303113Z","shell.execute_reply":"2023-07-24T10:04:13.301722Z"},"papermill":{"duration":0.060489,"end_time":"2023-07-24T10:04:13.306102","exception":false,"start_time":"2023-07-24T10:04:13.245613","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>prompt</th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","      <th>D</th>\n","      <th>E</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Which of the following statements accurately d...</td>\n","      <td>MOND is a theory that reduces the observed mis...</td>\n","      <td>MOND is a theory that increases the discrepanc...</td>\n","      <td>MOND is a theory that explains the missing bar...</td>\n","      <td>MOND is a theory that reduces the discrepancy ...</td>\n","      <td>MOND is a theory that eliminates the observed ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Which of the following is an accurate definiti...</td>\n","      <td>Dynamic scaling refers to the evolution of sel...</td>\n","      <td>Dynamic scaling refers to the non-evolution of...</td>\n","      <td>Dynamic scaling refers to the evolution of sel...</td>\n","      <td>Dynamic scaling refers to the non-evolution of...</td>\n","      <td>Dynamic scaling refers to the evolution of sel...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Which of the following statements accurately d...</td>\n","      <td>The triskeles symbol was reconstructed as a fe...</td>\n","      <td>The triskeles symbol is a representation of th...</td>\n","      <td>The triskeles symbol is a representation of a ...</td>\n","      <td>The triskeles symbol represents three interloc...</td>\n","      <td>The triskeles symbol is a representation of th...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>What is the significance of regularization in ...</td>\n","      <td>Regularizing the mass-energy of an electron wi...</td>\n","      <td>Regularizing the mass-energy of an electron wi...</td>\n","      <td>Regularizing the mass-energy of an electron wi...</td>\n","      <td>Regularizing the mass-energy of an electron wi...</td>\n","      <td>Regularizing the mass-energy of an electron wi...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Which of the following statements accurately d...</td>\n","      <td>The angular spacing of features in the diffrac...</td>\n","      <td>The angular spacing of features in the diffrac...</td>\n","      <td>The angular spacing of features in the diffrac...</td>\n","      <td>The angular spacing of features in the diffrac...</td>\n","      <td>The angular spacing of features in the diffrac...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>195</td>\n","      <td>What is the relation between the three moment ...</td>\n","      <td>The three moment theorem expresses the relatio...</td>\n","      <td>The three moment theorem is used to calculate ...</td>\n","      <td>The three moment theorem describes the relatio...</td>\n","      <td>The three moment theorem is used to calculate ...</td>\n","      <td>The three moment theorem is used to derive the...</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>196</td>\n","      <td>What is the throttling process, and why is it ...</td>\n","      <td>The throttling process is a steady flow of a f...</td>\n","      <td>The throttling process is a steady adiabatic f...</td>\n","      <td>The throttling process is a steady adiabatic f...</td>\n","      <td>The throttling process is a steady flow of a f...</td>\n","      <td>The throttling process is a steady adiabatic f...</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>197</td>\n","      <td>What happens to excess base metal as a solutio...</td>\n","      <td>The excess base metal will often solidify, bec...</td>\n","      <td>The excess base metal will often crystallize-o...</td>\n","      <td>The excess base metal will often dissolve, bec...</td>\n","      <td>The excess base metal will often liquefy, beco...</td>\n","      <td>The excess base metal will often evaporate, be...</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>198</td>\n","      <td>What is the relationship between mass, force, ...</td>\n","      <td>Mass is a property that determines the weight ...</td>\n","      <td>Mass is an inertial property that determines a...</td>\n","      <td>Mass is an inertial property that determines a...</td>\n","      <td>Mass is an inertial property that determines a...</td>\n","      <td>Mass is a property that determines the size of...</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>199</td>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>200 rows Ã— 7 columns</p>\n","</div>"],"text/plain":["      id                                             prompt  \\\n","0      0  Which of the following statements accurately d...   \n","1      1  Which of the following is an accurate definiti...   \n","2      2  Which of the following statements accurately d...   \n","3      3  What is the significance of regularization in ...   \n","4      4  Which of the following statements accurately d...   \n","..   ...                                                ...   \n","195  195  What is the relation between the three moment ...   \n","196  196  What is the throttling process, and why is it ...   \n","197  197  What happens to excess base metal as a solutio...   \n","198  198  What is the relationship between mass, force, ...   \n","199  199  What did Arthur Eddington discover about two o...   \n","\n","                                                     A  \\\n","0    MOND is a theory that reduces the observed mis...   \n","1    Dynamic scaling refers to the evolution of sel...   \n","2    The triskeles symbol was reconstructed as a fe...   \n","3    Regularizing the mass-energy of an electron wi...   \n","4    The angular spacing of features in the diffrac...   \n","..                                                 ...   \n","195  The three moment theorem expresses the relatio...   \n","196  The throttling process is a steady flow of a f...   \n","197  The excess base metal will often solidify, bec...   \n","198  Mass is a property that determines the weight ...   \n","199  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                     B  \\\n","0    MOND is a theory that increases the discrepanc...   \n","1    Dynamic scaling refers to the non-evolution of...   \n","2    The triskeles symbol is a representation of th...   \n","3    Regularizing the mass-energy of an electron wi...   \n","4    The angular spacing of features in the diffrac...   \n","..                                                 ...   \n","195  The three moment theorem is used to calculate ...   \n","196  The throttling process is a steady adiabatic f...   \n","197  The excess base metal will often crystallize-o...   \n","198  Mass is an inertial property that determines a...   \n","199  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                     C  \\\n","0    MOND is a theory that explains the missing bar...   \n","1    Dynamic scaling refers to the evolution of sel...   \n","2    The triskeles symbol is a representation of a ...   \n","3    Regularizing the mass-energy of an electron wi...   \n","4    The angular spacing of features in the diffrac...   \n","..                                                 ...   \n","195  The three moment theorem describes the relatio...   \n","196  The throttling process is a steady adiabatic f...   \n","197  The excess base metal will often dissolve, bec...   \n","198  Mass is an inertial property that determines a...   \n","199  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                     D  \\\n","0    MOND is a theory that reduces the discrepancy ...   \n","1    Dynamic scaling refers to the non-evolution of...   \n","2    The triskeles symbol represents three interloc...   \n","3    Regularizing the mass-energy of an electron wi...   \n","4    The angular spacing of features in the diffrac...   \n","..                                                 ...   \n","195  The three moment theorem is used to calculate ...   \n","196  The throttling process is a steady flow of a f...   \n","197  The excess base metal will often liquefy, beco...   \n","198  Mass is an inertial property that determines a...   \n","199  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                     E  \n","0    MOND is a theory that eliminates the observed ...  \n","1    Dynamic scaling refers to the evolution of sel...  \n","2    The triskeles symbol is a representation of th...  \n","3    Regularizing the mass-energy of an electron wi...  \n","4    The angular spacing of features in the diffrac...  \n","..                                                 ...  \n","195  The three moment theorem is used to derive the...  \n","196  The throttling process is a steady adiabatic f...  \n","197  The excess base metal will often evaporate, be...  \n","198  Mass is a property that determines the size of...  \n","199  Arthur Eddington showed that two of Einstein's...  \n","\n","[200 rows x 7 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["test = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/test.csv\")\n","test"]},{"cell_type":"markdown","id":"b16bb6a1","metadata":{"papermill":{"duration":0.026163,"end_time":"2023-07-24T10:04:13.359159","exception":false,"start_time":"2023-07-24T10:04:13.332996","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#ff0000; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #ff0000\">3 | Tokenizers ğŸ’»</p>\n","\n","<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","\n","Now we will use different types of tokenizers for different types of results\n","\n","* $BERT-Tokenizer$\n","* $Flan$ $T5$\n","* $Falcon$ $7B$\n","* $RoBERTa$\n","* $DeBERTa$\n","* $AlBERT$\n","* $ELECTRA$\n","* $RoBERTa$"]},{"cell_type":"code","execution_count":4,"id":"8a6fe1a1","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-24T10:04:13.414633Z","iopub.status.busy":"2023-07-24T10:04:13.413894Z","iopub.status.idle":"2023-07-24T10:04:19.56561Z","shell.execute_reply":"2023-07-24T10:04:19.564481Z"},"papermill":{"duration":6.183158,"end_time":"2023-07-24T10:04:19.568897","exception":false,"start_time":"2023-07-24T10:04:13.385739","status":"completed"},"tags":[]},"outputs":[],"source":["import numpy as np\n","from string import Template\n","import tqdm\n","import torch\n","import os\n","\n","import sentencepiece \n","from transformers import AutoTokenizer , AutoModel"]},{"cell_type":"markdown","id":"fadbeff0","metadata":{"papermill":{"duration":0.026685,"end_time":"2023-07-24T10:04:19.622595","exception":false,"start_time":"2023-07-24T10:04:19.59591","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","\n","## $3.1$ $|$ $BERT-Tokenizer$\n","\n","<img src = \"https://datajenius.com/wp-content/uploads/2022/03/Screen-Shot-2022-03-13-at-12.24.34-PM-768x497.png\" width = 400>\n","\n","The $BERT$ $Tokenizer$ is a `pre-trained` `tokenizer` that is specifically `designed` for the `BERT Model`. It is a $Byte-Pair$ $Encoding$ $(BPE)$ $Tokenizer$, which means that it `breaks down text` into `tokens` by `iteratively merging pairs` of the `most frequent characters`. This allows the tokenizer to `learn a vocabulary of subwords`, which can be `more efficient` for `representing text` than a vocabulary of full words. Assume a word `mousing`. A normal tokenizer would tokenize this as whole, but this one will rather split it into `mous`/`ing`, which captures more information for new words which are actually unknown to vocublary \n","\n","The $Huggingface-Bert$/$Bert-Base-Cased$ $Tokenizer$ also includes a number of `special tokens` that are `used by the BERT model`. These tokens include the `[CLS]` token, which is used to `represent the beginning` of a sentence, the `[SEP]` token, which is used to `represent the end of a sentence`, and the `[MASK]` token, which is used to `represent a masked token`.\n","\n","<img src = \"https://blogger.googleusercontent.com/img/a/AVvXsEi-pFW9FPFJ7p2Sspv8tCZrtnr3TSv2UAcxi780EhpVik9Q2m87tFHj4pppKOq7ZvrvywRhSB8yE2Sq9TzF3EwlWZ8byqlWgs_atSE3Wlw2tOLkUS4z0dlDBubktjzQB0XX359tJBj9IG3tHnD9_LLHUkaUU47b6GEgu0qTxP5f94TvAerpZ3Y2zxqF_g=w640-h414\" width = 400>"]},{"cell_type":"code","execution_count":5,"id":"56d9b472","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-24T10:04:19.682004Z","iopub.status.busy":"2023-07-24T10:04:19.680252Z","iopub.status.idle":"2023-07-24T10:04:23.373497Z","shell.execute_reply":"2023-07-24T10:04:23.372502Z"},"papermill":{"duration":3.724837,"end_time":"2023-07-24T10:04:23.376353","exception":false,"start_time":"2023-07-24T10:04:19.651516","status":"completed"},"tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"40a0f41c6eeb40cdaf5233207ccf1c5c","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b798ceca05004e91913273b8df3956e3","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2248f9f9491946a79acaaa2a840ca0c8","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5bcf316e43894e93bd2010d24fb6108f","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"]},{"cell_type":"code","execution_count":6,"id":"6167a0fa","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-24T10:04:23.435034Z","iopub.status.busy":"2023-07-24T10:04:23.434139Z","iopub.status.idle":"2023-07-24T10:04:41.430292Z","shell.execute_reply":"2023-07-24T10:04:41.429253Z"},"papermill":{"duration":18.028537,"end_time":"2023-07-24T10:04:41.432977","exception":false,"start_time":"2023-07-24T10:04:23.40444","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c41102a366584b188d6c684766876b88","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["bert_based = AutoModel.from_pretrained(\"bert-base-cased\")"]},{"cell_type":"markdown","id":"869dd573","metadata":{"papermill":{"duration":0.027362,"end_time":"2023-07-24T10:04:41.487922","exception":false,"start_time":"2023-07-24T10:04:41.46056","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Lets assume we have this sample text\n","\n","```\n","Everybody Is A Gangster , Till You See The Monster\n","```"]},{"cell_type":"code","execution_count":7,"id":"db5141c4","metadata":{"execution":{"iopub.execute_input":"2023-07-24T10:04:41.54602Z","iopub.status.busy":"2023-07-24T10:04:41.544984Z","iopub.status.idle":"2023-07-24T10:04:41.560643Z","shell.execute_reply":"2023-07-24T10:04:41.559604Z"},"papermill":{"duration":0.048006,"end_time":"2023-07-24T10:04:41.563656","exception":false,"start_time":"2023-07-24T10:04:41.51565","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["{'input_ids': tensor([[  101, 14325,  2181,   138, 12469,  4648,   117, 22430,  1192,  3969,\n","          1109, 11701,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["bert_tokens = bert_tokenizer(\"Everybody Is A Gangster, Till You See The Monster\" , return_tensors = \"pt\")\n","bert_tokens"]},{"cell_type":"markdown","id":"cbbba65d","metadata":{"papermill":{"duration":0.027476,"end_time":"2023-07-24T10:04:41.621049","exception":false,"start_time":"2023-07-24T10:04:41.593573","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","\n","This will give error \n","\n","```\n","In [1]: model(tokens)\n","\n","Out [1]: \n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Traceback (most recent call last) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n","â”‚ /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:254 in           â”‚\n","â”‚ __getattr__                                                                                      â”‚\n","â”‚                                                                                                  â”‚\n","â”‚    251 â”‚                                                                                         â”‚\n","â”‚    252 â”‚   def __getattr__(self, item: str):                                                     â”‚\n","â”‚    253 â”‚   â”‚   try:                                                                              â”‚\n","â”‚ â±  254 â”‚   â”‚   â”‚   return self.data[item]                                                        â”‚\n","â”‚    255 â”‚   â”‚   except KeyError:                                                                  â”‚\n","â”‚    256 â”‚   â”‚   â”‚   raise AttributeError                                                          â”‚\n","â”‚    257                                                                                           â”‚\n","â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n","KeyError: 'size'\n","\n","During handling of the above exception, another exception occurred:\n","\n","â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Traceback (most recent call last) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n","â”‚ in <module>:1                                                                                    â”‚\n","â”‚                                                                                                  â”‚\n","â”‚ â± 1 model(tokens)                                                                                â”‚\n","â”‚   2                                                                                              â”‚\n","â”‚                                                                                                  â”‚\n","â”‚ /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501 in _call_impl            â”‚\n","â”‚                                                                                                  â”‚\n","â”‚   1498 â”‚   â”‚   if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks   â”‚\n","â”‚   1499 â”‚   â”‚   â”‚   â”‚   or _global_backward_pre_hooks or _global_backward_hooks                   â”‚\n","â”‚   1500 â”‚   â”‚   â”‚   â”‚   or _global_forward_hooks or _global_forward_pre_hooks):                   â”‚\n","â”‚ â± 1501 â”‚   â”‚   â”‚   return forward_call(*args, **kwargs)                                          â”‚\n","â”‚   1502 â”‚   â”‚   # Do not call functions when jit is used                                          â”‚\n","â”‚   1503 â”‚   â”‚   full_backward_hooks, non_full_backward_hooks = [], []                             â”‚\n","â”‚   1504 â”‚   â”‚   backward_pre_hooks = []                                                           â”‚\n","â”‚                                                                                                  â”‚\n","â”‚ /opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:968 in forward â”‚\n","â”‚                                                                                                  â”‚\n","â”‚    965 â”‚   â”‚   if input_ids is not None and inputs_embeds is not None:                           â”‚\n","â”‚    966 â”‚   â”‚   â”‚   raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the  â”‚\n","â”‚    967 â”‚   â”‚   elif input_ids is not None:                                                       â”‚\n","â”‚ â±  968 â”‚   â”‚   â”‚   input_shape = input_ids.size()                                                â”‚\n","â”‚    969 â”‚   â”‚   elif inputs_embeds is not None:                                                   â”‚\n","â”‚    970 â”‚   â”‚   â”‚   input_shape = inputs_embeds.size()[:-1]                                       â”‚\n","â”‚    971 â”‚   â”‚   else:                                                                             â”‚\n","â”‚                                                                                                  â”‚\n","â”‚ /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:256 in           â”‚\n","â”‚ __getattr__                                                                                      â”‚\n","â”‚                                                                                                  â”‚\n","â”‚    253 â”‚   â”‚   try:                                                                              â”‚\n","â”‚    254 â”‚   â”‚   â”‚   return self.data[item]                                                        â”‚\n","â”‚    255 â”‚   â”‚   except KeyError:                                                                  â”‚\n","â”‚ â±  256 â”‚   â”‚   â”‚   raise AttributeError                                                          â”‚\n","â”‚    257 â”‚                                                                                         â”‚\n","â”‚    258 â”‚   def __getstate__(self):                                                               â”‚\n","â”‚    259 â”‚   â”‚   return {\"data\": self.data, \"encodings\": self._encodings}                          â”‚\n","â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n","AttributeError\n","```"]},{"cell_type":"code","execution_count":8,"id":"01983efb","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-24T10:04:41.679274Z","iopub.status.busy":"2023-07-24T10:04:41.678415Z","iopub.status.idle":"2023-07-24T10:04:41.880852Z","shell.execute_reply":"2023-07-24T10:04:41.879898Z"},"papermill":{"duration":0.234303,"end_time":"2023-07-24T10:04:41.883576","exception":false,"start_time":"2023-07-24T10:04:41.649273","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.2735,  0.1281, -0.1138,  ...,  0.0849,  0.2736, -0.1576],\n","         [-0.8027,  0.4616,  0.1243,  ...,  0.5486, -0.0444, -0.1121],\n","         [-0.1207,  0.2429,  0.4388,  ...,  0.2734,  0.1653, -0.2329],\n","         ...,\n","         [-0.3941, -0.0716, -0.0864,  ...,  0.6747,  0.0764,  0.1317],\n","         [ 0.3185, -0.4049, -0.0438,  ...,  0.0533, -0.1618, -0.1742],\n","         [ 0.0257,  0.7954, -0.0842,  ...,  0.5175,  0.1617, -0.4017]]],\n","       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.6699,  0.5028,  0.9999, -0.9948,  0.9714,  0.8739,  0.9832, -0.9809,\n","         -0.9826, -0.7324,  0.9875,  0.9987, -0.9968, -0.9999,  0.7018, -0.9832,\n","          0.9917, -0.6042, -1.0000, -0.6883, -0.5744, -0.9999,  0.3807,  0.9633,\n","          0.9813,  0.0957,  0.9900,  1.0000,  0.8789,  0.1188,  0.3033, -0.9924,\n","          0.8438, -0.9994,  0.1987,  0.0854,  0.7423, -0.3160,  0.7678, -0.9025,\n","         -0.7755, -0.7057,  0.5877, -0.6446,  0.8924,  0.4262,  0.0838, -0.0662,\n","         -0.1451,  0.9999, -0.9689,  0.9996, -0.9900,  0.9979,  0.9950,  0.5297,\n","          0.9959,  0.2058, -0.9975,  0.2430,  0.9809,  0.1430,  0.9369, -0.3443,\n","          0.2940, -0.5631, -0.8667,  0.2162, -0.5525,  0.4538,  0.3700,  0.4022,\n","          0.9820, -0.9108, -0.0914, -0.9402,  0.0283, -0.9999,  0.9677,  1.0000,\n","          0.5662, -0.9998,  0.9933, -0.3545, -0.7318,  0.5584, -0.9986, -0.9996,\n","          0.1658, -0.7105,  0.8348, -0.9905,  0.6289, -0.8622,  1.0000, -0.8619,\n","         -0.2121,  0.4787,  0.9009, -0.4666, -0.7712,  0.8859,  0.9982, -0.9929,\n","          0.9976,  0.5782, -0.9641, -0.7251,  0.5751,  0.1098,  0.9916, -0.9929,\n","         -0.7277,  0.0907,  0.9331, -0.8344,  0.9920,  0.7533, -0.3512,  1.0000,\n","         -0.1007,  0.9597,  0.9982,  0.8126, -0.6515, -0.3076, -0.5790,  0.8247,\n","         -0.4915, -0.5100,  0.8489, -0.9914, -0.9969,  0.9996, -0.3149,  1.0000,\n","         -0.9994,  0.9856, -1.0000, -0.7033, -0.7730, -0.0035, -0.9809,  0.1917,\n","          0.9933,  0.0306, -0.8379, -0.6048,  0.5700, -0.7235,  0.6324,  0.7289,\n","         -0.9649,  0.9988,  0.9949,  0.9383,  0.9717,  0.2672, -0.9345,  0.7857,\n","          0.9918, -0.9996,  0.8066, -0.9909,  0.9996,  0.9691,  0.7817, -0.9909,\n","          0.9999, -0.5817, -0.0174,  0.2415, -0.2864, -0.9984,  0.4720,  0.5329,\n","          0.8475,  0.9998, -0.9925,  0.9999,  0.9810,  0.0583,  0.8311,  0.9970,\n","         -0.9960, -0.9789, -0.9895,  0.4478,  0.7138,  0.6156,  0.4082,  0.9710,\n","          0.9985,  0.7371, -0.9989, -0.4940,  0.9805, -0.2081,  1.0000, -0.3483,\n","         -0.9999, -0.7991,  0.9285,  0.9565, -0.3891,  0.9826, -0.6456, -0.1349,\n","          0.9604, -0.9992,  0.9969,  0.0421,  0.7280,  0.8849,  0.9937, -0.6676,\n","         -0.0930,  0.2270, -0.5829,  0.9999, -0.9997, -0.2670,  0.5915, -0.9961,\n","         -0.9983,  0.9765, -0.0297, -0.6817, -0.3317,  0.2362,  0.2313,  0.8626,\n","          0.9923, -0.4284, -0.2798, -0.9999, -0.9960, -0.9029, -0.9437,  0.1251,\n","          0.6860, -0.4344, -0.9567, -0.9977,  0.9678,  0.4823, -0.8405, -0.1436,\n","         -0.6451, -0.9983,  0.5951, -0.8121, -0.9994,  0.9997, -0.6956,  0.9928,\n","          0.9550, -0.9963,  0.6998, -0.9982, -0.0532, -0.9991,  0.2546,  0.4842,\n","         -0.6522, -0.0682,  0.9918, -0.9812, -0.5844,  0.6982, -0.9999,  0.9374,\n","         -0.2794,  0.9993,  0.8400, -0.1496,  0.9855,  0.8669, -0.9897, -0.9999,\n","          0.9133,  0.9939, -0.9935, -0.2537,  0.9999, -0.9971, -0.8618, -0.9581,\n","         -0.9954, -0.9998,  0.1657, -0.7003,  0.1147,  0.9858,  0.3002,  0.0937,\n","          0.9951,  0.9970,  0.2314, -0.1661,  0.0370, -0.9738, -0.9956,  0.6973,\n","          0.2504, -1.0000,  0.9999, -0.9959,  0.9991,  0.9478, -0.9907,  0.8448,\n","          0.1060, -0.9514,  0.0029,  0.9999,  0.9822, -0.1448,  0.2479,  0.8438,\n","         -0.0821,  0.6032, -0.8357, -0.5778,  0.2124, -0.9505,  0.9896,  0.4027,\n","         -0.9926,  0.9927,  0.1012,  0.8213, -0.6819,  0.9300,  0.9924, -0.1039,\n","         -0.2344, -0.2117, -0.8225, -0.9559,  0.2363, -0.9945, -0.2186,  0.9600,\n","          0.9819, -0.9820,  0.9973, -0.1920,  0.8318, -0.9978,  1.0000, -0.9981,\n","          0.2331,  0.6933, -0.8482, -0.0989,  0.9939,  0.9708,  0.9262, -0.8305,\n","         -0.7206,  0.8707,  0.9709, -0.9731,  0.0633, -0.9991, -0.7058,  0.9973,\n","          0.9960, -0.1637, -0.3845, -0.9961,  0.9817, -0.7939, -0.7034, -0.1619,\n","         -0.6804,  0.6244,  0.9966, -0.4999,  0.6314,  0.1942, -0.9885,  0.8142,\n","          0.7396,  0.9999, -0.9803,  0.4851,  0.9846, -0.1823, -0.7309,  0.6522,\n","          0.9981, -0.9581, -0.2894, -0.9997,  0.0654, -0.6223, -0.2845, -0.5972,\n","          0.1343, -0.7450,  0.9596, -0.1744,  0.8803, -0.2589,  0.9842,  0.0612,\n","         -0.0873, -0.3444, -0.1115,  0.5010,  0.1153,  0.9861, -0.9741,  0.9999,\n","         -0.5164, -1.0000, -0.9965, -0.7295, -0.9999,  0.6530, -0.9977,  0.9881,\n","          0.9007, -0.9976, -0.9984, -0.9986, -0.9989,  0.7782,  0.5991, -0.0454,\n","          0.4912,  0.8051,  0.1097, -0.2010, -0.1169, -0.9540, -0.4040, -0.9975,\n","          0.8562, -1.0000, -0.7682,  0.9962, -0.9940, -0.9507, -0.9247, -0.5807,\n","         -0.8426,  0.4738,  0.9896, -0.2614, -0.6616, -0.9998,  0.9915, -0.7826,\n","          0.2890, -0.7666, -0.9830,  0.9998,  0.7183, -0.1239, -0.2019, -0.9995,\n","          0.9856, -0.9030, -0.8164, -0.9837,  0.2130, -0.9469, -0.9999,  0.0491,\n","          0.9959,  0.9975,  0.9888,  0.5267, -0.4001, -0.9653,  0.1936, -1.0000,\n","          0.8195,  0.7927, -0.9885, -0.7439,  0.9962,  0.9784, -0.8989, -0.9752,\n","          0.9151,  0.3595,  0.9844, -0.5111, -0.6066,  0.4272, -0.1331, -0.9930,\n","         -0.9513,  0.9967, -0.9986,  0.9881,  0.9953,  0.9980, -0.0710,  0.0317,\n","         -0.9831, -0.9981, -0.7087,  0.3067, -1.0000,  1.0000, -1.0000,  0.4986,\n","         -0.6105,  0.7990,  0.9929, -0.2361, -0.9999, -0.9999,  0.7497,  0.0512,\n","          0.9921,  0.1697,  0.3664, -0.4416, -0.2603,  0.9976, -0.9251, -0.7105,\n","         -0.9975,  0.9998,  0.6256, -0.9981,  0.9908, -0.9997,  0.7732,  0.9760,\n","          0.8877,  0.9818, -0.9985,  1.0000, -0.9999,  0.9986, -1.0000, -0.9986,\n","          0.9999, -0.9946, -0.5827, -0.9998, -0.9960,  0.5632,  0.2342, -0.6996,\n","          0.9885, -0.9999, -0.9986, -0.3125, -0.8784, -0.7980,  0.9931, -0.6774,\n","          0.9902, -0.0731,  0.9720,  0.1194,  0.9932,  0.9990, -0.6134, -0.7614,\n","         -0.9926,  0.9935, -0.6236,  0.3589,  0.9724,  0.0525, -0.6318,  0.4834,\n","         -0.9975,  0.5276, -0.6216,  0.8559,  0.8980,  0.8917,  0.0273, -0.4204,\n","         -0.1875, -0.9936,  0.5744, -0.9997,  0.9889, -0.9207,  0.0759, -0.4761,\n","          0.3446, -0.9643,  0.9998,  0.9987, -0.9996,  0.1494,  0.9892, -0.7341,\n","          0.9769, -0.9948, -0.1076,  0.9243, -0.7469,  0.9865,  0.2290, -0.0814,\n","          0.9879, -0.9959, -0.8737, -0.7060,  0.3187,  0.2780, -0.9660,  0.1076,\n","          0.9786, -0.4332, -0.9998,  0.8984, -0.9995, -0.2041,  0.9780, -0.4894,\n","          0.9999, -0.7913,  0.0882,  0.0554, -0.9998, -0.9984,  0.0854, -0.2006,\n","         -0.9306,  0.9988, -0.1604,  0.7749, -1.0000,  0.3300,  0.9948,  0.4142,\n","          0.8637, -0.8061, -0.9797, -0.8951, -0.7738,  0.0460,  0.7477, -0.9580,\n","         -0.8511, -0.8084,  1.0000, -0.9981, -0.9453, -0.9958,  0.6498,  0.7814,\n","          0.4464,  0.1238, -0.7998,  0.8657, -0.7964,  0.9976, -0.9932, -0.9962,\n","          0.9998,  0.4622, -0.9844,  0.0710, -0.4317,  0.2756,  0.0274,  0.5799,\n","         -0.8206, -0.2361, -0.9989,  0.8973, -0.7222, -0.9938, -0.7112, -0.3886,\n","         -0.9994,  0.9945,  0.9748,  1.0000, -0.9998,  0.9012,  0.1238,  0.9993,\n","          0.0634, -0.7182,  0.8286,  0.9998, -0.6699,  0.7832, -0.0027, -0.0735,\n","          0.2282, -0.4106,  0.9938, -0.9052,  0.1483, -0.9796, -1.0000,  1.0000,\n","         -0.1364,  0.9920,  0.3017,  0.7858, -0.9035,  0.9704, -0.9798, -0.9438,\n","         -1.0000,  0.2103, -0.9996, -0.9906,  0.1314,  0.9851, -0.9997, -0.9948,\n","         -0.3258, -1.0000,  0.8484, -0.9837, -0.8026, -0.9903,  0.9975, -0.4000,\n","         -0.4903,  0.9848, -0.9760,  0.9146,  0.9438,  0.5095,  0.2630,  0.1948,\n","         -0.7295, -0.9912, -0.9282, -0.9777,  0.8938, -0.9868, -0.8136,  0.9973,\n","          0.9895, -0.9996, -0.9966,  0.9939,  0.0561,  0.9915, -0.5779, -0.9999,\n","         -0.9999,  0.1651, -0.1355,  0.9944, -0.5023,  0.9984,  0.8673, -0.2307,\n","          0.4285, -0.5978, -0.2297, -0.3522, -0.3453,  1.0000, -0.6037,  0.9894]],\n","       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["bert_based(bert_tokens[\"input_ids\"])"]},{"cell_type":"markdown","id":"c36f5c05","metadata":{"papermill":{"duration":0.029734,"end_time":"2023-07-24T10:04:41.942097","exception":false,"start_time":"2023-07-24T10:04:41.912363","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Lets make a simple function for iterating over our data "]},{"cell_type":"code","execution_count":9,"id":"91b05005","metadata":{"execution":{"iopub.execute_input":"2023-07-24T10:04:42.002699Z","iopub.status.busy":"2023-07-24T10:04:42.001564Z","iopub.status.idle":"2023-07-24T10:04:42.008539Z","shell.execute_reply":"2023-07-24T10:04:42.007489Z"},"papermill":{"duration":0.040124,"end_time":"2023-07-24T10:04:42.011446","exception":false,"start_time":"2023-07-24T10:04:41.971322","status":"completed"},"tags":[]},"outputs":[],"source":["def token(value , tokenizer = bert_tokenizer , model = bert_based , pool = False):\n","    \n","    tokens = tokenizer(value , return_tensors = \"pt\")\n","    \n","    output = model(tokens[\"input_ids\"])\n","    \n","    if pool:return output[1].detach().numpy().squeeze()\n","    \n","    return output[0].detach().numpy().squeeze()"]},{"cell_type":"code","execution_count":10,"id":"fc682044","metadata":{"execution":{"iopub.execute_input":"2023-07-24T10:04:42.071295Z","iopub.status.busy":"2023-07-24T10:04:42.070441Z","iopub.status.idle":"2023-07-24T10:06:41.523937Z","shell.execute_reply":"2023-07-24T10:06:41.522901Z"},"papermill":{"duration":119.487061,"end_time":"2023-07-24T10:06:41.527198","exception":false,"start_time":"2023-07-24T10:04:42.040137","status":"completed"},"tags":[]},"outputs":[],"source":["bert_csv = pd.DataFrame([0 for _ in range(200)])\n","\n","bert_csv[\"prompt\"] = train[\"prompt\"].apply(token)\n","bert_csv[\"A\"] = train[\"A\"].apply(token)\n","bert_csv[\"B\"] = train[\"B\"].apply(token)\n","bert_csv[\"C\"] = train[\"C\"].apply(token)\n","bert_csv[\"D\"] = train[\"D\"].apply(token)\n","bert_csv[\"E\"] = train[\"E\"].apply(token)\n","bert_csv[\"answer\"] = train[\"answer\"]"]},{"cell_type":"code","execution_count":11,"id":"4acd5668","metadata":{"execution":{"iopub.execute_input":"2023-07-24T10:06:41.589694Z","iopub.status.busy":"2023-07-24T10:06:41.58829Z","iopub.status.idle":"2023-07-24T10:06:41.598617Z","shell.execute_reply":"2023-07-24T10:06:41.597766Z"},"papermill":{"duration":0.043933,"end_time":"2023-07-24T10:06:41.601393","exception":false,"start_time":"2023-07-24T10:06:41.55746","status":"completed"},"tags":[]},"outputs":[],"source":["bert_csv[\"answer\"] = np.where(bert_csv[\"answer\"] == \"A\" , 1 , bert_csv[\"answer\"])\n","bert_csv[\"answer\"] = np.where(bert_csv[\"answer\"] == \"B\" , 2 , bert_csv[\"answer\"])\n","bert_csv[\"answer\"] = np.where(bert_csv[\"answer\"] == \"C\" , 3 , bert_csv[\"answer\"])\n","bert_csv[\"answer\"] = np.where(bert_csv[\"answer\"] == \"D\" , 4 , bert_csv[\"answer\"])\n","bert_csv[\"answer\"] = np.where(bert_csv[\"answer\"] == \"E\" , 5 , bert_csv[\"answer\"])"]},{"cell_type":"markdown","id":"d49dbfd4","metadata":{"papermill":{"duration":0.027345,"end_time":"2023-07-24T10:06:41.656904","exception":false,"start_time":"2023-07-24T10:06:41.629559","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","This is our tokenized format "]},{"cell_type":"code","execution_count":12,"id":"964b82e4","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-07-24T10:06:41.71438Z","iopub.status.busy":"2023-07-24T10:06:41.71363Z","iopub.status.idle":"2023-07-24T10:06:45.85879Z","shell.execute_reply":"2023-07-24T10:06:45.857645Z"},"papermill":{"duration":4.176887,"end_time":"2023-07-24T10:06:45.861411","exception":false,"start_time":"2023-07-24T10:06:41.684524","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>prompt</th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","      <th>D</th>\n","      <th>E</th>\n","      <th>answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>[[0.5954785, 0.016742375, 0.25113845, -0.33201...</td>\n","      <td>[[0.26678404, -0.13396168, 0.048275813, -0.190...</td>\n","      <td>[[0.3160099, -0.07156702, 0.03550779, -0.20390...</td>\n","      <td>[[0.31307223, -0.15782145, 0.0039771437, -0.10...</td>\n","      <td>[[0.39717036, 0.009571799, 0.02090334, -0.2079...</td>\n","      <td>[[0.26498082, -0.11152987, 0.09861849, -0.1717...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>[[0.48086163, 0.13048011, 0.20981884, -0.29516...</td>\n","      <td>[[0.6098233, 0.0972536, 0.16351525, -0.1299212...</td>\n","      <td>[[0.6067397, 0.13667028, 0.18718192, -0.164518...</td>\n","      <td>[[0.5301055, 0.0713303, 0.19720834, -0.1847760...</td>\n","      <td>[[0.55116785, 0.08227803, 0.22088835, -0.18411...</td>\n","      <td>[[0.5684599, 0.1910345, 0.14520799, -0.1389537...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>[[0.5633879, 0.022773514, 0.11718962, -0.14262...</td>\n","      <td>[[0.43013036, -0.05444927, 0.04960315, -0.0816...</td>\n","      <td>[[0.38208723, -0.1964721, -0.024255829, -0.127...</td>\n","      <td>[[0.4089076, -0.109597705, 0.06722128, -0.0298...</td>\n","      <td>[[0.21592978, -0.23158002, 0.028887426, -0.068...</td>\n","      <td>[[0.38425943, -0.14076975, 0.044870295, -0.117...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>[[0.4242367, 0.13664639, 0.08093922, -0.279368...</td>\n","      <td>[[0.4670743, -0.21700826, 0.16711907, -0.35785...</td>\n","      <td>[[0.60160524, -0.082947515, 0.28576776, -0.489...</td>\n","      <td>[[0.6052707, -0.08577526, 0.22512098, -0.48140...</td>\n","      <td>[[0.5814356, -0.1303677, 0.22648613, -0.440707...</td>\n","      <td>[[0.6130338, -0.036285013, 0.2662849, -0.43933...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>[[0.61632174, 0.092921205, 0.27170777, -0.2215...</td>\n","      <td>[[0.37809604, -0.16092303, 0.16882758, -0.2595...</td>\n","      <td>[[0.3694178, -0.15149622, 0.17266133, -0.25841...</td>\n","      <td>[[0.2997911, -0.15832873, 0.09018601, -0.24680...</td>\n","      <td>[[0.38440725, -0.15802866, 0.17178412, -0.2330...</td>\n","      <td>[[0.36492893, -0.1719651, 0.18760608, -0.25752...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>0</td>\n","      <td>[[0.37028533, 0.24675308, 0.11544872, -0.36422...</td>\n","      <td>[[0.29882017, -0.027735448, 0.08780523, -0.200...</td>\n","      <td>[[0.2983277, 0.115363, 0.08399957, -0.3266757,...</td>\n","      <td>[[0.444976, 0.11159219, 0.034268778, -0.186582...</td>\n","      <td>[[0.35315177, 0.019672012, 0.091255896, -0.301...</td>\n","      <td>[[0.4171703, 0.00043702722, 0.13987462, -0.410...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>0</td>\n","      <td>[[0.51109606, 0.0829629, 0.12613802, 0.0109595...</td>\n","      <td>[[0.34055692, 0.06306243, 0.03861563, -0.19832...</td>\n","      <td>[[0.36286342, 0.042207185, 0.014683261, -0.188...</td>\n","      <td>[[0.35367307, 0.055113252, 0.017835828, -0.203...</td>\n","      <td>[[0.3479987, 0.050205637, 0.03540563, -0.18161...</td>\n","      <td>[[0.5213482, 0.006469099, -0.0054984107, -0.23...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>0</td>\n","      <td>[[0.39656845, 0.14130571, -0.013567732, -0.371...</td>\n","      <td>[[0.45368078, -0.29536974, -0.049366374, -0.31...</td>\n","      <td>[[0.46274835, -0.2906356, -0.04002542, -0.3202...</td>\n","      <td>[[0.43663096, -0.30893922, -0.037753228, -0.30...</td>\n","      <td>[[0.4456481, -0.31710142, -0.04196011, -0.3282...</td>\n","      <td>[[0.43670073, -0.30175078, -0.05860339, -0.319...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>0</td>\n","      <td>[[0.36871165, 0.18375124, 0.015941879, -0.1210...</td>\n","      <td>[[0.26379362, -0.057898458, 0.071916506, -0.24...</td>\n","      <td>[[0.2760112, -0.16288757, 0.08594819, -0.20769...</td>\n","      <td>[[0.274591, -0.15716897, 0.091395885, -0.20302...</td>\n","      <td>[[0.28071156, -0.16528511, 0.084627695, -0.203...</td>\n","      <td>[[0.25818092, -0.08729951, 0.086152844, -0.240...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>0</td>\n","      <td>[[0.51533663, 0.0009040135, 0.050474167, -0.26...</td>\n","      <td>[[0.4557482, -0.062204674, 0.09033542, -0.0671...</td>\n","      <td>[[0.42661777, -0.05760088, 0.086184986, -0.077...</td>\n","      <td>[[0.44780895, -0.03275532, 0.09187614, -0.0594...</td>\n","      <td>[[0.43931064, -0.0259413, 0.07334492, -0.06686...</td>\n","      <td>[[0.4515665, -0.04801793, 0.093121506, -0.0780...</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>200 rows Ã— 8 columns</p>\n","</div>"],"text/plain":["     0                                             prompt  \\\n","0    0  [[0.5954785, 0.016742375, 0.25113845, -0.33201...   \n","1    0  [[0.48086163, 0.13048011, 0.20981884, -0.29516...   \n","2    0  [[0.5633879, 0.022773514, 0.11718962, -0.14262...   \n","3    0  [[0.4242367, 0.13664639, 0.08093922, -0.279368...   \n","4    0  [[0.61632174, 0.092921205, 0.27170777, -0.2215...   \n","..  ..                                                ...   \n","195  0  [[0.37028533, 0.24675308, 0.11544872, -0.36422...   \n","196  0  [[0.51109606, 0.0829629, 0.12613802, 0.0109595...   \n","197  0  [[0.39656845, 0.14130571, -0.013567732, -0.371...   \n","198  0  [[0.36871165, 0.18375124, 0.015941879, -0.1210...   \n","199  0  [[0.51533663, 0.0009040135, 0.050474167, -0.26...   \n","\n","                                                     A  \\\n","0    [[0.26678404, -0.13396168, 0.048275813, -0.190...   \n","1    [[0.6098233, 0.0972536, 0.16351525, -0.1299212...   \n","2    [[0.43013036, -0.05444927, 0.04960315, -0.0816...   \n","3    [[0.4670743, -0.21700826, 0.16711907, -0.35785...   \n","4    [[0.37809604, -0.16092303, 0.16882758, -0.2595...   \n","..                                                 ...   \n","195  [[0.29882017, -0.027735448, 0.08780523, -0.200...   \n","196  [[0.34055692, 0.06306243, 0.03861563, -0.19832...   \n","197  [[0.45368078, -0.29536974, -0.049366374, -0.31...   \n","198  [[0.26379362, -0.057898458, 0.071916506, -0.24...   \n","199  [[0.4557482, -0.062204674, 0.09033542, -0.0671...   \n","\n","                                                     B  \\\n","0    [[0.3160099, -0.07156702, 0.03550779, -0.20390...   \n","1    [[0.6067397, 0.13667028, 0.18718192, -0.164518...   \n","2    [[0.38208723, -0.1964721, -0.024255829, -0.127...   \n","3    [[0.60160524, -0.082947515, 0.28576776, -0.489...   \n","4    [[0.3694178, -0.15149622, 0.17266133, -0.25841...   \n","..                                                 ...   \n","195  [[0.2983277, 0.115363, 0.08399957, -0.3266757,...   \n","196  [[0.36286342, 0.042207185, 0.014683261, -0.188...   \n","197  [[0.46274835, -0.2906356, -0.04002542, -0.3202...   \n","198  [[0.2760112, -0.16288757, 0.08594819, -0.20769...   \n","199  [[0.42661777, -0.05760088, 0.086184986, -0.077...   \n","\n","                                                     C  \\\n","0    [[0.31307223, -0.15782145, 0.0039771437, -0.10...   \n","1    [[0.5301055, 0.0713303, 0.19720834, -0.1847760...   \n","2    [[0.4089076, -0.109597705, 0.06722128, -0.0298...   \n","3    [[0.6052707, -0.08577526, 0.22512098, -0.48140...   \n","4    [[0.2997911, -0.15832873, 0.09018601, -0.24680...   \n","..                                                 ...   \n","195  [[0.444976, 0.11159219, 0.034268778, -0.186582...   \n","196  [[0.35367307, 0.055113252, 0.017835828, -0.203...   \n","197  [[0.43663096, -0.30893922, -0.037753228, -0.30...   \n","198  [[0.274591, -0.15716897, 0.091395885, -0.20302...   \n","199  [[0.44780895, -0.03275532, 0.09187614, -0.0594...   \n","\n","                                                     D  \\\n","0    [[0.39717036, 0.009571799, 0.02090334, -0.2079...   \n","1    [[0.55116785, 0.08227803, 0.22088835, -0.18411...   \n","2    [[0.21592978, -0.23158002, 0.028887426, -0.068...   \n","3    [[0.5814356, -0.1303677, 0.22648613, -0.440707...   \n","4    [[0.38440725, -0.15802866, 0.17178412, -0.2330...   \n","..                                                 ...   \n","195  [[0.35315177, 0.019672012, 0.091255896, -0.301...   \n","196  [[0.3479987, 0.050205637, 0.03540563, -0.18161...   \n","197  [[0.4456481, -0.31710142, -0.04196011, -0.3282...   \n","198  [[0.28071156, -0.16528511, 0.084627695, -0.203...   \n","199  [[0.43931064, -0.0259413, 0.07334492, -0.06686...   \n","\n","                                                     E answer  \n","0    [[0.26498082, -0.11152987, 0.09861849, -0.1717...      4  \n","1    [[0.5684599, 0.1910345, 0.14520799, -0.1389537...      1  \n","2    [[0.38425943, -0.14076975, 0.044870295, -0.117...      1  \n","3    [[0.6130338, -0.036285013, 0.2662849, -0.43933...      3  \n","4    [[0.36492893, -0.1719651, 0.18760608, -0.25752...      4  \n","..                                                 ...    ...  \n","195  [[0.4171703, 0.00043702722, 0.13987462, -0.410...      3  \n","196  [[0.5213482, 0.006469099, -0.0054984107, -0.23...      2  \n","197  [[0.43670073, -0.30175078, -0.05860339, -0.319...      2  \n","198  [[0.25818092, -0.08729951, 0.086152844, -0.240...      4  \n","199  [[0.4515665, -0.04801793, 0.093121506, -0.0780...      3  \n","\n","[200 rows x 8 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["bert_csv"]},{"cell_type":"markdown","id":"b032f4c5","metadata":{"papermill":{"duration":0.028556,"end_time":"2023-07-24T10:06:45.919126","exception":false,"start_time":"2023-07-24T10:06:45.89057","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Lets export it to output files, to use them further without any extra usage of time/resources"]},{"cell_type":"code","execution_count":13,"id":"632af9d0","metadata":{"_kg_hide-input":false,"execution":{"iopub.execute_input":"2023-07-24T10:06:45.977689Z","iopub.status.busy":"2023-07-24T10:06:45.977313Z","iopub.status.idle":"2023-07-24T10:06:45.98256Z","shell.execute_reply":"2023-07-24T10:06:45.981591Z"},"papermill":{"duration":0.037384,"end_time":"2023-07-24T10:06:45.984771","exception":false,"start_time":"2023-07-24T10:06:45.947387","status":"completed"},"tags":[]},"outputs":[],"source":["os.makedirs(\"/kaggle/working/Kaggle LLMs Embedments/CSV/Bert Based Tokenizer/\")\n","os.makedirs(\"/kaggle/working/Kaggle LLMs Embedments/Numpy/Bert Based Tokenizer/\")"]},{"cell_type":"code","execution_count":14,"id":"94122c4e","metadata":{"execution":{"iopub.execute_input":"2023-07-24T10:06:46.043793Z","iopub.status.busy":"2023-07-24T10:06:46.043406Z","iopub.status.idle":"2023-07-24T10:06:46.63695Z","shell.execute_reply":"2023-07-24T10:06:46.635974Z"},"papermill":{"duration":0.626318,"end_time":"2023-07-24T10:06:46.639661","exception":false,"start_time":"2023-07-24T10:06:46.013343","status":"completed"},"tags":[]},"outputs":[],"source":["bert_csv.to_csv(\"/kaggle/working/Kaggle LLMs Embedments/CSV/Bert Based Tokenizer/Train Embeds\")"]},{"cell_type":"markdown","id":"0189ca4a","metadata":{"papermill":{"duration":0.02798,"end_time":"2023-07-24T10:06:46.696143","exception":false,"start_time":"2023-07-24T10:06:46.668163","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","We will also store this information in `npy` file format"]},{"cell_type":"code","execution_count":15,"id":"faef0180","metadata":{"execution":{"iopub.execute_input":"2023-07-24T10:06:46.754172Z","iopub.status.busy":"2023-07-24T10:06:46.75374Z","iopub.status.idle":"2023-07-24T10:06:46.920987Z","shell.execute_reply":"2023-07-24T10:06:46.919755Z"},"papermill":{"duration":0.199743,"end_time":"2023-07-24T10:06:46.924107","exception":false,"start_time":"2023-07-24T10:06:46.724364","status":"completed"},"tags":[]},"outputs":[],"source":["bert_based = bert_csv.to_numpy()\n","\n","np.save(\"/kaggle/working/Kaggle LLMs Embedments/Numpy/Bert Based Tokenizer/Train Embeds\" , bert_based)"]},{"cell_type":"markdown","id":"703b4b4c","metadata":{"papermill":{"duration":0.028376,"end_time":"2023-07-24T10:06:46.981363","exception":false,"start_time":"2023-07-24T10:06:46.952987","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","## $3.2$ $|$ $FLAN-T5$ $Small$\n","    \n","$Flan-T5$ is an `instruction-finetuned` version of $T5$, a `text-to-text` `transfer` `transformer` `language model`. It was released in the paper **[Scaling Instruction-Finetuned Language Models](https://arxiv.org/pdf/2210.11416.pdf)** by $Google$ $AI$. $Flan-T5$ is `trained` on a mixture of tasks, including \n","* $Summarization$\n","* Translation$\n","* $Question$ $Answering$\n","* $Code$ $Generation$\n","This makes it `more versatile` than $T5$, which is only trained on text-to-text tasks.\n","\n","$Flan-T5$ has been shown to achieve state-of-the-art performance on several benchmarks, including\n","* $MMLU$ $Multi-Task$ $Few-Shot$ $Learning$ $Understanding$ - $75.2$%\n","* $GLUE$ $General$ $Language$ $Understanding$ $Evaluation$ - $91.4$% \n","* $SQuAD$ $Stanford$ $Question$ $Answering$ $Dataset$ - $94.0$%\n","\n","We can get the model from `Kaggle` itself"]},{"cell_type":"code","execution_count":16,"id":"d4e5e946","metadata":{"execution":{"iopub.execute_input":"2023-07-24T10:06:47.042724Z","iopub.status.busy":"2023-07-24T10:06:47.041633Z","iopub.status.idle":"2023-07-24T10:06:47.159562Z","shell.execute_reply":"2023-07-24T10:06:47.158311Z"},"papermill":{"duration":0.151921,"end_time":"2023-07-24T10:06:47.162644","exception":false,"start_time":"2023-07-24T10:06:47.010723","status":"completed"},"tags":[]},"outputs":[],"source":["flan_t5_tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/flan-t5/pytorch/base/2')"]},{"cell_type":"code","execution_count":17,"id":"9b3f7fdd","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-24T10:06:47.221984Z","iopub.status.busy":"2023-07-24T10:06:47.221271Z","iopub.status.idle":"2023-07-24T10:07:01.395285Z","shell.execute_reply":"2023-07-24T10:07:01.394219Z"},"papermill":{"duration":14.207006,"end_time":"2023-07-24T10:07:01.398144","exception":false,"start_time":"2023-07-24T10:06:47.191138","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at /kaggle/input/flan-t5/pytorch/base/2 were not used when initializing T5Model: ['lm_head.weight']\n","- This IS expected if you are initializing T5Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing T5Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["flan_t5 = AutoModel.from_pretrained('/kaggle/input/flan-t5/pytorch/base/2')"]},{"cell_type":"markdown","id":"3142cf32","metadata":{"papermill":{"duration":0.027942,"end_time":"2023-07-24T10:07:01.45433","exception":false,"start_time":"2023-07-24T10:07:01.426388","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","If we pass a sample text like this "]},{"cell_type":"code","execution_count":18,"id":"5f720501","metadata":{"execution":{"iopub.execute_input":"2023-07-24T10:07:01.513392Z","iopub.status.busy":"2023-07-24T10:07:01.512408Z","iopub.status.idle":"2023-07-24T10:07:01.521202Z","shell.execute_reply":"2023-07-24T10:07:01.519989Z"},"papermill":{"duration":0.040986,"end_time":"2023-07-24T10:07:01.523452","exception":false,"start_time":"2023-07-24T10:07:01.482466","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["'Answer the following question by outputting the letters A, B, C, D, and E '    'in order of the most likely to be correct to the to least likely to be correct.'\n","\n","\n","prompt) Which of the following statements accurately describes the impact of Modified Newtonian Dynamics (MOND) on the observed \"missing baryonic mass\" discrepancy in galaxy clusters?\n","A) MOND is a theory that reduces the observed missing baryonic mass in galaxy clusters by postulating the existence of a new form of matter called \"fuzzy dark matter.\"\n","B) MOND is a theory that increases the discrepancy between the observed missing baryonic mass in galaxy clusters and the measured velocity dispersions from a factor of around 10 to a factor of about 20.\n","C) MOND is a theory that explains the missing baryonic mass in galaxy clusters that was previously considered dark matter by demonstrating that the mass is in the form of neutrinos and axions.\n","D) MOND is a theory that reduces the discrepancy between the observed missing baryonic mass in galaxy clusters and the measured velocity dispersions from a factor of around 10 to a factor of about 2.\n"]}],"source":["stri = \"'Answer the following question by outputting the letters A, B, C, D, and E '\\\n","    'in order of the most likely to be correct to the to least likely to be correct.'\\n\\n\"\n","for x in range(1 , 6):\n","    stri += \"\\n\" + str(train.columns[x]) + \") \" + str(train.iloc[0][x])\n","    \n","print(stri)"]},{"cell_type":"code","execution_count":19,"id":"ab70ee30","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-24T10:07:01.583155Z","iopub.status.busy":"2023-07-24T10:07:01.582732Z","iopub.status.idle":"2023-07-24T10:07:01.596724Z","shell.execute_reply":"2023-07-24T10:07:01.595595Z"},"papermill":{"duration":0.047618,"end_time":"2023-07-24T10:07:01.599632","exception":false,"start_time":"2023-07-24T10:07:01.552014","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["{'input_ids': tensor([[    3,    31,   188,    29,     7,  3321,     8,   826,   822,    57,\n","            91,  3131,     8,  5487,    71,     6,   272,     6,   205,     6,\n","           309,     6,    11,   262,     3,    31,     3,    31,    77,   455,\n","            13,     8,   167,   952,    12,    36,  2024,    12,     8,    12,\n","           709,   952,    12,    36,  2024,     5,    31,  9005,    61,  4073,\n","            13,     8,   826,  6643, 12700,  8788,     8,  1113,    13,  5073,\n","          3676, 20126,    23,   152, 23398,    41, 20399,   308,    61,    30,\n","             8,  6970,    96, 11502,    53,  1207,    63,  4554,  3294,   121,\n","          5025,    60,   102,  6833,    16, 24856,  9068,     7,    58,    71,\n","            61,   283, 24796,    19,     3,     9,  4516,    24,  1428,     7,\n","             8,  6970,  3586,  1207,    63,  4554,  3294,    16, 24856,  9068,\n","             7,    57,   442,    83,  1014,     8,  6831,    13,     3,     9,\n","           126,   607,    13,  1052,   718,    96, 22845,  4164,  2164,  1052,\n","           535,   272,    61,   283, 24796,    19,     3,     9,  4516,    24,\n","          5386,     8,  5025,    60,   102,  6833,   344,     8,  6970,  3586,\n","          1207,    63,  4554,  3294,    16, 24856,  9068,     7,    11,     8,\n","          8413, 22924,  1028,  4660,  2865,    45,     3,     9,  2945,    13,\n","           300,   335,    12,     3,     9,  2945,    13,    81,   460,     5,\n","           205,    61,   283, 24796,    19,     3,     9,  4516,    24,     3,\n","          9453,     8,  3586,  1207,    63,  4554,  3294,    16, 24856,  9068,\n","             7,    24,    47,  3150,  1702,  2164,  1052,    57,     3, 20968,\n","            24,     8,  3294,    19,    16,     8,   607,    13, 22883,    23,\n","          4844,    11,     3,     9,   226,  2865,     5,   309,    61,   283,\n","         24796,    19,     3,     9,  4516,    24,  1428,     7,     8,  5025,\n","            60,   102,  6833,   344,     8,  6970,  3586,  1207,    63,  4554,\n","          3294,    16, 24856,  9068,     7,    11,     8,  8413, 22924,  1028,\n","          4660,  2865,    45,     3,     9,  2945,    13,   300,   335,    12,\n","             3,     9,  2945,    13,    81,  1682,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["flan_t5_tokens = flan_t5_tokenizer(stri , return_tensors = \"pt\")\n","flan_t5_tokens"]},{"cell_type":"markdown","id":"4f9c8206","metadata":{"papermill":{"duration":0.028977,"end_time":"2023-07-24T10:07:01.658332","exception":false,"start_time":"2023-07-24T10:07:01.629355","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","what we actually need is this "]},{"cell_type":"code","execution_count":20,"id":"c4827724","metadata":{"execution":{"iopub.execute_input":"2023-07-24T10:07:01.720442Z","iopub.status.busy":"2023-07-24T10:07:01.720063Z","iopub.status.idle":"2023-07-24T10:07:01.730271Z","shell.execute_reply":"2023-07-24T10:07:01.729136Z"},"papermill":{"duration":0.042767,"end_time":"2023-07-24T10:07:01.732619","exception":false,"start_time":"2023-07-24T10:07:01.689852","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[    3,    31,   188,    29,     7,  3321,     8,   826,   822,    57,\n","            91,  3131,     8,  5487,    71,     6,   272,     6,   205,     6,\n","           309,     6,    11,   262,     3,    31,     3,    31,    77,   455,\n","            13,     8,   167,   952,    12,    36,  2024,    12,     8,    12,\n","           709,   952,    12,    36,  2024,     5,    31,  9005,    61,  4073,\n","            13,     8,   826,  6643, 12700,  8788,     8,  1113,    13,  5073,\n","          3676, 20126,    23,   152, 23398,    41, 20399,   308,    61,    30,\n","             8,  6970,    96, 11502,    53,  1207,    63,  4554,  3294,   121,\n","          5025,    60,   102,  6833,    16, 24856,  9068,     7,    58,    71,\n","            61,   283, 24796,    19,     3,     9,  4516,    24,  1428,     7,\n","             8,  6970,  3586,  1207,    63,  4554,  3294,    16, 24856,  9068,\n","             7,    57,   442,    83,  1014,     8,  6831,    13,     3,     9,\n","           126,   607,    13,  1052,   718,    96, 22845,  4164,  2164,  1052,\n","           535,   272,    61,   283, 24796,    19,     3,     9,  4516,    24,\n","          5386,     8,  5025,    60,   102,  6833,   344,     8,  6970,  3586,\n","          1207,    63,  4554,  3294,    16, 24856,  9068,     7,    11,     8,\n","          8413, 22924,  1028,  4660,  2865,    45,     3,     9,  2945,    13,\n","           300,   335,    12,     3,     9,  2945,    13,    81,   460,     5,\n","           205,    61,   283, 24796,    19,     3,     9,  4516,    24,     3,\n","          9453,     8,  3586,  1207,    63,  4554,  3294,    16, 24856,  9068,\n","             7,    24,    47,  3150,  1702,  2164,  1052,    57,     3, 20968,\n","            24,     8,  3294,    19,    16,     8,   607,    13, 22883,    23,\n","          4844,    11,     3,     9,   226,  2865,     5,   309,    61,   283,\n","         24796,    19,     3,     9,  4516,    24,  1428,     7,     8,  5025,\n","            60,   102,  6833,   344,     8,  6970,  3586,  1207,    63,  4554,\n","          3294,    16, 24856,  9068,     7,    11,     8,  8413, 22924,  1028,\n","          4660,  2865,    45,     3,     9,  2945,    13,   300,   335,    12,\n","             3,     9,  2945,    13,    81,  1682,     1]])"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["flan_t5_tokens[\"input_ids\"]"]},{"cell_type":"markdown","id":"73a0775e","metadata":{"papermill":{"duration":0.029323,"end_time":"2023-07-24T10:07:01.791206","exception":false,"start_time":"2023-07-24T10:07:01.761883","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Lets make a function for this "]},{"cell_type":"code","execution_count":21,"id":"d711088d","metadata":{"execution":{"iopub.execute_input":"2023-07-24T10:07:01.851604Z","iopub.status.busy":"2023-07-24T10:07:01.851213Z","iopub.status.idle":"2023-07-24T10:07:01.858354Z","shell.execute_reply":"2023-07-24T10:07:01.857299Z"},"papermill":{"duration":0.040476,"end_time":"2023-07-24T10:07:01.860622","exception":false,"start_time":"2023-07-24T10:07:01.820146","status":"completed"},"tags":[]},"outputs":[],"source":["def string_format(idx , tokenizer = flan_t5_tokenizer):\n","    \n","    stri = \"'Answer the following question by outputting the letters A, B, C, D, and E '\\\n","    'in order of the most likely to be correct to the to least likely to be correct.'\\n\\n\"\n","    for x in range(1 , 6):\n","        stri += \"\\n\" + str(train.columns[x]) + \") \" + str(train.iloc[idx][x])\n","\n","    flan_t5_tokens = tokenizer(stri , return_tensors = \"pt\")\n","    \n","    return flan_t5_tokens[\"input_ids\"].detach().numpy().squeeze()"]},{"cell_type":"code","execution_count":22,"id":"5087518d","metadata":{"execution":{"iopub.execute_input":"2023-07-24T10:07:01.920661Z","iopub.status.busy":"2023-07-24T10:07:01.920267Z","iopub.status.idle":"2023-07-24T10:07:01.930349Z","shell.execute_reply":"2023-07-24T10:07:01.928895Z"},"papermill":{"duration":0.043301,"end_time":"2023-07-24T10:07:01.93278","exception":false,"start_time":"2023-07-24T10:07:01.889479","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["[    3    31   188    29     7  3321     8   826   822    57    91  3131\n","     8  5487    71     6   272     6   205     6   309     6    11   262\n","     3    31     3    31    77   455    13     8   167   952    12    36\n","  2024    12     8    12   709   952    12    36  2024     5    31  9005\n","    61  4073    13     8   826    19    46  4034  4903    13  4896 24485\n","    16  1044    18 26714  1002    58    71    61 13967  3113 24485  2401\n","     7    12     8  9009    13  1044    18 26714  1002     6   213   331\n","  5105    45 23052     7    44  3599   648  6981     7  1126   485    12\n","     8  6477   331  1026    45 23052     7    13   136  2283    42   865\n","    97     5   100  1126   485    19  5285    57     3     9   824    97\n","    18 17631 13564   107 10057  7660     3   226     5   272    61 13967\n","  3113 24485  2401     7    12     8   529    18    15 24817    13  1044\n","    18 26714  1002     6   213   331  5105    45 23052     7    44  3599\n","   648    19  1126    12     8  6477   331  1026    45 23052     7    13\n","   136  2283    42   865    97     5   100  1126   485    19  5285    57\n","     3     9   824    97    18 17631 13564   107 10057  7660     3   226\n","     5   205    61 13967  3113 24485  2401     7    12     8  9009    13\n","  1044    18 26714  1002     6   213   331  5105    45 23052     7    44\n","  3599   648    19  1028 26714    12     8  6477   331  1026    45 23052\n","     7    13   136  2283    42   865    97     5   100  1028 26714   485\n","    19  5285    57     3     9   824    97    18    77 17631 13564   107\n"," 10057  7660     3    63     5   309    61 13967  3113 24485  2401     7\n","    12     8   529    18    15 24817    13  1044    18 26714  1002     6\n","   213   331  5105    45 23052     7    44  3599   648    19  1028 26714\n","    12     8  6477   331  1026    45 23052     7    13   136  2283    42\n","   865    97     5   100  1028 26714   485    19  5285    57     3     9\n","   824    97    18    77 17631 13564   107 10057  7660     3    63     5\n","     1]\n"]}],"source":["print(string_format(1))"]},{"cell_type":"code","execution_count":23,"id":"20de1619","metadata":{"execution":{"iopub.execute_input":"2023-07-24T10:07:01.99383Z","iopub.status.busy":"2023-07-24T10:07:01.993396Z","iopub.status.idle":"2023-07-24T10:07:02.361297Z","shell.execute_reply":"2023-07-24T10:07:02.360038Z"},"papermill":{"duration":0.402046,"end_time":"2023-07-24T10:07:02.36413","exception":false,"start_time":"2023-07-24T10:07:01.962084","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/200 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:00<00:00, 559.93it/s]\n"]}],"source":["flan_t5_base_v2 = pd.DataFrame([0 for _ in range(200)])\n","\n","flan_t5_base_v2[\"tokens\"] = ([string_format(idx) for idx in tqdm.tqdm(range(200) , total = 200)])"]},{"cell_type":"code","execution_count":24,"id":"ebf85ae5","metadata":{"execution":{"iopub.execute_input":"2023-07-24T10:07:02.426058Z","iopub.status.busy":"2023-07-24T10:07:02.425597Z","iopub.status.idle":"2023-07-24T10:07:02.45457Z","shell.execute_reply":"2023-07-24T10:07:02.453467Z"},"papermill":{"duration":0.062667,"end_time":"2023-07-24T10:07:02.456814","exception":false,"start_time":"2023-07-24T10:07:02.394147","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>tokens</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>[3, 31, 188, 29, 7, 3321, 8, 826, 822, 57, 91,...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>[3, 31, 188, 29, 7, 3321, 8, 826, 822, 57, 91,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>[3, 31, 188, 29, 7, 3321, 8, 826, 822, 57, 91,...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>[3, 31, 188, 29, 7, 3321, 8, 826, 822, 57, 91,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>[3, 31, 188, 29, 7, 3321, 8, 826, 822, 57, 91,...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>0</td>\n","      <td>[3, 31, 188, 29, 7, 3321, 8, 826, 822, 57, 91,...</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>0</td>\n","      <td>[3, 31, 188, 29, 7, 3321, 8, 826, 822, 57, 91,...</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>0</td>\n","      <td>[3, 31, 188, 29, 7, 3321, 8, 826, 822, 57, 91,...</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>0</td>\n","      <td>[3, 31, 188, 29, 7, 3321, 8, 826, 822, 57, 91,...</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>0</td>\n","      <td>[3, 31, 188, 29, 7, 3321, 8, 826, 822, 57, 91,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>200 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["     0                                             tokens\n","0    0  [3, 31, 188, 29, 7, 3321, 8, 826, 822, 57, 91,...\n","1    0  [3, 31, 188, 29, 7, 3321, 8, 826, 822, 57, 91,...\n","2    0  [3, 31, 188, 29, 7, 3321, 8, 826, 822, 57, 91,...\n","3    0  [3, 31, 188, 29, 7, 3321, 8, 826, 822, 57, 91,...\n","4    0  [3, 31, 188, 29, 7, 3321, 8, 826, 822, 57, 91,...\n","..  ..                                                ...\n","195  0  [3, 31, 188, 29, 7, 3321, 8, 826, 822, 57, 91,...\n","196  0  [3, 31, 188, 29, 7, 3321, 8, 826, 822, 57, 91,...\n","197  0  [3, 31, 188, 29, 7, 3321, 8, 826, 822, 57, 91,...\n","198  0  [3, 31, 188, 29, 7, 3321, 8, 826, 822, 57, 91,...\n","199  0  [3, 31, 188, 29, 7, 3321, 8, 826, 822, 57, 91,...\n","\n","[200 rows x 2 columns]"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["flan_t5_base_v2"]},{"cell_type":"code","execution_count":25,"id":"a53a08de","metadata":{"execution":{"iopub.execute_input":"2023-07-24T10:07:02.518264Z","iopub.status.busy":"2023-07-24T10:07:02.517854Z","iopub.status.idle":"2023-07-24T10:07:02.522853Z","shell.execute_reply":"2023-07-24T10:07:02.521876Z"},"papermill":{"duration":0.038102,"end_time":"2023-07-24T10:07:02.524887","exception":false,"start_time":"2023-07-24T10:07:02.486785","status":"completed"},"tags":[]},"outputs":[],"source":["os.makedirs(\"/kaggle/working/Kaggle LLMs Embedments/CSV/Flan T5 Small Base V2/\")\n","os.makedirs(\"/kaggle/working/Kaggle LLMs Embedments/Numpy/Flan T5 Small Base V2/\")"]},{"cell_type":"code","execution_count":26,"id":"49723888","metadata":{"execution":{"iopub.execute_input":"2023-07-24T10:07:02.586894Z","iopub.status.busy":"2023-07-24T10:07:02.585916Z","iopub.status.idle":"2023-07-24T10:07:02.775385Z","shell.execute_reply":"2023-07-24T10:07:02.774131Z"},"papermill":{"duration":0.223732,"end_time":"2023-07-24T10:07:02.778248","exception":false,"start_time":"2023-07-24T10:07:02.554516","status":"completed"},"tags":[]},"outputs":[],"source":["flan_t5_base_v2.to_csv(\"/kaggle/working/Kaggle LLMs Embedments/CSV/Flan T5 Small Base V2/Train Embeds\")"]},{"cell_type":"code","execution_count":27,"id":"6e0923ca","metadata":{"execution":{"iopub.execute_input":"2023-07-24T10:07:02.840368Z","iopub.status.busy":"2023-07-24T10:07:02.839318Z","iopub.status.idle":"2023-07-24T10:07:02.847425Z","shell.execute_reply":"2023-07-24T10:07:02.84651Z"},"papermill":{"duration":0.041241,"end_time":"2023-07-24T10:07:02.849675","exception":false,"start_time":"2023-07-24T10:07:02.808434","status":"completed"},"tags":[]},"outputs":[],"source":["flan_t5_ = flan_t5_base_v2[\"tokens\"].to_numpy()\n","\n","np.save(\"/kaggle/working/Kaggle LLMs Embedments/Numpy/Flan T5 Small Base V2/Train Embeds\" , flan_t5_)"]},{"cell_type":"markdown","id":"05566fb6","metadata":{"papermill":{"duration":0.030632,"end_time":"2023-07-24T10:07:02.910736","exception":false,"start_time":"2023-07-24T10:07:02.880104","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","## $3.3$ $|$ $Falcon$ $7B$\n","    \n","I got the idea to implement `Falcon 7B` from **[Debarshi Chanda](https://www.kaggle.com/debarshichanda)=>[LLM Evaluation (MMLU Style)](https://www.kaggle.com/code/debarshichanda/llm-evaluation-mmlu-style)**, kudos to the mate for amazing notebook $:)$\n","\n","    The $Falcon$ $7B$ $Tokenizer$ is a `text tokenizer` that is used with the $Falcon$ $7B$ language model. The `tokenizer` is responsible for `splitting text` into `tokens`, which are the basic units that the language model understands. The tokenizer also assigns `each token a unique ID`, which allows the language model to refer to the tokens later.\n","\n","The $Falcon$ $7B$ Tokenizer is based on the `GPT-3 Tokenizer`, but it has been modified to work with the $Falcon$ $7B$ language model. The tokenizer includes a `number of features` that are designed to `improve the performance` of the language model, such as:\n","\n","* $Support$ $Unicode$ $Characters$ - The tokenizer `supports` a wide range of `Unicode characters`, which allows it to handle text in a variety of languages.\n","* $Efficient$ $Tokenization$ - The tokenizer is `designed to be efficient`, so it can be used to tokenize large amounts of text quickly.\n","* $Robust$ $Error$ $Handling$ - The tokenizer `includes a number of features` that help to prevent errors, such as handling invalid characters and out-of-vocabulary words."]},{"cell_type":"code","execution_count":28,"id":"3ba6736c","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-24T10:07:02.973764Z","iopub.status.busy":"2023-07-24T10:07:02.972653Z","iopub.status.idle":"2023-07-24T10:07:05.365295Z","shell.execute_reply":"2023-07-24T10:07:05.364393Z"},"papermill":{"duration":2.426841,"end_time":"2023-07-24T10:07:05.367838","exception":false,"start_time":"2023-07-24T10:07:02.940997","status":"completed"},"tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"929f20f2276347bfa13f0ecf20577fb6","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/220 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef4527c37bc74ad3becea833d813dd88","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)/main/tokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"363502e2fc1444a3b17d01c4e83b43ad","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["falcon_tokenizer = AutoTokenizer.from_pretrained(\"tiiuae/falcon-7b\")"]},{"cell_type":"code","execution_count":29,"id":"ed1e80b9","metadata":{"execution":{"iopub.execute_input":"2023-07-24T10:07:05.432058Z","iopub.status.busy":"2023-07-24T10:07:05.431617Z","iopub.status.idle":"2023-07-24T10:07:05.441372Z","shell.execute_reply":"2023-07-24T10:07:05.440307Z"},"papermill":{"duration":0.04467,"end_time":"2023-07-24T10:07:05.443541","exception":false,"start_time":"2023-07-24T10:07:05.398871","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["{'input_ids': [49366, 100], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["falcon_tokenizer(\"Yayy\")"]},{"cell_type":"markdown","id":"2f0f4acf","metadata":{"papermill":{"duration":0.030538,"end_time":"2023-07-24T10:07:05.504951","exception":false,"start_time":"2023-07-24T10:07:05.474413","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","\n","Now we will do the same thing we did for `Flan T5`"]},{"cell_type":"code","execution_count":30,"id":"fc50cd52","metadata":{"execution":{"iopub.execute_input":"2023-07-24T10:07:05.569019Z","iopub.status.busy":"2023-07-24T10:07:05.568332Z","iopub.status.idle":"2023-07-24T10:07:05.991213Z","shell.execute_reply":"2023-07-24T10:07:05.989885Z"},"papermill":{"duration":0.457698,"end_time":"2023-07-24T10:07:05.99365","exception":false,"start_time":"2023-07-24T10:07:05.535952","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:00<00:00, 488.05it/s]\n"]}],"source":["falcon_7b = pd.DataFrame([0 for _ in range(200)])\n","\n","falcon_7b[\"tokens\"] = ([string_format(idx , tokenizer = falcon_tokenizer) for idx in tqdm.tqdm(range(200) , total = 200)])"]},{"cell_type":"code","execution_count":31,"id":"a6fe792a","metadata":{"execution":{"iopub.execute_input":"2023-07-24T10:07:06.059546Z","iopub.status.busy":"2023-07-24T10:07:06.059161Z","iopub.status.idle":"2023-07-24T10:07:06.064027Z","shell.execute_reply":"2023-07-24T10:07:06.062881Z"},"papermill":{"duration":0.040712,"end_time":"2023-07-24T10:07:06.066151","exception":false,"start_time":"2023-07-24T10:07:06.025439","status":"completed"},"tags":[]},"outputs":[],"source":["os.makedirs(\"/kaggle/working/Kaggle LLMs Embedments/CSV/Falcon 7b/\")"]},{"cell_type":"code","execution_count":32,"id":"c21100b3","metadata":{"execution":{"iopub.execute_input":"2023-07-24T10:07:06.130564Z","iopub.status.busy":"2023-07-24T10:07:06.129837Z","iopub.status.idle":"2023-07-24T10:07:07.47861Z","shell.execute_reply":"2023-07-24T10:07:07.476881Z"},"papermill":{"duration":1.383505,"end_time":"2023-07-24T10:07:07.480968","exception":true,"start_time":"2023-07-24T10:07:06.097463","status":"failed"},"tags":[]},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>falcon_7 = falcon_7b[<span style=\"color: #808000; text-decoration-color: #808000\">\"tokens\"</span>].to_numpy()                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>5 np.save(<span style=\"color: #808000; text-decoration-color: #808000\">\"/kaggle/working/Kaggle LLMs Embedments/Numpy/Falcon 7b/Train Embeds\"</span> , falcon_7     <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">save</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">180</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/numpy/lib/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">npyio.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">518</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">save</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 515 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span>file = os_fspath(file)                                                            <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 516 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> file.endswith(<span style=\"color: #808000; text-decoration-color: #808000\">'.npy'</span>):                                                     <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 517 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span>file = file + <span style=\"color: #808000; text-decoration-color: #808000\">'.npy'</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span> 518 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span>file_ctx = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">open</span>(file, <span style=\"color: #808000; text-decoration-color: #808000\">\"wb\"</span>)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 519 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 520 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> file_ctx <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> fid:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 521 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span>arr = np.asanyarray(arr)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">FileNotFoundError: </span><span style=\"font-weight: bold\">[</span>Errno <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span> No such file or directory: <span style=\"color: #008000; text-decoration-color: #008000\">'/kaggle/working/Kaggle LLMs Embedments/Numpy/Falcon </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">7b/Train Embeds.npy'</span>\n","</pre>\n"],"text/plain":["\u001b[31mâ•­â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â•®\u001b[0m\n","\u001b[31mâ”‚\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m5\u001b[0m                                                                                    \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m3 \u001b[0mfalcon_7 = falcon_7b[\u001b[33m\"\u001b[0m\u001b[33mtokens\u001b[0m\u001b[33m\"\u001b[0m].to_numpy()                                                    \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m4 \u001b[0m                                                                                             \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m5 np.save(\u001b[33m\"\u001b[0m\u001b[33m/kaggle/working/Kaggle LLMs Embedments/Numpy/Falcon 7b/Train Embeds\u001b[0m\u001b[33m\"\u001b[0m , falcon_7     \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m6 \u001b[0m                                                                                             \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m in \u001b[92msave\u001b[0m:\u001b[94m180\u001b[0m                                                                                      \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/numpy/lib/\u001b[0m\u001b[1;33mnpyio.py\u001b[0m:\u001b[94m518\u001b[0m in \u001b[92msave\u001b[0m                           \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m 515 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mfile = os_fspath(file)                                                            \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m 516 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m file.endswith(\u001b[33m'\u001b[0m\u001b[33m.npy\u001b[0m\u001b[33m'\u001b[0m):                                                     \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m 517 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0mfile = file + \u001b[33m'\u001b[0m\u001b[33m.npy\u001b[0m\u001b[33m'\u001b[0m                                                          \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m 518 \u001b[2mâ”‚   â”‚   \u001b[0mfile_ctx = \u001b[96mopen\u001b[0m(file, \u001b[33m\"\u001b[0m\u001b[33mwb\u001b[0m\u001b[33m\"\u001b[0m)                                                       \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m 519 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                                      \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m 520 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mwith\u001b[0m file_ctx \u001b[94mas\u001b[0m fid:                                                                 \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m 521 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0marr = np.asanyarray(arr)                                                          \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n","\u001b[1;91mFileNotFoundError: \u001b[0m\u001b[1m[\u001b[0mErrno \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m No such file or directory: \u001b[32m'/kaggle/working/Kaggle LLMs Embedments/Numpy/Falcon \u001b[0m\n","\u001b[32m7b/Train Embeds.npy'\u001b[0m\n"]},"metadata":{},"output_type":"display_data"}],"source":["falcon_7b.to_csv(\"/kaggle/working/Kaggle LLMs Embedments/CSV/Falcon 7b/Train Embeds\")\n","\n","falcon_7 = falcon_7b[\"tokens\"].to_numpy()\n","\n","np.save(\"/kaggle/working/Kaggle LLMs Embedments/Numpy/Falcon 7b/Train Embeds\" , falcon_7)"]},{"cell_type":"markdown","id":"7ab6c5db","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","## $3.4$ $|$ $RoBERTa$  \n","\n","$RoBERTa$ $Robustly$ $Optimized$ $BERT$ $Pretraining$ $Approach$ is a $Natural$ $Language$ $Processing$ $Model$ that was introduced in the paper **[RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/pdf/1907.11692.pdf)** by `Yinhan Liu` et al. in $2019$. It is based on the $BERT$ $Model$, but it makes a number of modifications to the pretraining procedure that improve its performance.\n","\n","One of the key differences between $RoBERTa$ and $BERT$ is that $RoBERTa$ uses a `larger batch size` and a `higher learning rate` during pretraining. This allows $RoBERTa$ to learn `more effectively` from the training data. Additionally, $RoBERTa$ removes the `next sentence prediction task` from the pretraining procedure. This task was originally used in BERT to help the model learn the relationship between sentences, but $RoBERTa$ found that it was `not necessary` for `good performance`.\n","\n","$RoBERTa$ has been shown to outperform $BERT$ on a number of $Natural$ $Language$ $Processing$ $Tasks$, including \n","* $Question$ $Answering$\n","* $Natural$ $Language$ $Inference$\n","* $Text$ $Summarization$\n","\n","<img src = \"https://www.researchgate.net/publication/352642553/figure/fig2/AS:1037416861282304@1624350862022/The-RoBERTa-model-architecture.ppm\" width = 400>"]},{"cell_type":"code","execution_count":null,"id":"fb5d9b4a","metadata":{"execution":{"iopub.execute_input":"2023-07-15T13:33:33.647152Z","iopub.status.busy":"2023-07-15T13:33:33.646241Z","iopub.status.idle":"2023-07-15T13:33:35.377049Z","shell.execute_reply":"2023-07-15T13:33:35.375814Z","shell.execute_reply.started":"2023-07-15T13:33:33.647091Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"]},{"cell_type":"markdown","id":"c3be4288","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","If we pass a sample text into this like `Donkey on a Horse`"]},{"cell_type":"code","execution_count":null,"id":"d255e191","metadata":{"execution":{"iopub.execute_input":"2023-07-15T13:33:36.208445Z","iopub.status.busy":"2023-07-15T13:33:36.207984Z","iopub.status.idle":"2023-07-15T13:33:36.217793Z","shell.execute_reply":"2023-07-15T13:33:36.216629Z","shell.execute_reply.started":"2023-07-15T13:33:36.208411Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["tokenizer(\"Donkey on a Horse\" , return_tensors = \"pt\")"]},{"cell_type":"markdown","id":"9bdcc573","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","And pass it into the model"]},{"cell_type":"code","execution_count":null,"id":"9385744a","metadata":{"execution":{"iopub.execute_input":"2023-07-15T13:33:37.688931Z","iopub.status.busy":"2023-07-15T13:33:37.687704Z","iopub.status.idle":"2023-07-15T13:33:41.691669Z","shell.execute_reply":"2023-07-15T13:33:41.690423Z","shell.execute_reply.started":"2023-07-15T13:33:37.688877Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["model = AutoModel.from_pretrained(\"roberta-base\")"]},{"cell_type":"code","execution_count":null,"id":"ec762d9c","metadata":{"execution":{"iopub.execute_input":"2023-07-15T13:33:41.694875Z","iopub.status.busy":"2023-07-15T13:33:41.694467Z","iopub.status.idle":"2023-07-15T13:33:41.859085Z","shell.execute_reply":"2023-07-15T13:33:41.858119Z","shell.execute_reply.started":"2023-07-15T13:33:41.69484Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["model(tokenizer(\"Donkey on a Horse\" , return_tensors = \"pt\")[\"input_ids\"])[0] , model(tokenizer(\"Donkey on a Horse\" , return_tensors = \"pt\")[\"input_ids\"])[0].shape"]},{"cell_type":"markdown","id":"e209a1b6","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","We get this \n","\n","But this is in $7$ different dimensions, thus we will apply PCA here to make it right \n","\n","This will take a lot of time thats, why I have already did it before in colab. Here is the code I used \n","\n","```\n","embeds = []\n","pca = PCA(n_components = 1)\n","\n","for index in tqdm.tqdm(range(train.shape[0]) , total = train.shape[0]):\n","\n","    torch.cuda.empty_cache()\n","\n","    stri = \"\"\n","\n","    for columns in [\"prompt\" , \"A\" , \"B\" , \"C\" , \"D\"]:\n","        stri += \"\\n\\n\" + str(train[columns][index])\n","\n","    if len(stri) > tokenizer.model_max_length: stri = stri[:tokenizer.model_max_length]\n","    else:stri += \" \" * (tokenizer.model_max_length - len(stri))\n","\n","    tokens = tokenizer(stri , return_tensors = \"pt\")[\"input_ids\"].to(\"cuda\")\n","    with torch.no_grad():\n","        x = model(input_ids=tokens)[0]\n","    # print(x , x.shape)\n","    x = pca.fit_transform(x.cpu().detach().numpy().squeeze().T).squeeze()\n","\n","    torch.cuda.empty_cache()\n","\n","    embeds.append(x)\n","```"]},{"cell_type":"code","execution_count":null,"id":"ca71c3bf","metadata":{"execution":{"iopub.execute_input":"2023-07-14T18:59:09.108639Z","iopub.status.busy":"2023-07-14T18:59:09.108209Z","iopub.status.idle":"2023-07-14T18:59:09.116247Z","shell.execute_reply":"2023-07-14T18:59:09.115426Z","shell.execute_reply.started":"2023-07-14T18:59:09.108606Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["os.makedirs(\"/kaggle/working/Robert A\")\n","np.save(\"/kaggle/working/Robert A/Train Embeds\" , np.load(\"/kaggle/input/kaggle-llm-robert-a/Roberta Train Embeds (1).npy\"))"]},{"cell_type":"markdown","id":"331046bc","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","## $3.5$ $|$ $DeBERTa$\n","    \n","$Decoding-Enhanced$ $BERT$ with $Disentangled$ $Attention$ $(DeBERTa)$ is a $Transformer-Based$ $Neural$ $Language$ $Model$ that was proposed in $2020$. It builds on the $BERT$ and $RoBERTa$ models, but it introduces two novel techniques: \n","* $Disentangled$ $Dttention$ - `Representing` each `word` in a `sentence` using two vectors\n","* * One that `encodes` the `content` of the word, \n","* * One that `encodes` the `position` of the word in the sentence.\n","This allows the `model to focus on different aspects` of the sentence when computing attention weights.\n","* $Enhanced$ $Mask$ $Decoder$ - `Predicting` the `masked tokens` in the `model pre-training process`. The enhanced mask decoder `incorporates absolute positions` in the decoding layer, which helps the model to `better understand` the `context of the masked tokens`.\n","\n","<img src = \"https://production-media.paperswithcode.com/methods/cdd53959-f9f1-4f79-b604-3f531e431abd.png\" width = 400>"]},{"cell_type":"code","execution_count":null,"id":"c524ae82","metadata":{"execution":{"iopub.execute_input":"2023-07-15T16:19:40.525959Z","iopub.status.busy":"2023-07-15T16:19:40.525614Z","iopub.status.idle":"2023-07-15T16:19:42.351521Z","shell.execute_reply":"2023-07-15T16:19:42.350762Z","shell.execute_reply.started":"2023-07-15T16:19:40.525932Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")"]},{"cell_type":"code","execution_count":null,"id":"c41cbb49","metadata":{"execution":{"iopub.execute_input":"2023-07-15T16:19:53.471053Z","iopub.status.busy":"2023-07-15T16:19:53.470702Z","iopub.status.idle":"2023-07-15T16:19:53.525987Z","shell.execute_reply":"2023-07-15T16:19:53.525037Z","shell.execute_reply.started":"2023-07-15T16:19:53.471028Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["tokenizer(\"If dreams ask for a price to come true, pay the price by staying awake at night.\" , return_tensors = \"pt\")"]},{"cell_type":"code","execution_count":null,"id":"b5448cd1","metadata":{"execution":{"iopub.execute_input":"2023-07-15T16:20:02.712854Z","iopub.status.busy":"2023-07-15T16:20:02.712486Z","iopub.status.idle":"2023-07-15T16:20:06.163481Z","shell.execute_reply":"2023-07-15T16:20:06.162171Z","shell.execute_reply.started":"2023-07-15T16:20:02.712819Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["model = AutoModel.from_pretrained(\"microsoft/deberta-base\")"]},{"cell_type":"code","execution_count":null,"id":"c25efe1f","metadata":{"execution":{"iopub.execute_input":"2023-07-15T16:20:12.578238Z","iopub.status.busy":"2023-07-15T16:20:12.575464Z","iopub.status.idle":"2023-07-15T16:20:13.103907Z","shell.execute_reply":"2023-07-15T16:20:13.103293Z","shell.execute_reply.started":"2023-07-15T16:20:12.578171Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["model(tokenizer(\"If dreams ask for a price to come true, pay the price by staying awake at night.\" , return_tensors = \"pt\")[\"input_ids\"])[0] , model(tokenizer(\"If dreams ask for a price to come true, pay the price by staying awake at night.\" , return_tensors = \"pt\")[\"input_ids\"])[0].shape"]},{"cell_type":"markdown","id":"d41fbed7","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","As we can see this is of shape $(21 , 768)$. \n","\n","These are all similar values and thus we can make them at one axis using $PCA$\n","    \n","I am not using `Kaggle GPUs` at this moment. I have imported the Embeddings from colab. Here is the code I used. The lengths are truncated to 512 for this moment \n","\n","```\n","import numpy as np \n","import tqdm\n","from sklearn.decomposition import PCA\n","from transformers import AutoTokenizer, DebertaModel\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")\n","model = DebertaModel.from_pretrained(\"microsoft/deberta-base\").to(\"cuda\")\n","\n","pca = PCA(n_components = 1)\n","\n","embeds = []\n","\n","for index in tqdm.tqdm(range(train.shape[0]) , total = train.shape[0]):\n","\n","    torch.cuda.empty_cache()\n","    \n","    stri = \"\"\n","    \n","    for columns in [\"prompt\" , \"A\" , \"B\" , \"C\" , \"D\" , \"E\"]: stri += \"\\n\\n\" + str(train[columns][index])\n","    \n","    if len(stri) > tokenizer.model_max_length: stri = stri[:tokenizer.model_max_length]\n","    else:stri += \" \" * (tokenizer.model_max_length - len(stri))\n","\n","    tokens = tokenizer(stri , return_tensors = \"pt\")[\"input_ids\"].to(\"cuda\")\n","    \n","    with torch.no_grad():x = model(input_ids=tokens)[0]\n"," \n","    x = pca.fit_transform(x.cpu().detach().numpy().squeeze().T).squeeze()\n","\n","    torch.cuda.empty_cache()\n","\n","    embeds.append(x)\n","```"]},{"cell_type":"code","execution_count":null,"id":"4b71214a","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["os.makedirs(\"/kaggle/working/Deberta\")\n","np.save(\"/kaggle/working/Deberta/Train Embeds\" , np.load(\"/kaggle/input/kaggle-llm-robert-a/Deberta Train Embeds (1).npy\"))"]},{"cell_type":"markdown","id":"91ae562e","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","## $3.6$ $|$ $AlBERT$\n","    \n","$A$ $Lite$ $BERT$ $(ALBERT)$ is a model for $Self-Supervised$ $Learning$ of $Language$ $Rrepresentations$. It was proposed in the paper **[ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](https://arxiv.org/pdf/1909.11942.pdf)** by `Zhenzhong Lan`/`Mingda Chen`/`Sebastian Goodman`/`Kevin Gimpel`/`Piyush Sharma`/`Radu Soricut`\n","\n","$ALBERT$ is a simplified version of $BERT$ that has `fewer parameters` and is therefore faster to `Train`/`Deploy`. It achieves this by using two parameter-reduction techniques:\n","\n","* $Factorizing$ the $Embedding$ $Matrix$ - The `Embedding Matrix` in $BERT$ is a `large matrix` that `maps words` to `vectors`. $ALBERT$ factors this `matrix` into two `smaller matrices`, one for the `first half` of the `vocabulary` and one for the `second half`. This `reduces` the number of `parameters` in the embedding matrix by `half`.\n","* $Repeating$ $Layers$ - $ALBERT$ uses `Repeating Layers`, which means that `each layer is applied twice`. This allows $ALBERT$ to achieve the same performance as $BERT$ with `Fewer Parameters`."]},{"cell_type":"code","execution_count":null,"id":"0c47ab69","metadata":{"execution":{"iopub.execute_input":"2023-07-16T05:26:43.872472Z","iopub.status.busy":"2023-07-16T05:26:43.872056Z","iopub.status.idle":"2023-07-16T05:27:01.615924Z","shell.execute_reply":"2023-07-16T05:27:01.614783Z","shell.execute_reply.started":"2023-07-16T05:26:43.872439Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained('albert-xxlarge-v2')\n","model = AutoModel.from_pretrained(\"albert-xxlarge-v2\")"]},{"cell_type":"markdown","id":"9dc29695","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","If we pass a sample text like `Save Version`"]},{"cell_type":"code","execution_count":null,"id":"cbf3cf30","metadata":{"execution":{"iopub.execute_input":"2023-07-16T05:28:13.224927Z","iopub.status.busy":"2023-07-16T05:28:13.224475Z","iopub.status.idle":"2023-07-16T05:28:13.236525Z","shell.execute_reply":"2023-07-16T05:28:13.234751Z","shell.execute_reply.started":"2023-07-16T05:28:13.224892Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["tokenizer(\"Save Version\" , return_tensors = \"tf\")"]},{"cell_type":"code","execution_count":null,"id":"3eabff34","metadata":{"execution":{"iopub.execute_input":"2023-07-16T05:29:23.147562Z","iopub.status.busy":"2023-07-16T05:29:23.147167Z","iopub.status.idle":"2023-07-16T05:29:26.424356Z","shell.execute_reply":"2023-07-16T05:29:26.422943Z","shell.execute_reply.started":"2023-07-16T05:29:23.147532Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["model(tokenizer(\"Save Version\" , return_tensors = \"tf\")[\"input_ids\"])[0][0][0] , model(tokenizer(\"Save Version\" , return_tensors = \"tf\")[\"input_ids\"])[0][0][0].shape"]},{"cell_type":"markdown","id":"079ad356","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","   \n","I am not using `Kaggle GPUs` at this moment. I have imported the Embeddings from colab. Here is the code I used. The lengths are truncated to 512 for this moment \n","\n","```\n","import numpy as np \n","import tqdm\n","import sentencepiece\n","from transformers import AlbertTokenizer, TFAlbertModel\n","\n","tokenizer = AlbertTokenizer.from_pretrained('albert-xxlarge-v2')\n","model = TFAlbertModel.from_pretrained(\"albert-xxlarge-v2\")\n","\n","embeds = []\n","\n","for index in tqdm.tqdm(range(train.shape[0]) , total = train.shape[0]):\n","\n","    torch.cuda.empty_cache()\n","\n","    stri = \"\"\n","\n","    for columns in [\"prompt\" , \"A\" , \"B\" , \"C\" , \"D\" , \"E\"]: stri += \"\\n\\n\" + str(train[columns][index])\n","\n","    tokens = tokenizer(stri , return_tensors = \"tf\")[\"input_ids\"]\n","\n","    with torch.no_grad():x = model(input_ids=tokens)[0][0][0]\n","    \n","    torch.cuda.empty_cache()\n","\n","    embeds.append(x)\n","```\n"]},{"cell_type":"code","execution_count":null,"id":"203d81f9","metadata":{"execution":{"iopub.execute_input":"2023-07-16T05:33:22.53118Z","iopub.status.busy":"2023-07-16T05:33:22.530773Z","iopub.status.idle":"2023-07-16T05:33:22.574968Z","shell.execute_reply":"2023-07-16T05:33:22.57361Z","shell.execute_reply.started":"2023-07-16T05:33:22.531149Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["os.makedirs(\"/kaggle/working/Alberta\")\n","np.save(\"/kaggle/working/Alberta/Train Embeds\" , \n","        np.load(\"/kaggle/input/kaggle-llm-robert-a/AlBERT Train Embeds.npy\"))"]},{"cell_type":"markdown","id":"95f328a5","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","## $3.7$ $|$ $ELECTRA$\n","    \n","$Efficiently$ $Learning$ an $Encoder$ that $Classifies$ $Token$ $Replacements$ $Accurately$ $(ELECTRA)$ is a new `Pre-Training` approach for `Natural Language Processing` `(NLP)` tasks. It is based on the idea of `replacing some tokens` in a sequence with `plausible alternatives`, and then `training a model` to `distinguish between` the `original tokens` and the `replacements`. This approach is more `sample-efficient` than `masked language modeling` $(MLM)$, which is the pre-training method used by BERT and other popular NLP models.\n","\n","ELECTRA consists of two main components\n","* $Generator$ - A small language model that is used to `generate plausible replacements` for tokens in a sequence\n","* $Discriminator$ - A larger language model that is used to `distinguish between the original tokens and the replacements`."]},{"cell_type":"code","execution_count":null,"id":"eb9b3ea6","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"google/electra-small-discriminator\")"]},{"cell_type":"markdown","id":"fc6ac5f5","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Lets assume we have this sentence `Dhoni is faster than cheetah, while running between the wickets`"]},{"cell_type":"code","execution_count":null,"id":"fff02aaa","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["tokenizer(\"Dhoni is faster than cheetah , while running between the wickets\")"]},{"cell_type":"markdown","id":"9235b3a4","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","These tokens can be further passed to models to get embeddings"]},{"cell_type":"code","execution_count":null,"id":"2f4276bd","metadata":{"_kg_hide-output":true,"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["model = AutoModel.from_pretrained(\"google/electra-small-discriminator\")"]},{"cell_type":"code","execution_count":null,"id":"500dbd66","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["model(tokenizer(\"Dhoni is faster than cheetah , while running between the wickets\" , return_tensors = \"pt\")[\"input_ids\"])[0] , model(tokenizer(\"Dhoni is faster than cheetah , while running between the wickets\" , return_tensors = \"pt\")[\"input_ids\"])[0].shape"]},{"cell_type":"markdown","id":"d5dee0c1","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","\n","As we can see this is of shape $(16 , 256)$. \n","\n","These are all similar values and thus we can make them at one axis using $PCA$\n","    \n","I am not using `Kaggle GPUs` at this moment. I have imported the Embeddings from colab. Here is the code I used. The lengths are truncated to 512 for this moment \n","\n","```\n","import numpy as np \n","import tqdm\n","from sklearn.decomposition import PCA\n","from transformers import AutoTokenizer, ElectraModel\n","\n","train_pro = pd.read_csv(\"/content/train.csv\")\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"google/electra-small-discriminator\")\n","model = ElectraModel.from_pretrained(\"google/electra-small-discriminator\").to(\"cuda\")\n","\n","pca = PCA(n_components = 1)\n","\n","embeds = []\n","\n","for index in tqdm.tqdm(range(train.shape[0]) , total = train.shape[0]):\n","\n","    torch.cuda.empty_cache()\n","    \n","    stri = \"\"\n","    \n","    for columns in [\"prompt_question\" , \"prompt\" , \"A\" , \"B\" , \"C\" , \"D\" , \"E\"]: stri += \"\\n\\n\" + str(train[columns][index])\n","    \n","    if len(stri) > tokenizer.model_max_length: stri = stri[:tokenizer.model_max_length]\n","    else:stri += \" \" * (tokenizer.model_max_length - len(stri))\n","\n","    tokens = tokenizer(stri , return_tensors = \"pt\")[\"input_ids\"].to(\"cuda\")\n","    \n","    with torch.no_grad():x = model(input_ids=tokens)[0]\n"," \n","    x = pca.fit_transform(x.cpu().detach().numpy().squeeze().T).squeeze()\n","\n","    torch.cuda.empty_cache()\n","\n","    embeds.append(x)\n","```"]},{"cell_type":"code","execution_count":null,"id":"62bf3967","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["os.makedirs(\"/kaggle/working/Electra/\")\n","np.save(\"/kaggle/working/Electra/Electra Embeds\" , np.load(\"/kaggle/input/kaggle-llm-robert-a/Electra Embeds (1).npy\"))"]},{"cell_type":"markdown","id":"083d44c8","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","## $3.8$ $|$ $RoBERTa$ $Large$\n","    \n","$RoBERTa$ $Large$ is a $Large$ $Language$ $Model$ $(LLM)$ that was `pretrained` on a `massive dataset` of `text and code`. It is a `variant` of the $Transformer$ $Architecture$, which is a $Neural$ $Network$ $Architecture$ that is `particularly well-suited` for `natural language processing` tasks. $RoBERTa$ $Large$ was trained on a `dataset` of $1.56TB$ of text and code, and it has $350$ $Million$ $Parameters$. This makes it one of the `largest` and `most powerful` $LLMs$ that is currently available.\n","\n","RoBERTa Large can be used for a variety of natural language processing tasks, including:\n","\n","* $Question$ $Answering$\n","* $Natural$ $Language$ $Inference$\n","* $Text$ $Summarization$\n","* $Machine$ $Translation$\n","* $Text$ $Generation$"]},{"cell_type":"code","execution_count":null,"id":"4bf1a544","metadata":{"execution":{"iopub.execute_input":"2023-07-20T15:01:09.091946Z","iopub.status.busy":"2023-07-20T15:01:09.091489Z","iopub.status.idle":"2023-07-20T15:01:10.38287Z","shell.execute_reply":"2023-07-20T15:01:10.381444Z","shell.execute_reply.started":"2023-07-20T15:01:09.091897Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained('roberta-large')"]},{"cell_type":"markdown","id":"d55d3486","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","Lets assume we have a sentence like \n","```\n","A Strange Story of Wonderful Love\n","```"]},{"cell_type":"code","execution_count":null,"id":"38e60bf9","metadata":{"execution":{"iopub.execute_input":"2023-07-20T15:06:28.826281Z","iopub.status.busy":"2023-07-20T15:06:28.825807Z","iopub.status.idle":"2023-07-20T15:06:28.838482Z","shell.execute_reply":"2023-07-20T15:06:28.837181Z","shell.execute_reply.started":"2023-07-20T15:06:28.826247Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["tokenizer(\"A Strange Story of Wonderful Love\" , return_tensors = \"pt\")"]},{"cell_type":"markdown","id":"7f97b825","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","If we send thsi to or model we get a vector of $1,024$ Size "]},{"cell_type":"code","execution_count":null,"id":"46d5f45d","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-20T15:04:43.315515Z","iopub.status.busy":"2023-07-20T15:04:43.315013Z","iopub.status.idle":"2023-07-20T15:04:55.727024Z","shell.execute_reply":"2023-07-20T15:04:55.725782Z","shell.execute_reply.started":"2023-07-20T15:04:43.31548Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["model = RobertaModel.from_pretrained('roberta-large')"]},{"cell_type":"code","execution_count":null,"id":"324c12c3","metadata":{"execution":{"iopub.execute_input":"2023-07-20T15:07:39.200185Z","iopub.status.busy":"2023-07-20T15:07:39.199749Z","iopub.status.idle":"2023-07-20T15:07:39.488184Z","shell.execute_reply":"2023-07-20T15:07:39.486904Z","shell.execute_reply.started":"2023-07-20T15:07:39.200154Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["model(tokenizer(\"A Strange Story of Wonderful Love\" , return_tensors = \"pt\")[\"input_ids\"])[0]"]},{"cell_type":"markdown","id":"5f4addea","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF595E solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","We will pass these to PCA to extract more contextual knowledge"]},{"cell_type":"code","execution_count":null,"id":"6dd4bbf8","metadata":{"execution":{"iopub.execute_input":"2023-07-20T15:09:53.69106Z","iopub.status.busy":"2023-07-20T15:09:53.690547Z","iopub.status.idle":"2023-07-20T15:09:54.171476Z","shell.execute_reply":"2023-07-20T15:09:54.169793Z","shell.execute_reply.started":"2023-07-20T15:09:53.691024Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"source":["os.makedirs(\"/kaggle/working/RoBERTa Large\")\n","\n","np.save(\"/kaggle/working/RoBERTa Large/Embeds\" , np.load(\"/kaggle/input/kaggle-llm-robert-a/Roberta Large Embeds.npy\" , allow_pickle = True))"]},{"cell_type":"markdown","id":"dcb008c1","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#964B00; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #964B00\">3 | TO DO LIST ğŸ“</p>\n","\n","<div style=\"border-radius:10px; border:#F2E9DA solid; padding: 15px; background-color: #F2E9DA; font-size:100%; text-align:left\">\n","\n","* TO DO 1 : VISUALIZE THE DATA \n","\n","* TO DO 2 : EXPLORE THE DATA\n","\n","* TO DO 3 : TOKENIZE THE DATA \n","\n","* TO DO 4 : MAKE A NPY TOKENIZED FILE\n","\n","* TO DO 5 : TRAIN A MODEL\n","\n","* TO DO 6 : WANDB SUPPORT\n","\n","* TO DO 7 : BETTER RESULTS\n","\n","* TO DO 8 : LESS TRAINING TIME\n","\n","* TO DO 9 : DANCE"]},{"cell_type":"markdown","id":"cc9a2dc8","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#800080; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #800080\">5 | Ending ğŸš€</p>\n","\n","<div style=\"border-radius:10px; border:#C264FF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","\n","**THAT IT FOR TODAY GUYS**\n","\n","**WE WILL GO DEEPER INTO THE DATA IN THE UPCOMING VERSIONS**\n","\n","**PLEASE COMMENT YOUR THOUGHTS, HIHGLY APPRICIATED**\n","\n","**DONT FORGET TO MAKE AN UPVOTE, IF YOU LIKED MY WORK $:)$**\n"," \n","<IMG SRC = \"htTps://i.imgflip.com/19aadg.jpg\">\n","    \n","**PEACE OUT $!!!$**"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":189.966295,"end_time":"2023-07-24T10:07:11.026541","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-07-24T10:04:01.060246","version":"2.4.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"03d28e9fcf284466b8bdc756ed1a82bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e949073a9f64c3380e163d4d45a8c05":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fb2f2a5d30b4cd2829816a8a408859b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5aa4b2ed927248b5bee3416dfe65d417","placeholder":"â€‹","style":"IPY_MODEL_42a601d2dc2841c988590d7a2b8eaac9","value":" 281/281 [00:00&lt;00:00, 21.3kB/s]"}},"15c9274c25654c6eac0bb81e017fd744":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae26895aee9e4bf09b7e341d46f98ba0","max":2734130.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_2f5b743458c440839c2f28508d5b2545","value":2734130.0}},"160cb0283741480193c43bb216382ea4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1914847870164b1690ff272d544978a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a8d690afa634f07b24d4c19f17f1bd3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b2fea9847b442deac14db912357144f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e7d81876a854e73882491a91c4c11af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21b32f86e62d4339b9600368b58eb84f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2248f9f9491946a79acaaa2a840ca0c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_36359d5365244f42b510d8b123f83225","IPY_MODEL_2f45807d530d4dc6803f806cbb4a64ba","IPY_MODEL_91cf34d6ffe84edeb30706a5271a68b6"],"layout":"IPY_MODEL_ef9a9c57e6004fc0ab3d51939c28fd03"}},"2720c0ebabbc466f98043d9ac3322d1d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"279d027b99ee4d2c9d2f3948bd445259":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"27ac51edeb1b480395064e4369afb59f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a741c2359794768bfb1cbab33431531":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_160cb0283741480193c43bb216382ea4","placeholder":"â€‹","style":"IPY_MODEL_bba9b8b931c140a08f32586946e117be","value":"Downloading (â€¦)cial_tokens_map.json: 100%"}},"2c67400fb47345a38b77999ac51b368f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d81d0b5c1504387ad1bd4b345432b87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb43f281d4f2402093181265cd4f2b2e","placeholder":"â€‹","style":"IPY_MODEL_ce584d7bd01e4e8ca3ce1eb4fe8d2d55","value":" 29.0/29.0 [00:00&lt;00:00, 1.73kB/s]"}},"2f45807d530d4dc6803f806cbb4a64ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2720c0ebabbc466f98043d9ac3322d1d","max":213450.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_82cefd554b2f41469aa8c0fcaebb1cde","value":213450.0}},"2f5b743458c440839c2f28508d5b2545":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"30f9db1287ab41e8a9eea54994555b89":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"343e703f91774bc09ec4df96755807f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbc1c3fd50614f2d8d0e91e1573af6fb","placeholder":"â€‹","style":"IPY_MODEL_5426ebbe89e94ddcb3f988bd5e7f891f","value":" 220/220 [00:00&lt;00:00, 14.7kB/s]"}},"363502e2fc1444a3b17d01c4e83b43ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2a741c2359794768bfb1cbab33431531","IPY_MODEL_b3cb34eeb4c44907ab08c00378868878","IPY_MODEL_0fb2f2a5d30b4cd2829816a8a408859b"],"layout":"IPY_MODEL_8b0638e44c0d46ac9b04e3adc0cb5bee"}},"36359d5365244f42b510d8b123f83225":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6ac9d29c1b24777bc27fcb0e098f684","placeholder":"â€‹","style":"IPY_MODEL_1a8d690afa634f07b24d4c19f17f1bd3","value":"Downloading (â€¦)solve/main/vocab.txt: 100%"}},"40a0f41c6eeb40cdaf5233207ccf1c5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d4f86e93d54a4b1898f4b863a4aab09d","IPY_MODEL_a56226142db846fcad092e4fb14d0797","IPY_MODEL_2d81d0b5c1504387ad1bd4b345432b87"],"layout":"IPY_MODEL_51954f2363654ec18ea473ae145873c1"}},"42a601d2dc2841c988590d7a2b8eaac9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4958bdae4a464c4e9f0cf526b544d776":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e949073a9f64c3380e163d4d45a8c05","max":570.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_7c8d05bec11b4eeebd0b8e2d9d7283d5","value":570.0}},"4e16f20101344f1aaf2efa26d13f9a16":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5dadc06e87ad42c2b3c46b7600f04085","placeholder":"â€‹","style":"IPY_MODEL_03d28e9fcf284466b8bdc756ed1a82bc","value":" 2.73M/2.73M [00:00&lt;00:00, 3.95MB/s]"}},"4f9eec1cac00479c9bf0d8722265e60c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51954f2363654ec18ea473ae145873c1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5426ebbe89e94ddcb3f988bd5e7f891f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5925ed823643437d9a4380f4a20f65dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df093a2990244e9dbd10ef70df4550a7","placeholder":"â€‹","style":"IPY_MODEL_ae70fec3bc3b46028d6c1eb4421afeea","value":"Downloading model.safetensors: 100%"}},"5970c5bea5e94c6584822fc5be6ae51c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5aa4b2ed927248b5bee3416dfe65d417":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bcf316e43894e93bd2010d24fb6108f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7c77e2eff52d441a884168c147eff4cc","IPY_MODEL_eb4fa343cf844befa411a03d6674d565","IPY_MODEL_60ebc09de6a14154ab8a3627e9fc7a0d"],"layout":"IPY_MODEL_b1901964087c4e27b87539cd1019d929"}},"5dadc06e87ad42c2b3c46b7600f04085":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60ebc09de6a14154ab8a3627e9fc7a0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0879a1c09e149c9a176d3ef4ee91eb3","placeholder":"â€‹","style":"IPY_MODEL_1e7d81876a854e73882491a91c4c11af","value":" 436k/436k [00:00&lt;00:00, 2.51MB/s]"}},"66c4c8ab0d7d46a996a12910738cac4a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf83ddbf720d4dc595049affb2206483","max":220.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_279d027b99ee4d2c9d2f3948bd445259","value":220.0}},"68e4cc0c90ab40da9368af8658359288":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d5ebbcad7374228a978163df6c75bd7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e5ee9b6e8014b38b11cd299ab95aa61":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_27ac51edeb1b480395064e4369afb59f","max":435755784.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_f3175775e77a49068173a1a8d4615417","value":435755784.0}},"75e4d9d902b0461f9f35c3198dc583a4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c77e2eff52d441a884168c147eff4cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30f9db1287ab41e8a9eea54994555b89","placeholder":"â€‹","style":"IPY_MODEL_2c67400fb47345a38b77999ac51b368f","value":"Downloading (â€¦)/main/tokenizer.json: 100%"}},"7c8d05bec11b4eeebd0b8e2d9d7283d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"82cefd554b2f41469aa8c0fcaebb1cde":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"889c733cf2e54116803e91154b081205":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a0f80e8c1144c4986413461d490e199":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8b0638e44c0d46ac9b04e3adc0cb5bee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8df18e4c02e74230a581ecbf5570f85e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8efe41f4a85a4aedb8b33c09a82a264e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"91cf34d6ffe84edeb30706a5271a68b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8df18e4c02e74230a581ecbf5570f85e","placeholder":"â€‹","style":"IPY_MODEL_c0d0eb26c82a48f5b3ff4402d2eae8d4","value":" 213k/213k [00:00&lt;00:00, 620kB/s]"}},"9288e428c4d4406aa46f12d5c4975c44":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"929f20f2276347bfa13f0ecf20577fb6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7069fb2e30a411fb132ccc72ddd7677","IPY_MODEL_66c4c8ab0d7d46a996a12910738cac4a","IPY_MODEL_343e703f91774bc09ec4df96755807f8"],"layout":"IPY_MODEL_dfa1ac2395bc42ff9f92a24a1eb1c3b9"}},"a0879a1c09e149c9a176d3ef4ee91eb3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1816db2b6e8470f9a4311c4a59b1e64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a56226142db846fcad092e4fb14d0797":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b19a77a12d634bd78721d8d18c7e56ca","max":29.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_1b2fea9847b442deac14db912357144f","value":29.0}},"a577812304844a60bf850e2e52d444d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8d99be038474ba6889744ffb7e49622","placeholder":"â€‹","style":"IPY_MODEL_a1816db2b6e8470f9a4311c4a59b1e64","value":" 570/570 [00:00&lt;00:00, 35.1kB/s]"}},"a6707ee738694a15926cf34dc56ba69d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75e4d9d902b0461f9f35c3198dc583a4","placeholder":"â€‹","style":"IPY_MODEL_c8a79f3778f24fc3912cc4d08d4d4670","value":"Downloading (â€¦)/main/tokenizer.json: 100%"}},"a7565d05917145ee935bd89eab321eed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec092da47b8d4f1aaf2f1c71dc25a063","placeholder":"â€‹","style":"IPY_MODEL_6d5ebbcad7374228a978163df6c75bd7","value":"Downloading (â€¦)lve/main/config.json: 100%"}},"adf4b606138046df8b59fb850ebafe5a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1914847870164b1690ff272d544978a5","placeholder":"â€‹","style":"IPY_MODEL_d0761a15b6474e8aad5ba7aee372200b","value":" 436M/436M [00:06&lt;00:00, 69.2MB/s]"}},"ae26895aee9e4bf09b7e341d46f98ba0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae70fec3bc3b46028d6c1eb4421afeea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1901964087c4e27b87539cd1019d929":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b19a77a12d634bd78721d8d18c7e56ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3cb34eeb4c44907ab08c00378868878":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_889c733cf2e54116803e91154b081205","max":281.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_8efe41f4a85a4aedb8b33c09a82a264e","value":281.0}},"b6ac9d29c1b24777bc27fcb0e098f684":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b798ceca05004e91913273b8df3956e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a7565d05917145ee935bd89eab321eed","IPY_MODEL_4958bdae4a464c4e9f0cf526b544d776","IPY_MODEL_a577812304844a60bf850e2e52d444d5"],"layout":"IPY_MODEL_68e4cc0c90ab40da9368af8658359288"}},"b8501b94f3734c48946e5527764e50da":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb43f281d4f2402093181265cd4f2b2e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bba9b8b931c140a08f32586946e117be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bcbd9ae3d0c94690bcaf48acb3c6b065":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf83ddbf720d4dc595049affb2206483":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0d0eb26c82a48f5b3ff4402d2eae8d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c41102a366584b188d6c684766876b88":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5925ed823643437d9a4380f4a20f65dd","IPY_MODEL_6e5ee9b6e8014b38b11cd299ab95aa61","IPY_MODEL_adf4b606138046df8b59fb850ebafe5a"],"layout":"IPY_MODEL_bcbd9ae3d0c94690bcaf48acb3c6b065"}},"c8a79f3778f24fc3912cc4d08d4d4670":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce584d7bd01e4e8ca3ce1eb4fe8d2d55":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0761a15b6474e8aad5ba7aee372200b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d4f86e93d54a4b1898f4b863a4aab09d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21b32f86e62d4339b9600368b58eb84f","placeholder":"â€‹","style":"IPY_MODEL_dd7ec9c91c2c483e99ecd670ae5ba6f8","value":"Downloading (â€¦)okenizer_config.json: 100%"}},"dbc1c3fd50614f2d8d0e91e1573af6fb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd7ec9c91c2c483e99ecd670ae5ba6f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df093a2990244e9dbd10ef70df4550a7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfa1ac2395bc42ff9f92a24a1eb1c3b9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7069fb2e30a411fb132ccc72ddd7677":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9288e428c4d4406aa46f12d5c4975c44","placeholder":"â€‹","style":"IPY_MODEL_4f9eec1cac00479c9bf0d8722265e60c","value":"Downloading (â€¦)okenizer_config.json: 100%"}},"e8d99be038474ba6889744ffb7e49622":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb4fa343cf844befa411a03d6674d565":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5970c5bea5e94c6584822fc5be6ae51c","max":435797.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_8a0f80e8c1144c4986413461d490e199","value":435797.0}},"ec092da47b8d4f1aaf2f1c71dc25a063":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef4527c37bc74ad3becea833d813dd88":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a6707ee738694a15926cf34dc56ba69d","IPY_MODEL_15c9274c25654c6eac0bb81e017fd744","IPY_MODEL_4e16f20101344f1aaf2efa26d13f9a16"],"layout":"IPY_MODEL_b8501b94f3734c48946e5527764e50da"}},"ef9a9c57e6004fc0ab3d51939c28fd03":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3175775e77a49068173a1a8d4615417":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":5}
