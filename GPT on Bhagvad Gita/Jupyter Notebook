{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ayushs9020/inventing-bert-from-scratch?scriptVersionId=132484876\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"be824c0b","metadata":{"papermill":{"duration":0.018724,"end_time":"2023-06-06T08:29:21.766962","exception":false,"start_time":"2023-06-06T08:29:21.748238","status":"completed"},"tags":[]},"source":["# 2023 Kaggle AI Report\n","\n","<img src = \"https://i.chzbgr.com/full/9274249984/hC9529C78/grew-up-sarcastic-above-a-pic-of-bert-saying-ernie-how-do-i-look-ernie-replies-with-your-eyes-bert\" width = 400px>\n","\n","The $2023$ $Kaggle$ $AI$ $Report$ is an `analytics competition` that invites participants to `write essays on the state of machine learning in 2023`. The essays should describe `what the community has learned over the past 2 years of working and experimenting` with one of the following seven topics:\n","\n","* $Text$\n","* $Image$\n","* $Video$ \n","* $Data$\n","* $Tabular$\n","* $Time$ $Series$\n","* $Kaggle$ $Competitions$\n","* $Generative$ $AI$\n","* $AI$ $Ethics$\n","\n","The essays `should be well-written and informative`, and they `should provide a comprehensive overview of the state of machine learning` in $2023$. The top essays will be `published in the 2023 Kaggle AI Report`, which will be a `valuable resource for anyone who is interested in learning more about the state of machine learning`.\n","\n","Here are some additional details about the competition:\n","\n","|_____|_____|\n","|---|---\n","|Prizes| \n","||$$$10,000$$\n","||$$$5,000$$\n","||$$$2,500$$\n","|Submission deadline|The deadline for submissions is $June$ $1,$ $2023$.\n","|Submission format|Essays should be submitted as a `PDF file`.\n","|Length|Essays should be no more than $2,500$ words in length.\n","|Judging criteria|Clarity\n","||Organization\n","||Accuracy\n","||Completeness\n","||Originality \n","||Creativity\n","\n","## BERT \n","\n","$BERT$ stands for $Bidirectional$ $Encoder$ $Representations$ from $Transformers$. It is a `language model` that was developed by $Google$ $AI$ in $2018$. $BERT$ is `trained on a massive dataset of text and code`. It can be used for a variety of natural language processing tasks, such as \n","* $Question$ $Answering$ \n","* $Sentiment$ $Analysis$\n","* $Natural$ $Language$ $Inference$.\n","\n","# 1 | Data 🚀\n","\n","Lets get our data into working "]},{"cell_type":"code","execution_count":1,"id":"6302849d","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-06-06T08:29:21.806014Z","iopub.status.busy":"2023-06-06T08:29:21.805315Z","iopub.status.idle":"2023-06-06T08:29:21.819814Z","shell.execute_reply":"2023-06-06T08:29:21.818267Z"},"papermill":{"duration":0.036457,"end_time":"2023-06-06T08:29:21.822082","exception":false,"start_time":"2023-06-06T08:29:21.785625","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/2023-kaggle-ai-report/sample_submission.csv\n","/kaggle/input/2023-kaggle-ai-report/arxiv_metadata_20230510.json\n","/kaggle/input/2023-kaggle-ai-report/kaggle_writeups_20230510.csv\n"]}],"source":["import pandas as pd \n","import numpy as np\n","\n","import re\n","import tqdm\n","\n","from pathlib import Path\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","execution_count":2,"id":"fa0c8792","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:21.86272Z","iopub.status.busy":"2023-06-06T08:29:21.862315Z","iopub.status.idle":"2023-06-06T08:29:22.326531Z","shell.execute_reply":"2023-06-06T08:29:22.325354Z"},"papermill":{"duration":0.487726,"end_time":"2023-06-06T08:29:22.329277","exception":false,"start_time":"2023-06-06T08:29:21.841551","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Competition Launch Date</th>\n","      <th>Title of Competition</th>\n","      <th>Competition URL</th>\n","      <th>Date of Writeup</th>\n","      <th>Title of Writeup</th>\n","      <th>Writeup</th>\n","      <th>Writeup URL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>08/03/2010 00:00:00</td>\n","      <td>Chess ratings - Elo versus the Rest of the World</td>\n","      <td>https://www.kaggle.com/c/2447</td>\n","      <td>11/18/2010 00:06:46</td>\n","      <td>Released: my Source Code and Analysis</td>\n","      <td>&lt;p&gt;I had a lot of fun with this competition an...</td>\n","      <td>https://www.kaggle.com/c/2447/discussion/185</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>08/03/2010 00:00:00</td>\n","      <td>Chess ratings - Elo versus the Rest of the World</td>\n","      <td>https://www.kaggle.com/c/2447</td>\n","      <td>11/20/2010 04:38:53</td>\n","      <td>6th place(UriB) by Uri Blass</td>\n","      <td>&lt;P&gt;I calculated rating for every player in mon...</td>\n","      <td>https://www.kaggle.com/c/2447/discussion/192</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>08/03/2010 00:00:00</td>\n","      <td>Chess ratings - Elo versus the Rest of the World</td>\n","      <td>https://www.kaggle.com/c/2447</td>\n","      <td>11/23/2010 10:38:23</td>\n","      <td>7th place - littlefish</td>\n","      <td>I'm a little surprised I ended up in the top-1...</td>\n","      <td>https://www.kaggle.com/c/2447/discussion/194</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>08/03/2010 00:00:00</td>\n","      <td>Chess ratings - Elo versus the Rest of the World</td>\n","      <td>https://www.kaggle.com/c/2447</td>\n","      <td>11/20/2010 11:27:17</td>\n","      <td>3rd place: Chessmetrics - Variant</td>\n","      <td>&lt;p&gt;&lt;span id=\"post_text_content_1230\"&gt;&lt;div dir=...</td>\n","      <td>https://www.kaggle.com/c/2447/discussion/193</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>08/03/2010 00:00:00</td>\n","      <td>Chess ratings - Elo versus the Rest of the World</td>\n","      <td>https://www.kaggle.com/c/2447</td>\n","      <td>11/18/2010 02:44:10</td>\n","      <td>2nd place: TrueSkill Through Time</td>\n","      <td>Wow, this is a surprise! I looked at this comp...</td>\n","      <td>https://www.kaggle.com/c/2447/discussion/186</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3122</th>\n","      <td>02/23/2023 17:25:32</td>\n","      <td>Google - Isolated Sign Language Recognition</td>\n","      <td>https://www.kaggle.com/c/46105</td>\n","      <td>05/02/2023 09:45:01</td>\n","      <td>49th place silver solution</td>\n","      <td>&lt;p&gt;Thank you Kaggle and Pop sign for hosting t...</td>\n","      <td>https://www.kaggle.com/c/46105/discussion/406426</td>\n","    </tr>\n","    <tr>\n","      <th>3123</th>\n","      <td>02/23/2023 17:25:32</td>\n","      <td>Google - Isolated Sign Language Recognition</td>\n","      <td>https://www.kaggle.com/c/46105</td>\n","      <td>05/02/2023 10:13:31</td>\n","      <td>10th place solution</td>\n","      <td>&lt;blockquote&gt;\\n  &lt;p&gt;First, I would like to than...</td>\n","      <td>https://www.kaggle.com/c/46105/discussion/406434</td>\n","    </tr>\n","    <tr>\n","      <th>3124</th>\n","      <td>02/23/2023 17:25:32</td>\n","      <td>Google - Isolated Sign Language Recognition</td>\n","      <td>https://www.kaggle.com/c/46105</td>\n","      <td>05/02/2023 03:24:28</td>\n","      <td>Solution - Single transformer without val dataset</td>\n","      <td>&lt;p&gt;Thanks to the organisers of the PopSign Gam...</td>\n","      <td>https://www.kaggle.com/c/46105/discussion/406346</td>\n","    </tr>\n","    <tr>\n","      <th>3125</th>\n","      <td>02/23/2023 17:25:32</td>\n","      <td>Google - Isolated Sign Language Recognition</td>\n","      <td>https://www.kaggle.com/c/46105</td>\n","      <td>05/02/2023 04:01:15</td>\n","      <td>Top 8% Bronze Medal Solution</td>\n","      <td>&lt;blockquote&gt;\\n  &lt;p&gt;&lt;strong&gt;Many congratulation...</td>\n","      <td>https://www.kaggle.com/c/46105/discussion/406354</td>\n","    </tr>\n","    <tr>\n","      <th>3126</th>\n","      <td>02/23/2023 17:25:32</td>\n","      <td>Google - Isolated Sign Language Recognition</td>\n","      <td>https://www.kaggle.com/c/46105</td>\n","      <td>05/02/2023 00:08:37</td>\n","      <td>44th Place Silver - How To Improve Best Public...</td>\n","      <td>&lt;p&gt;Thank you Kaggle, Kagglers, PopSign, and Pa...</td>\n","      <td>https://www.kaggle.com/c/46105/discussion/406302</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3127 rows × 7 columns</p>\n","</div>"],"text/plain":["     Competition Launch Date  \\\n","0        08/03/2010 00:00:00   \n","1        08/03/2010 00:00:00   \n","2        08/03/2010 00:00:00   \n","3        08/03/2010 00:00:00   \n","4        08/03/2010 00:00:00   \n","...                      ...   \n","3122     02/23/2023 17:25:32   \n","3123     02/23/2023 17:25:32   \n","3124     02/23/2023 17:25:32   \n","3125     02/23/2023 17:25:32   \n","3126     02/23/2023 17:25:32   \n","\n","                                  Title of Competition  \\\n","0     Chess ratings - Elo versus the Rest of the World   \n","1     Chess ratings - Elo versus the Rest of the World   \n","2     Chess ratings - Elo versus the Rest of the World   \n","3     Chess ratings - Elo versus the Rest of the World   \n","4     Chess ratings - Elo versus the Rest of the World   \n","...                                                ...   \n","3122       Google - Isolated Sign Language Recognition   \n","3123       Google - Isolated Sign Language Recognition   \n","3124       Google - Isolated Sign Language Recognition   \n","3125       Google - Isolated Sign Language Recognition   \n","3126       Google - Isolated Sign Language Recognition   \n","\n","                     Competition URL      Date of Writeup  \\\n","0      https://www.kaggle.com/c/2447  11/18/2010 00:06:46   \n","1      https://www.kaggle.com/c/2447  11/20/2010 04:38:53   \n","2      https://www.kaggle.com/c/2447  11/23/2010 10:38:23   \n","3      https://www.kaggle.com/c/2447  11/20/2010 11:27:17   \n","4      https://www.kaggle.com/c/2447  11/18/2010 02:44:10   \n","...                              ...                  ...   \n","3122  https://www.kaggle.com/c/46105  05/02/2023 09:45:01   \n","3123  https://www.kaggle.com/c/46105  05/02/2023 10:13:31   \n","3124  https://www.kaggle.com/c/46105  05/02/2023 03:24:28   \n","3125  https://www.kaggle.com/c/46105  05/02/2023 04:01:15   \n","3126  https://www.kaggle.com/c/46105  05/02/2023 00:08:37   \n","\n","                                       Title of Writeup  \\\n","0                 Released: my Source Code and Analysis   \n","1                          6th place(UriB) by Uri Blass   \n","2                                7th place - littlefish   \n","3                     3rd place: Chessmetrics - Variant   \n","4                     2nd place: TrueSkill Through Time   \n","...                                                 ...   \n","3122                         49th place silver solution   \n","3123                                10th place solution   \n","3124  Solution - Single transformer without val dataset   \n","3125                       Top 8% Bronze Medal Solution   \n","3126  44th Place Silver - How To Improve Best Public...   \n","\n","                                                Writeup  \\\n","0     <p>I had a lot of fun with this competition an...   \n","1     <P>I calculated rating for every player in mon...   \n","2     I'm a little surprised I ended up in the top-1...   \n","3     <p><span id=\"post_text_content_1230\"><div dir=...   \n","4     Wow, this is a surprise! I looked at this comp...   \n","...                                                 ...   \n","3122  <p>Thank you Kaggle and Pop sign for hosting t...   \n","3123  <blockquote>\\n  <p>First, I would like to than...   \n","3124  <p>Thanks to the organisers of the PopSign Gam...   \n","3125  <blockquote>\\n  <p><strong>Many congratulation...   \n","3126  <p>Thank you Kaggle, Kagglers, PopSign, and Pa...   \n","\n","                                           Writeup URL  \n","0         https://www.kaggle.com/c/2447/discussion/185  \n","1         https://www.kaggle.com/c/2447/discussion/192  \n","2         https://www.kaggle.com/c/2447/discussion/194  \n","3         https://www.kaggle.com/c/2447/discussion/193  \n","4         https://www.kaggle.com/c/2447/discussion/186  \n","...                                                ...  \n","3122  https://www.kaggle.com/c/46105/discussion/406426  \n","3123  https://www.kaggle.com/c/46105/discussion/406434  \n","3124  https://www.kaggle.com/c/46105/discussion/406346  \n","3125  https://www.kaggle.com/c/46105/discussion/406354  \n","3126  https://www.kaggle.com/c/46105/discussion/406302  \n","\n","[3127 rows x 7 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.read_csv(\"/kaggle/input/2023-kaggle-ai-report/kaggle_writeups_20230510.csv\")\n","data"]},{"cell_type":"markdown","id":"45c253fc","metadata":{"papermill":{"duration":0.019036,"end_time":"2023-06-06T08:29:22.36794","exception":false,"start_time":"2023-06-06T08:29:22.348904","status":"completed"},"tags":[]},"source":["At this point we will only focus on the `Writeup` column, we will try to access/process more information in the upcoming versions\n","\n","Our data is distributed in a `CSV File`. We need to extract our data in a `txt File` as a large corpus of data "]},{"cell_type":"code","execution_count":3,"id":"8559aff9","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:22.408422Z","iopub.status.busy":"2023-06-06T08:29:22.40802Z","iopub.status.idle":"2023-06-06T08:29:22.415783Z","shell.execute_reply":"2023-06-06T08:29:22.414987Z"},"papermill":{"duration":0.030779,"end_time":"2023-06-06T08:29:22.417959","exception":false,"start_time":"2023-06-06T08:29:22.38718","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["0       <p>I had a lot of fun with this competition an...\n","1       <P>I calculated rating for every player in mon...\n","2       I'm a little surprised I ended up in the top-1...\n","3       <p><span id=\"post_text_content_1230\"><div dir=...\n","4       Wow, this is a surprise! I looked at this comp...\n","                              ...                        \n","3122    <p>Thank you Kaggle and Pop sign for hosting t...\n","3123    <blockquote>\\n  <p>First, I would like to than...\n","3124    <p>Thanks to the organisers of the PopSign Gam...\n","3125    <blockquote>\\n  <p><strong>Many congratulation...\n","3126    <p>Thank you Kaggle, Kagglers, PopSign, and Pa...\n","Name: Writeup, Length: 3127, dtype: object"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["data[\"Writeup\"]"]},{"cell_type":"markdown","id":"ec44bcda","metadata":{"papermill":{"duration":0.019299,"end_time":"2023-06-06T08:29:22.456963","exception":false,"start_time":"2023-06-06T08:29:22.437664","status":"completed"},"tags":[]},"source":["I think that `for understanding BERT`. It would be great if we choose the way of `Question Answering`. This data, by default is not made for `Question Answering`. But somwhow we will make the data as we want "]},{"cell_type":"code","execution_count":4,"id":"a7a4253a","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:22.498184Z","iopub.status.busy":"2023-06-06T08:29:22.497748Z","iopub.status.idle":"2023-06-06T08:29:22.502954Z","shell.execute_reply":"2023-06-06T08:29:22.50224Z"},"papermill":{"duration":0.028353,"end_time":"2023-06-06T08:29:22.505149","exception":false,"start_time":"2023-06-06T08:29:22.476796","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["<p>I had a lot of fun with this competition and learned a lot about ratings systems.</p>\r\n","<div>Sadly, I only came 18th :)</div>\r\n","<div>If you're interested, you can download all of my code and&nbsp;analysis&nbsp;from my github repo:&nbsp;https://github.com/jbrownlee/ChessML</div>\r\n","<div>There are implementations of a few rating systems (elo, glicko, chessmetrics, etc) and many attempts at improving them (a nice little experimentation framework).</div>\r\n","<div>Thanks all. Looking forward to the next big comp!</div>\r\n","<div>jasonb</div>\n"]}],"source":["print(data[\"Writeup\"][0])"]},{"cell_type":"markdown","id":"f8ed2666","metadata":{"papermill":{"duration":0.019724,"end_time":"2023-06-06T08:29:22.545418","exception":false,"start_time":"2023-06-06T08:29:22.525694","status":"completed"},"tags":[]},"source":["You can note that there are many of the `HTML tags` and other links provided in the data. We do not need these links, So it would be great if we juse remove all of this "]},{"cell_type":"code","execution_count":5,"id":"101e676d","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-06-06T08:29:22.58574Z","iopub.status.busy":"2023-06-06T08:29:22.585348Z","iopub.status.idle":"2023-06-06T08:29:22.59263Z","shell.execute_reply":"2023-06-06T08:29:22.591514Z"},"papermill":{"duration":0.030816,"end_time":"2023-06-06T08:29:22.59565","exception":false,"start_time":"2023-06-06T08:29:22.564834","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["I had a lot of fun with this competition and learned a lot about ratings systems.\r\n","Sadly, I only came 18th  )\r\n","If you're interested, you can download all of my code and analysis from my github repo   \r\n","There are implementations of a few rating systems (elo, glicko, chessmetrics, etc) and many attempts at improving them (a nice little experimentation framework).\r\n","Thanks all. Looking forward to the next big comp!\r\n","jasonb\n"]}],"source":["print(\n","    re.sub(\n","        ':' , \" \" , \n","        re.sub(\n","            ';' , ' ' , \n","            re.sub(\n","                '&nbsp' , \"\" , \n","                (\n","                    re.sub(\n","                        r'http\\S+', ' ', \n","                        (\n","                            re.compile(r'<.*?>').sub(\n","                                \"\" , \n","                                data[\"Writeup\"][0]\n","                            )\n","                        )\n","                    )\n","                )\n","            )\n","        )\n","    )\n",")"]},{"cell_type":"code","execution_count":6,"id":"b35cd542","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-06-06T08:29:22.636963Z","iopub.status.busy":"2023-06-06T08:29:22.636227Z","iopub.status.idle":"2023-06-06T08:29:22.647494Z","shell.execute_reply":"2023-06-06T08:29:22.646414Z"},"papermill":{"duration":0.034625,"end_time":"2023-06-06T08:29:22.649796","exception":false,"start_time":"2023-06-06T08:29:22.615171","status":"completed"},"tags":[]},"outputs":[],"source":["emoj = re.compile(\"[\"\n","    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","    u\"\\U00002500-\\U00002BEF\"  # chinese char\n","    u\"\\U00002702-\\U000027B0\"\n","    u\"\\U00002702-\\U000027B0\"\n","    u\"\\U000024C2-\\U0001F251\"\n","    u\"\\U0001f926-\\U0001f937\"\n","    u\"\\U00010000-\\U0010ffff\"\n","    u\"\\u2640-\\u2642\" \n","    u\"\\u2600-\\u2B55\"\n","    u\"\\u200d\"\n","    u\"\\u23cf\"\n","    u\"\\u23e9\"\n","    u\"\\u231a\"\n","    u\"\\ufe0f\"  # dingbats\n","    u\"\\u3030\"\n","    u\"\\u2028\"\n","    \"\\x08\"\n","    u\"\\u200a\"\n","    u\"\\u200b\"\n","                  \"]+\", re.UNICODE)"]},{"cell_type":"code","execution_count":7,"id":"f5541aa5","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-06-06T08:29:22.691123Z","iopub.status.busy":"2023-06-06T08:29:22.690436Z","iopub.status.idle":"2023-06-06T08:29:22.696809Z","shell.execute_reply":"2023-06-06T08:29:22.6957Z"},"papermill":{"duration":0.029816,"end_time":"2023-06-06T08:29:22.699319","exception":false,"start_time":"2023-06-06T08:29:22.669503","status":"completed"},"tags":[]},"outputs":[],"source":["def preprocess(text): \n","    k = re.sub(\n","        ':' , \" \" , \n","        re.sub(\n","            ';' , ' ' , \n","            re.sub(\n","                '&nbsp' , '' , \n","                (\n","                    re.sub(\n","                        r'http\\S+', ' ', \n","                        (\n","                            re.compile(r'<.*?>').sub(\n","                                \"\" , str(text)\n","                            )\n","                        )\n","                    )\n","                )\n","            )\n","        )\n","    )\n","    k = emoj.sub(r'' , k)\n","    \n","    return k"]},{"cell_type":"code","execution_count":8,"id":"a946e6c6","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:22.739862Z","iopub.status.busy":"2023-06-06T08:29:22.739458Z","iopub.status.idle":"2023-06-06T08:29:23.818255Z","shell.execute_reply":"2023-06-06T08:29:23.81695Z"},"papermill":{"duration":1.10215,"end_time":"2023-06-06T08:29:23.82098","exception":false,"start_time":"2023-06-06T08:29:22.71883","status":"completed"},"tags":[]},"outputs":[],"source":["data[\"Writeup\"] = data[\"Writeup\"].map(preprocess)"]},{"cell_type":"code","execution_count":9,"id":"2425a19e","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:23.862423Z","iopub.status.busy":"2023-06-06T08:29:23.861994Z","iopub.status.idle":"2023-06-06T08:29:23.867676Z","shell.execute_reply":"2023-06-06T08:29:23.866228Z"},"papermill":{"duration":0.029291,"end_time":"2023-06-06T08:29:23.870019","exception":false,"start_time":"2023-06-06T08:29:23.840728","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["I had a lot of fun with this competition and learned a lot about ratings systems.\r\n","Sadly, I only came 18th  )\r\n","If you're interested, you can download all of my code and analysis from my github repo   \r\n","There are implementations of a few rating systems (elo, glicko, chessmetrics, etc) and many attempts at improving them (a nice little experimentation framework).\r\n","Thanks all. Looking forward to the next big comp!\r\n","jasonb\n"]}],"source":["print(data[\"Writeup\"][0])"]},{"cell_type":"markdown","id":"0ba9812b","metadata":{"papermill":{"duration":0.01966,"end_time":"2023-06-06T08:29:23.909303","exception":false,"start_time":"2023-06-06T08:29:23.889643","status":"completed"},"tags":[]},"source":["And this is in good format"]},{"cell_type":"code","execution_count":10,"id":"f5524266","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:23.950664Z","iopub.status.busy":"2023-06-06T08:29:23.950291Z","iopub.status.idle":"2023-06-06T08:29:23.955615Z","shell.execute_reply":"2023-06-06T08:29:23.954526Z"},"papermill":{"duration":0.028597,"end_time":"2023-06-06T08:29:23.957863","exception":false,"start_time":"2023-06-06T08:29:23.929266","status":"completed"},"tags":[]},"outputs":[],"source":["que_splitter = lambda text: text[:len(text)//2]\n","ans_splitter = lambda text: text[len(text)//2:]"]},{"cell_type":"code","execution_count":11,"id":"84e13d23","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:23.999404Z","iopub.status.busy":"2023-06-06T08:29:23.999004Z","iopub.status.idle":"2023-06-06T08:29:24.027694Z","shell.execute_reply":"2023-06-06T08:29:24.026791Z"},"papermill":{"duration":0.052058,"end_time":"2023-06-06T08:29:24.029877","exception":false,"start_time":"2023-06-06T08:29:23.977819","status":"completed"},"tags":[]},"outputs":[],"source":["data[\"Qeustion\"] = data[\"Writeup\"].map(que_splitter)\n","data[\"Answer\"] = data[\"Writeup\"].map(ans_splitter)"]},{"cell_type":"code","execution_count":12,"id":"998747f2","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:24.071988Z","iopub.status.busy":"2023-06-06T08:29:24.071304Z","iopub.status.idle":"2023-06-06T08:29:24.094687Z","shell.execute_reply":"2023-06-06T08:29:24.093497Z"},"papermill":{"duration":0.047365,"end_time":"2023-06-06T08:29:24.096965","exception":false,"start_time":"2023-06-06T08:29:24.0496","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Competition Launch Date</th>\n","      <th>Title of Competition</th>\n","      <th>Competition URL</th>\n","      <th>Date of Writeup</th>\n","      <th>Title of Writeup</th>\n","      <th>Writeup</th>\n","      <th>Writeup URL</th>\n","      <th>Qeustion</th>\n","      <th>Answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>08/03/2010 00:00:00</td>\n","      <td>Chess ratings - Elo versus the Rest of the World</td>\n","      <td>https://www.kaggle.com/c/2447</td>\n","      <td>11/18/2010 00:06:46</td>\n","      <td>Released: my Source Code and Analysis</td>\n","      <td>I had a lot of fun with this competition and l...</td>\n","      <td>https://www.kaggle.com/c/2447/discussion/185</td>\n","      <td>I had a lot of fun with this competition and l...</td>\n","      <td>implementations of a few rating systems (elo,...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>08/03/2010 00:00:00</td>\n","      <td>Chess ratings - Elo versus the Rest of the World</td>\n","      <td>https://www.kaggle.com/c/2447</td>\n","      <td>11/20/2010 04:38:53</td>\n","      <td>6th place(UriB) by Uri Blass</td>\n","      <td>I calculated rating for every player in months...</td>\n","      <td>https://www.kaggle.com/c/2447/discussion/192</td>\n","      <td>I calculated rating for every player in months...</td>\n","      <td>formed practically better than his real score ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>08/03/2010 00:00:00</td>\n","      <td>Chess ratings - Elo versus the Rest of the World</td>\n","      <td>https://www.kaggle.com/c/2447</td>\n","      <td>11/23/2010 10:38:23</td>\n","      <td>7th place - littlefish</td>\n","      <td>I'm a little surprised I ended up in the top-1...</td>\n","      <td>https://www.kaggle.com/c/2447/discussion/194</td>\n","      <td>I'm a little surprised I ended up in the top-1...</td>\n","      <td>eighted with the square root of the number of ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>08/03/2010 00:00:00</td>\n","      <td>Chess ratings - Elo versus the Rest of the World</td>\n","      <td>https://www.kaggle.com/c/2447</td>\n","      <td>11/20/2010 11:27:17</td>\n","      <td>3rd place: Chessmetrics - Variant</td>\n","      <td>Dear all,it was a great competition, thanks a ...</td>\n","      <td>https://www.kaggle.com/c/2447/discussion/193</td>\n","      <td>Dear all,it was a great competition, thanks a ...</td>\n","      <td>ating_level = \\r\\n2.5game_weight  = (1 / (1 + ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>08/03/2010 00:00:00</td>\n","      <td>Chess ratings - Elo versus the Rest of the World</td>\n","      <td>https://www.kaggle.com/c/2447</td>\n","      <td>11/18/2010 02:44:10</td>\n","      <td>2nd place: TrueSkill Through Time</td>\n","      <td>Wow, this is a surprise! I looked at this comp...</td>\n","      <td>https://www.kaggle.com/c/2447/discussion/186</td>\n","      <td>Wow, this is a surprise! I looked at this comp...</td>\n","      <td>hrowing away valuable information. I switched ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3122</th>\n","      <td>02/23/2023 17:25:32</td>\n","      <td>Google - Isolated Sign Language Recognition</td>\n","      <td>https://www.kaggle.com/c/46105</td>\n","      <td>05/02/2023 09:45:01</td>\n","      <td>49th place silver solution</td>\n","      <td>Thank you Kaggle and Pop sign for hosting this...</td>\n","      <td>https://www.kaggle.com/c/46105/discussion/406426</td>\n","      <td>Thank you Kaggle and Pop sign for hosting this...</td>\n","      <td>for the remaining\\nFP16 quantization reduced m...</td>\n","    </tr>\n","    <tr>\n","      <th>3123</th>\n","      <td>02/23/2023 17:25:32</td>\n","      <td>Google - Isolated Sign Language Recognition</td>\n","      <td>https://www.kaggle.com/c/46105</td>\n","      <td>05/02/2023 10:13:31</td>\n","      <td>10th place solution</td>\n","      <td>\\n  First, I would like to thank the Armed For...</td>\n","      <td>https://www.kaggle.com/c/46105/discussion/406434</td>\n","      <td>\\n  First, I would like to thank the Armed For...</td>\n","      <td>more), Most of the boost i get from  \\n\\nMixup...</td>\n","    </tr>\n","    <tr>\n","      <th>3124</th>\n","      <td>02/23/2023 17:25:32</td>\n","      <td>Google - Isolated Sign Language Recognition</td>\n","      <td>https://www.kaggle.com/c/46105</td>\n","      <td>05/02/2023 03:24:28</td>\n","      <td>Solution - Single transformer without val dataset</td>\n","      <td>Thanks to the organisers of the PopSign Games ...</td>\n","      <td>https://www.kaggle.com/c/46105/discussion/406346</td>\n","      <td>Thanks to the organisers of the PopSign Games ...</td>\n","      <td>16] not working for me.\\nHow to do rotation co...</td>\n","    </tr>\n","    <tr>\n","      <th>3125</th>\n","      <td>02/23/2023 17:25:32</td>\n","      <td>Google - Isolated Sign Language Recognition</td>\n","      <td>https://www.kaggle.com/c/46105</td>\n","      <td>05/02/2023 04:01:15</td>\n","      <td>Top 8% Bronze Medal Solution</td>\n","      <td>\\n  Many congratulations to all the winners in...</td>\n","      <td>https://www.kaggle.com/c/46105/discussion/406354</td>\n","      <td>\\n  Many congratulations to all the winners in...</td>\n","      <td>tion. \\nDataset  Only Competition Data\\nModel ...</td>\n","    </tr>\n","    <tr>\n","      <th>3126</th>\n","      <td>02/23/2023 17:25:32</td>\n","      <td>Google - Isolated Sign Language Recognition</td>\n","      <td>https://www.kaggle.com/c/46105</td>\n","      <td>05/02/2023 00:08:37</td>\n","      <td>44th Place Silver - How To Improve Best Public...</td>\n","      <td>Thank you Kaggle, Kagglers, PopSign, and Partn...</td>\n","      <td>https://www.kaggle.com/c/46105/discussion/406302</td>\n","      <td>Thank you Kaggle, Kagglers, PopSign, and Partn...</td>\n","      <td>ers to see how small I could go without reduci...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3127 rows × 9 columns</p>\n","</div>"],"text/plain":["     Competition Launch Date  \\\n","0        08/03/2010 00:00:00   \n","1        08/03/2010 00:00:00   \n","2        08/03/2010 00:00:00   \n","3        08/03/2010 00:00:00   \n","4        08/03/2010 00:00:00   \n","...                      ...   \n","3122     02/23/2023 17:25:32   \n","3123     02/23/2023 17:25:32   \n","3124     02/23/2023 17:25:32   \n","3125     02/23/2023 17:25:32   \n","3126     02/23/2023 17:25:32   \n","\n","                                  Title of Competition  \\\n","0     Chess ratings - Elo versus the Rest of the World   \n","1     Chess ratings - Elo versus the Rest of the World   \n","2     Chess ratings - Elo versus the Rest of the World   \n","3     Chess ratings - Elo versus the Rest of the World   \n","4     Chess ratings - Elo versus the Rest of the World   \n","...                                                ...   \n","3122       Google - Isolated Sign Language Recognition   \n","3123       Google - Isolated Sign Language Recognition   \n","3124       Google - Isolated Sign Language Recognition   \n","3125       Google - Isolated Sign Language Recognition   \n","3126       Google - Isolated Sign Language Recognition   \n","\n","                     Competition URL      Date of Writeup  \\\n","0      https://www.kaggle.com/c/2447  11/18/2010 00:06:46   \n","1      https://www.kaggle.com/c/2447  11/20/2010 04:38:53   \n","2      https://www.kaggle.com/c/2447  11/23/2010 10:38:23   \n","3      https://www.kaggle.com/c/2447  11/20/2010 11:27:17   \n","4      https://www.kaggle.com/c/2447  11/18/2010 02:44:10   \n","...                              ...                  ...   \n","3122  https://www.kaggle.com/c/46105  05/02/2023 09:45:01   \n","3123  https://www.kaggle.com/c/46105  05/02/2023 10:13:31   \n","3124  https://www.kaggle.com/c/46105  05/02/2023 03:24:28   \n","3125  https://www.kaggle.com/c/46105  05/02/2023 04:01:15   \n","3126  https://www.kaggle.com/c/46105  05/02/2023 00:08:37   \n","\n","                                       Title of Writeup  \\\n","0                 Released: my Source Code and Analysis   \n","1                          6th place(UriB) by Uri Blass   \n","2                                7th place - littlefish   \n","3                     3rd place: Chessmetrics - Variant   \n","4                     2nd place: TrueSkill Through Time   \n","...                                                 ...   \n","3122                         49th place silver solution   \n","3123                                10th place solution   \n","3124  Solution - Single transformer without val dataset   \n","3125                       Top 8% Bronze Medal Solution   \n","3126  44th Place Silver - How To Improve Best Public...   \n","\n","                                                Writeup  \\\n","0     I had a lot of fun with this competition and l...   \n","1     I calculated rating for every player in months...   \n","2     I'm a little surprised I ended up in the top-1...   \n","3     Dear all,it was a great competition, thanks a ...   \n","4     Wow, this is a surprise! I looked at this comp...   \n","...                                                 ...   \n","3122  Thank you Kaggle and Pop sign for hosting this...   \n","3123  \\n  First, I would like to thank the Armed For...   \n","3124  Thanks to the organisers of the PopSign Games ...   \n","3125  \\n  Many congratulations to all the winners in...   \n","3126  Thank you Kaggle, Kagglers, PopSign, and Partn...   \n","\n","                                           Writeup URL  \\\n","0         https://www.kaggle.com/c/2447/discussion/185   \n","1         https://www.kaggle.com/c/2447/discussion/192   \n","2         https://www.kaggle.com/c/2447/discussion/194   \n","3         https://www.kaggle.com/c/2447/discussion/193   \n","4         https://www.kaggle.com/c/2447/discussion/186   \n","...                                                ...   \n","3122  https://www.kaggle.com/c/46105/discussion/406426   \n","3123  https://www.kaggle.com/c/46105/discussion/406434   \n","3124  https://www.kaggle.com/c/46105/discussion/406346   \n","3125  https://www.kaggle.com/c/46105/discussion/406354   \n","3126  https://www.kaggle.com/c/46105/discussion/406302   \n","\n","                                               Qeustion  \\\n","0     I had a lot of fun with this competition and l...   \n","1     I calculated rating for every player in months...   \n","2     I'm a little surprised I ended up in the top-1...   \n","3     Dear all,it was a great competition, thanks a ...   \n","4     Wow, this is a surprise! I looked at this comp...   \n","...                                                 ...   \n","3122  Thank you Kaggle and Pop sign for hosting this...   \n","3123  \\n  First, I would like to thank the Armed For...   \n","3124  Thanks to the organisers of the PopSign Games ...   \n","3125  \\n  Many congratulations to all the winners in...   \n","3126  Thank you Kaggle, Kagglers, PopSign, and Partn...   \n","\n","                                                 Answer  \n","0      implementations of a few rating systems (elo,...  \n","1     formed practically better than his real score ...  \n","2     eighted with the square root of the number of ...  \n","3     ating_level = \\r\\n2.5game_weight  = (1 / (1 + ...  \n","4     hrowing away valuable information. I switched ...  \n","...                                                 ...  \n","3122  for the remaining\\nFP16 quantization reduced m...  \n","3123  more), Most of the boost i get from  \\n\\nMixup...  \n","3124  16] not working for me.\\nHow to do rotation co...  \n","3125  tion. \\nDataset  Only Competition Data\\nModel ...  \n","3126  ers to see how small I could go without reduci...  \n","\n","[3127 rows x 9 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"markdown","id":"e07a9b41","metadata":{"papermill":{"duration":0.019769,"end_time":"2023-06-06T08:29:24.137053","exception":false,"start_time":"2023-06-06T08:29:24.117284","status":"completed"},"tags":[]},"source":["Now our data looks like this \n","\n","Lets focus on our major columns only "]},{"cell_type":"code","execution_count":13,"id":"90ddf045","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:24.179927Z","iopub.status.busy":"2023-06-06T08:29:24.179533Z","iopub.status.idle":"2023-06-06T08:29:24.188871Z","shell.execute_reply":"2023-06-06T08:29:24.187874Z"},"papermill":{"duration":0.033552,"end_time":"2023-06-06T08:29:24.191171","exception":false,"start_time":"2023-06-06T08:29:24.157619","status":"completed"},"tags":[]},"outputs":[],"source":["data.drop([\"Competition Launch Date\" , \"Title of Competition\" , \n","          \"Competition URL\" , \"Date of Writeup\" , \"Title of Writeup\" , \n","          \"Writeup URL\"], axis = 1 , inplace = True)"]},{"cell_type":"code","execution_count":14,"id":"fa845fad","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:24.234264Z","iopub.status.busy":"2023-06-06T08:29:24.23385Z","iopub.status.idle":"2023-06-06T08:29:24.247834Z","shell.execute_reply":"2023-06-06T08:29:24.246778Z"},"papermill":{"duration":0.038692,"end_time":"2023-06-06T08:29:24.250015","exception":false,"start_time":"2023-06-06T08:29:24.211323","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Writeup</th>\n","      <th>Qeustion</th>\n","      <th>Answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I had a lot of fun with this competition and l...</td>\n","      <td>I had a lot of fun with this competition and l...</td>\n","      <td>implementations of a few rating systems (elo,...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>I calculated rating for every player in months...</td>\n","      <td>I calculated rating for every player in months...</td>\n","      <td>formed practically better than his real score ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I'm a little surprised I ended up in the top-1...</td>\n","      <td>I'm a little surprised I ended up in the top-1...</td>\n","      <td>eighted with the square root of the number of ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Dear all,it was a great competition, thanks a ...</td>\n","      <td>Dear all,it was a great competition, thanks a ...</td>\n","      <td>ating_level = \\r\\n2.5game_weight  = (1 / (1 + ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Wow, this is a surprise! I looked at this comp...</td>\n","      <td>Wow, this is a surprise! I looked at this comp...</td>\n","      <td>hrowing away valuable information. I switched ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3122</th>\n","      <td>Thank you Kaggle and Pop sign for hosting this...</td>\n","      <td>Thank you Kaggle and Pop sign for hosting this...</td>\n","      <td>for the remaining\\nFP16 quantization reduced m...</td>\n","    </tr>\n","    <tr>\n","      <th>3123</th>\n","      <td>\\n  First, I would like to thank the Armed For...</td>\n","      <td>\\n  First, I would like to thank the Armed For...</td>\n","      <td>more), Most of the boost i get from  \\n\\nMixup...</td>\n","    </tr>\n","    <tr>\n","      <th>3124</th>\n","      <td>Thanks to the organisers of the PopSign Games ...</td>\n","      <td>Thanks to the organisers of the PopSign Games ...</td>\n","      <td>16] not working for me.\\nHow to do rotation co...</td>\n","    </tr>\n","    <tr>\n","      <th>3125</th>\n","      <td>\\n  Many congratulations to all the winners in...</td>\n","      <td>\\n  Many congratulations to all the winners in...</td>\n","      <td>tion. \\nDataset  Only Competition Data\\nModel ...</td>\n","    </tr>\n","    <tr>\n","      <th>3126</th>\n","      <td>Thank you Kaggle, Kagglers, PopSign, and Partn...</td>\n","      <td>Thank you Kaggle, Kagglers, PopSign, and Partn...</td>\n","      <td>ers to see how small I could go without reduci...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3127 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                Writeup  \\\n","0     I had a lot of fun with this competition and l...   \n","1     I calculated rating for every player in months...   \n","2     I'm a little surprised I ended up in the top-1...   \n","3     Dear all,it was a great competition, thanks a ...   \n","4     Wow, this is a surprise! I looked at this comp...   \n","...                                                 ...   \n","3122  Thank you Kaggle and Pop sign for hosting this...   \n","3123  \\n  First, I would like to thank the Armed For...   \n","3124  Thanks to the organisers of the PopSign Games ...   \n","3125  \\n  Many congratulations to all the winners in...   \n","3126  Thank you Kaggle, Kagglers, PopSign, and Partn...   \n","\n","                                               Qeustion  \\\n","0     I had a lot of fun with this competition and l...   \n","1     I calculated rating for every player in months...   \n","2     I'm a little surprised I ended up in the top-1...   \n","3     Dear all,it was a great competition, thanks a ...   \n","4     Wow, this is a surprise! I looked at this comp...   \n","...                                                 ...   \n","3122  Thank you Kaggle and Pop sign for hosting this...   \n","3123  \\n  First, I would like to thank the Armed For...   \n","3124  Thanks to the organisers of the PopSign Games ...   \n","3125  \\n  Many congratulations to all the winners in...   \n","3126  Thank you Kaggle, Kagglers, PopSign, and Partn...   \n","\n","                                                 Answer  \n","0      implementations of a few rating systems (elo,...  \n","1     formed practically better than his real score ...  \n","2     eighted with the square root of the number of ...  \n","3     ating_level = \\r\\n2.5game_weight  = (1 / (1 + ...  \n","4     hrowing away valuable information. I switched ...  \n","...                                                 ...  \n","3122  for the remaining\\nFP16 quantization reduced m...  \n","3123  more), Most of the boost i get from  \\n\\nMixup...  \n","3124  16] not working for me.\\nHow to do rotation co...  \n","3125  tion. \\nDataset  Only Competition Data\\nModel ...  \n","3126  ers to see how small I could go without reduci...  \n","\n","[3127 rows x 3 columns]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"markdown","id":"8f2c048c","metadata":{"papermill":{"duration":0.020117,"end_time":"2023-06-06T08:29:24.290881","exception":false,"start_time":"2023-06-06T08:29:24.270764","status":"completed"},"tags":[]},"source":["Now we will make a list continaing list of `Questions` and their correspodning `Answers`"]},{"cell_type":"code","execution_count":15,"id":"4275caaf","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:24.333985Z","iopub.status.busy":"2023-06-06T08:29:24.333573Z","iopub.status.idle":"2023-06-06T08:29:24.42268Z","shell.execute_reply":"2023-06-06T08:29:24.421473Z"},"papermill":{"duration":0.11376,"end_time":"2023-06-06T08:29:24.425524","exception":false,"start_time":"2023-06-06T08:29:24.311764","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 3127/3127 [00:00<00:00, 41733.37it/s]\n"]}],"source":["pairs = []\n","\n","for i in tqdm.tqdm(range(data.shape[0]) , total = data.shape[0]):\n","    \n","    sample_list = []\n","    \n","    sample_list.append(data[\"Qeustion\"][i])\n","    sample_list.append(data[\"Answer\"][i])\n","    \n","    pairs.append(sample_list)"]},{"cell_type":"code","execution_count":16,"id":"ebb86e39","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:24.469259Z","iopub.status.busy":"2023-06-06T08:29:24.468495Z","iopub.status.idle":"2023-06-06T08:29:24.780888Z","shell.execute_reply":"2023-06-06T08:29:24.77993Z"},"papermill":{"duration":0.336875,"end_time":"2023-06-06T08:29:24.783172","exception":false,"start_time":"2023-06-06T08:29:24.446297","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(3127, 2)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["x = np.array(pairs)\n","x.shape"]},{"cell_type":"markdown","id":"a4ade2fb","metadata":{"papermill":{"duration":0.020669,"end_time":"2023-06-06T08:29:24.825329","exception":false,"start_time":"2023-06-06T08:29:24.80466","status":"completed"},"tags":[]},"source":["So now we have our data in the correct format \n","\n","Lets save it somewhere"]},{"cell_type":"code","execution_count":17,"id":"248aa249","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:24.869999Z","iopub.status.busy":"2023-06-06T08:29:24.869373Z","iopub.status.idle":"2023-06-06T08:29:24.874125Z","shell.execute_reply":"2023-06-06T08:29:24.873393Z"},"papermill":{"duration":0.029943,"end_time":"2023-06-06T08:29:24.876265","exception":false,"start_time":"2023-06-06T08:29:24.846322","status":"completed"},"tags":[]},"outputs":[],"source":["text_data = []\n","file_count = 0\n","\n","os.mkdir(\"/kaggle/working/data\")"]},{"cell_type":"code","execution_count":18,"id":"a76d7f89","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:24.920141Z","iopub.status.busy":"2023-06-06T08:29:24.919756Z","iopub.status.idle":"2023-06-06T08:29:24.934691Z","shell.execute_reply":"2023-06-06T08:29:24.933489Z"},"papermill":{"duration":0.03956,"end_time":"2023-06-06T08:29:24.936866","exception":false,"start_time":"2023-06-06T08:29:24.897306","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 3127/3127 [00:00<00:00, 863720.03it/s]\n"]}],"source":["for sample in tqdm.tqdm([x[0] for x in pairs]):\n","    \n","    text_data.append(sample)\n","\n","    if len(text_data) == 10000:\n","        \n","        with open(f'/kaggle/working/data/text_{file_count}.txt', 'w', encoding='utf-8') as fp: \n","            fp.write('\\n'.join(text_data))\n","        \n","        text_data = []\n","        file_count += 1"]},{"cell_type":"code","execution_count":19,"id":"a6477af3","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:24.981752Z","iopub.status.busy":"2023-06-06T08:29:24.981103Z","iopub.status.idle":"2023-06-06T08:29:24.986362Z","shell.execute_reply":"2023-06-06T08:29:24.985618Z"},"papermill":{"duration":0.029857,"end_time":"2023-06-06T08:29:24.988453","exception":false,"start_time":"2023-06-06T08:29:24.958596","status":"completed"},"tags":[]},"outputs":[],"source":["paths = [str(x) for x in Path('./data').glob('**/*.txt')]"]},{"cell_type":"markdown","id":"70bdece5","metadata":{"papermill":{"duration":0.021022,"end_time":"2023-06-06T08:29:25.030706","exception":false,"start_time":"2023-06-06T08:29:25.009684","status":"completed"},"tags":[]},"source":["# 2 | Embeddings/Tokenizing 🔢\n","\n","Okay, so just hear me out. First thing to notice, we cannot just put letters into a model and expect it to undertand everything. No, We need to somehow make this characters into numbers, somehow, we really dont know how, but somehow, we will do that. \n","\n","Okay so we know what characters we have, like we know, all the characters will fall in the `English Alphabet`, maybe we find some extra characters like, `\",\" , \".\" , etc`. So what if we number them like that only. \n","\n","Lets assume we have a letter like `Optimus Prime`, we know that in the `English Alphabet` ,  `O`  comes at `15`, so we can number `O` as `15` and like this only the whole sequence becomes something like this \n","\n","|_____|_____\n","|---|---\n","|O|15\n","|p|42\n","|t|46\n","|i|35\n","|m|39\n","|u|47\n","|s|45\n","| |0\n","|P|16\n","|r|44\n","|i|35\n","|m|39\n","|e|31\n","\n","We call this numerical representation of a `str`, **Embedding/Tokenizing**\n","\n","What we did here was `character encoding` , means we were taking every character to be distinct of each other, or be independent to each character. \n","\n","There are other types of possible encoding available, such as `Bag Of Words , TF-IDF , Word2Vec , Glove`. There are more available like **[Sentence Piece by Google](https://github.com/google/sentencepiece)**  or **[Tik Token by OpenAI](https://github.com/openai/tiktoken)**\n"," , which you can try \n","\n","Here we will be using **[BertWordPeiceTokenizer](https://huggingface.co/learn/nlp-course/chapter6/6?fw=pt)**"]},{"cell_type":"code","execution_count":20,"id":"2285902b","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-06-06T08:29:25.076007Z","iopub.status.busy":"2023-06-06T08:29:25.075317Z","iopub.status.idle":"2023-06-06T08:29:27.022308Z","shell.execute_reply":"2023-06-06T08:29:27.021252Z"},"papermill":{"duration":1.972799,"end_time":"2023-06-06T08:29:27.025162","exception":false,"start_time":"2023-06-06T08:29:25.052363","status":"completed"},"tags":[]},"outputs":[],"source":["from tokenizers import BertWordPieceTokenizer\n","from transformers import BertTokenizer"]},{"cell_type":"code","execution_count":21,"id":"ed5be259","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:27.070201Z","iopub.status.busy":"2023-06-06T08:29:27.069566Z","iopub.status.idle":"2023-06-06T08:29:27.087914Z","shell.execute_reply":"2023-06-06T08:29:27.086855Z"},"papermill":{"duration":0.043447,"end_time":"2023-06-06T08:29:27.090342","exception":false,"start_time":"2023-06-06T08:29:27.046895","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Tokenizer(vocabulary_size=0, model=BertWordPiece, unk_token=[UNK], sep_token=[SEP], cls_token=[CLS], pad_token=[PAD], mask_token=[MASK], clean_text=True, handle_chinese_chars=False, strip_accents=False, lowercase=True, wordpieces_prefix=##)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer = BertWordPieceTokenizer(clean_text = True ,\n","                                   handle_chinese_chars = False , \n","                                   strip_accents = False , \n","                                   lowercase = True)\n","\n","tokenizer"]},{"cell_type":"code","execution_count":22,"id":"5f69c52d","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:27.135426Z","iopub.status.busy":"2023-06-06T08:29:27.135021Z","iopub.status.idle":"2023-06-06T08:29:27.154829Z","shell.execute_reply":"2023-06-06T08:29:27.153555Z"},"papermill":{"duration":0.044835,"end_time":"2023-06-06T08:29:27.15698","exception":false,"start_time":"2023-06-06T08:29:27.112145","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\n"]}],"source":["tokenizer.train( files = paths , vocab_size = 30_000 ,  min_frequency = 5 ,\n","                limit_alphabet = 1000 , wordpieces_prefix = '##' ,\n","                special_tokens=['[PAD]', '[CLS]', '[SEP]', '[MASK]', '[UNK]'])"]},{"cell_type":"code","execution_count":23,"id":"63c35f62","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:27.201435Z","iopub.status.busy":"2023-06-06T08:29:27.200905Z","iopub.status.idle":"2023-06-06T08:29:27.220887Z","shell.execute_reply":"2023-06-06T08:29:27.220018Z"},"papermill":{"duration":0.044397,"end_time":"2023-06-06T08:29:27.223016","exception":false,"start_time":"2023-06-06T08:29:27.178619","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n","  warnings.warn(\n"]}],"source":["os.mkdir('/kaggle/working/bert-it-1')\n","tokenizer.save_model('/kaggle/working/bert-it-1', 'bert-it')\n","tokenizer = BertTokenizer.from_pretrained('/kaggle/working/bert-it-1/bert-it-vocab.txt', local_files_only=True)"]},{"cell_type":"markdown","id":"34a4f16f","metadata":{"papermill":{"duration":0.021128,"end_time":"2023-06-06T08:29:27.265789","exception":false,"start_time":"2023-06-06T08:29:27.244661","status":"completed"},"tags":[]},"source":["Lets assume we have the line `A person who eats neighbourhood children`"]},{"cell_type":"code","execution_count":24,"id":"c58b31fe","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:27.310556Z","iopub.status.busy":"2023-06-06T08:29:27.310149Z","iopub.status.idle":"2023-06-06T08:29:27.318591Z","shell.execute_reply":"2023-06-06T08:29:27.317485Z"},"papermill":{"duration":0.033616,"end_time":"2023-06-06T08:29:27.321006","exception":false,"start_time":"2023-06-06T08:29:27.28739","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["{'input_ids': [1, 4, 4, 4, 4, 4, 4, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer(\"A person who eats neighbourhood children\")"]},{"cell_type":"markdown","id":"54dcc571","metadata":{"papermill":{"duration":0.021429,"end_time":"2023-06-06T08:29:27.364296","exception":false,"start_time":"2023-06-06T08:29:27.342867","status":"completed"},"tags":[]},"source":["Then this will be the corresponding embedding \n","\n","# 3 | BERTDataset 📚\n","\n","The `BERTDataset` class is a `PyTorch dataset class` that can be used to `train a BERT model`. \n","* We take\n","* * A Data Pair\n","* * Tokenizer\n","* * A Sequence Length as inputs. \n","* We then `randomly` select a `sentence from the data pair` and use the `tokenizer to convert it into a sequence of tokens`. \n","* We then `randomly replace` some of the tokens with `[MASK] tokens`, and some of the `tokens with randomly generated tokens`. \n","* We then create a `segment label` for `each token`, which indicates `whether the token belongs` to the `first sentence` or the `second sentence`. \n","* Finally, we `pad` the sequence to the specified sequence length."]},{"cell_type":"code","execution_count":25,"id":"21e601b9","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-06-06T08:29:27.409376Z","iopub.status.busy":"2023-06-06T08:29:27.408967Z","iopub.status.idle":"2023-06-06T08:29:31.00683Z","shell.execute_reply":"2023-06-06T08:29:31.005636Z"},"papermill":{"duration":3.623526,"end_time":"2023-06-06T08:29:31.009575","exception":false,"start_time":"2023-06-06T08:29:27.386049","status":"completed"},"tags":[]},"outputs":[],"source":["from torch.utils.data import Dataset"]},{"cell_type":"code","execution_count":26,"id":"28345d54","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:31.055787Z","iopub.status.busy":"2023-06-06T08:29:31.054708Z","iopub.status.idle":"2023-06-06T08:29:31.059875Z","shell.execute_reply":"2023-06-06T08:29:31.058965Z"},"papermill":{"duration":0.030696,"end_time":"2023-06-06T08:29:31.062232","exception":false,"start_time":"2023-06-06T08:29:31.031536","status":"completed"},"tags":[]},"outputs":[],"source":["class BERTDataset(Dataset):pass"]},{"cell_type":"markdown","id":"6c9a3d4e","metadata":{"papermill":{"duration":0.022118,"end_time":"2023-06-06T08:29:31.106696","exception":false,"start_time":"2023-06-06T08:29:31.084578","status":"completed"},"tags":[]},"source":["Lets add some initializers to our class "]},{"cell_type":"code","execution_count":27,"id":"1b0d301b","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:31.152288Z","iopub.status.busy":"2023-06-06T08:29:31.1519Z","iopub.status.idle":"2023-06-06T08:29:31.158155Z","shell.execute_reply":"2023-06-06T08:29:31.157318Z"},"papermill":{"duration":0.031826,"end_time":"2023-06-06T08:29:31.160276","exception":false,"start_time":"2023-06-06T08:29:31.12845","status":"completed"},"tags":[]},"outputs":[],"source":["class BERTDataset(Dataset):\n","\n","    def __init__(self , data_pair , tokenizer , seq_len = 64):\n","\n","        self.tokenizer = tokenizer\n","        self.seq_len = seq_len\n","        \n","        self.lines = data_pair\n","        self.corpus_lines - len(data_pair)"]},{"cell_type":"markdown","id":"059011d7","metadata":{"papermill":{"duration":0.022021,"end_time":"2023-06-06T08:29:31.204745","exception":false,"start_time":"2023-06-06T08:29:31.182724","status":"completed"},"tags":[]},"source":["Now leta add some `getters and setters` "]},{"cell_type":"code","execution_count":28,"id":"4c9eb41d","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:31.250668Z","iopub.status.busy":"2023-06-06T08:29:31.250256Z","iopub.status.idle":"2023-06-06T08:29:31.260034Z","shell.execute_reply":"2023-06-06T08:29:31.258671Z"},"papermill":{"duration":0.035378,"end_time":"2023-06-06T08:29:31.262376","exception":false,"start_time":"2023-06-06T08:29:31.226998","status":"completed"},"tags":[]},"outputs":[],"source":["class BERTDataset(Dataset):\n","    def __init__(self, data_pair, tokenizer, seq_len=64):\n","\n","        self.tokenizer = tokenizer\n","        self.seq_len = seq_len\n","        self.corpus_lines = len(data_pair)\n","        self.lines = data_pair\n","\n","    __len__ = lambda self : self.corpus_lines\n","\n","    get_random_line = lambda self : self.lines[random.randrange(len(self.lines))][1]\n","    \n","    def get_corpus(self, item) : return self.lines[item][0], self.lines[item][1]\n","\n","    def get_sent(self, index):\n","\n","        t1, t2 = self.get_corpus_line(index)\n","\n","        if random.random() > 0.5 : \n","            \n","            return t1 , t2 , 1\n","        \n","        else : \n","            \n","            return t1, self.get_random_line() , 0"]},{"cell_type":"markdown","id":"eb8f7dc9","metadata":{"papermill":{"duration":0.021515,"end_time":"2023-06-06T08:29:31.305813","exception":false,"start_time":"2023-06-06T08:29:31.284298","status":"completed"},"tags":[]},"source":["Now lets assume we are on this point of the data"]},{"cell_type":"code","execution_count":29,"id":"0cd1ea23","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:31.35161Z","iopub.status.busy":"2023-06-06T08:29:31.351202Z","iopub.status.idle":"2023-06-06T08:29:31.358443Z","shell.execute_reply":"2023-06-06T08:29:31.357254Z"},"papermill":{"duration":0.032573,"end_time":"2023-06-06T08:29:31.36062","exception":false,"start_time":"2023-06-06T08:29:31.328047","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["\"I had a lot of fun with this competition and learned a lot about ratings systems.\\r\\nSadly, I only came 18th  )\\r\\nIf you're interested, you can download all of my code and analysis from my github repo   \\r\\nThere are\""]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["pairs[0][0]"]},{"cell_type":"markdown","id":"827ef681","metadata":{"papermill":{"duration":0.021911,"end_time":"2023-06-06T08:29:31.404934","exception":false,"start_time":"2023-06-06T08:29:31.383023","status":"completed"},"tags":[]},"source":["If we want to get this as a list"]},{"cell_type":"code","execution_count":30,"id":"58670031","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-06-06T08:29:31.450466Z","iopub.status.busy":"2023-06-06T08:29:31.450059Z","iopub.status.idle":"2023-06-06T08:29:31.457841Z","shell.execute_reply":"2023-06-06T08:29:31.456681Z"},"papermill":{"duration":0.033099,"end_time":"2023-06-06T08:29:31.459927","exception":false,"start_time":"2023-06-06T08:29:31.426828","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["['I',\n"," 'had',\n"," 'a',\n"," 'lot',\n"," 'of',\n"," 'fun',\n"," 'with',\n"," 'this',\n"," 'competition',\n"," 'and',\n"," 'learned',\n"," 'a',\n"," 'lot',\n"," 'about',\n"," 'ratings',\n"," 'systems.',\n"," 'Sadly,',\n"," 'I',\n"," 'only',\n"," 'came',\n"," '18th',\n"," ')',\n"," 'If',\n"," \"you're\",\n"," 'interested,',\n"," 'you',\n"," 'can',\n"," 'download',\n"," 'all',\n"," 'of',\n"," 'my',\n"," 'code',\n"," 'and',\n"," 'analysis',\n"," 'from',\n"," 'my',\n"," 'github',\n"," 'repo',\n"," 'There',\n"," 'are']"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["pairs[0][0].split()"]},{"cell_type":"markdown","id":"d946674f","metadata":{"papermill":{"duration":0.021728,"end_time":"2023-06-06T08:29:31.504066","exception":false,"start_time":"2023-06-06T08:29:31.482338","status":"completed"},"tags":[]},"source":["This is a little bit to overview"]},{"cell_type":"code","execution_count":31,"id":"27b579bc","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:31.550174Z","iopub.status.busy":"2023-06-06T08:29:31.549773Z","iopub.status.idle":"2023-06-06T08:29:31.556484Z","shell.execute_reply":"2023-06-06T08:29:31.555501Z"},"papermill":{"duration":0.032531,"end_time":"2023-06-06T08:29:31.558706","exception":false,"start_time":"2023-06-06T08:29:31.526175","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'I'"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["pairs[0][0].split()[0]"]},{"cell_type":"markdown","id":"80d8c5e6","metadata":{"papermill":{"duration":0.021858,"end_time":"2023-06-06T08:29:31.602849","exception":false,"start_time":"2023-06-06T08:29:31.580991","status":"completed"},"tags":[]},"source":["If we send this into our tokenizer "]},{"cell_type":"code","execution_count":32,"id":"14bfa289","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:31.651236Z","iopub.status.busy":"2023-06-06T08:29:31.650518Z","iopub.status.idle":"2023-06-06T08:29:31.657902Z","shell.execute_reply":"2023-06-06T08:29:31.656856Z"},"papermill":{"duration":0.033996,"end_time":"2023-06-06T08:29:31.660292","exception":false,"start_time":"2023-06-06T08:29:31.626296","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["{'input_ids': [1, 4, 2], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer(pairs[0][0].split()[0])"]},{"cell_type":"markdown","id":"a86a1c9b","metadata":{"papermill":{"duration":0.021872,"end_time":"2023-06-06T08:29:31.704443","exception":false,"start_time":"2023-06-06T08:29:31.682571","status":"completed"},"tags":[]},"source":["We focus on the `input_ids`"]},{"cell_type":"code","execution_count":33,"id":"7e70618d","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:31.750628Z","iopub.status.busy":"2023-06-06T08:29:31.750237Z","iopub.status.idle":"2023-06-06T08:29:31.757204Z","shell.execute_reply":"2023-06-06T08:29:31.756443Z"},"papermill":{"duration":0.032563,"end_time":"2023-06-06T08:29:31.759309","exception":false,"start_time":"2023-06-06T08:29:31.726746","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["[1, 4, 2]"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer(pairs[0][0].split()[0])[\"input_ids\"]"]},{"cell_type":"markdown","id":"42f55019","metadata":{"papermill":{"duration":0.02236,"end_time":"2023-06-06T08:29:31.804386","exception":false,"start_time":"2023-06-06T08:29:31.782026","status":"completed"},"tags":[]},"source":["If we want the middle element."]},{"cell_type":"code","execution_count":34,"id":"e5ee4218","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:31.856693Z","iopub.status.busy":"2023-06-06T08:29:31.855706Z","iopub.status.idle":"2023-06-06T08:29:31.864559Z","shell.execute_reply":"2023-06-06T08:29:31.863751Z"},"papermill":{"duration":0.040224,"end_time":"2023-06-06T08:29:31.867157","exception":false,"start_time":"2023-06-06T08:29:31.826933","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["[4]"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer(pairs[0][0].split()[0])[\"input_ids\"][1:-1]"]},{"cell_type":"markdown","id":"af5e90fb","metadata":{"papermill":{"duration":0.027957,"end_time":"2023-06-06T08:29:31.929948","exception":false,"start_time":"2023-06-06T08:29:31.901991","status":"completed"},"tags":[]},"source":["What we do is we randomly \n","* Either mask the token\n","* or replace it with some other random token\n","* or do nothing\n","\n","$80$% of the time we mask the otken. $10$% of the time we replace it and $10$% of the time we do nothing "]},{"cell_type":"code","execution_count":35,"id":"fa5f433d","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:31.981275Z","iopub.status.busy":"2023-06-06T08:29:31.980642Z","iopub.status.idle":"2023-06-06T08:29:31.996235Z","shell.execute_reply":"2023-06-06T08:29:31.995276Z"},"papermill":{"duration":0.043305,"end_time":"2023-06-06T08:29:31.998967","exception":false,"start_time":"2023-06-06T08:29:31.955662","status":"completed"},"tags":[]},"outputs":[],"source":["class BERTDataset(Dataset):\n","    def __init__(self, data_pair, tokenizer, seq_len=64):\n","\n","        self.tokenizer = tokenizer\n","        self.seq_len = seq_len\n","        self.corpus_lines = len(data_pair)\n","        self.lines = data_pair\n","\n","    __len__ = lambda self : self.corpus_lines\n","\n","    get_random_line = lambda self : self.lines[random.randrange(len(self.lines))][1]\n","    \n","    def get_corpus(self, item) : return self.lines[item][0], self.lines[item][1]\n","\n","    def get_sent(self, index):\n","\n","        t1, t2 = self.get_corpus_line(index)\n","\n","        if random.random() > 0.5 : return t1 , t2 , 1\n","        else : return t1, self.get_random_line() , 0\n","\n","    def random_word(self, sentence):\n","        \n","        tokens = sentence.split()\n","        output_label = []\n","        output = []\n","\n","        for i, token in tqdm.tqdm(enumerate(tokens) , total = len(tokens)):\n","            \n","            prob = random.random()\n","\n","            token_id = self.tokenizer(token)['input_ids'][1:-1]\n","\n","            if prob < 0.15:\n","                \n","                prob /= 0.15\n","\n","                if prob < 0.8:\n","                    \n","                    for i in range(len(token_id)):\n","                        \n","                        output.append(self.tokenizer.vocab['[MASK]'])\n","\n","                elif prob < 0.9:\n","                    \n","                    for i in range(len(token_id)):\n","                        \n","                        output.append(random.randrange(len(self.tokenizer.vocab)))\n","\n","\n","                else:\n","                    \n","                    output.append(token_id)\n","\n","                output_label.append(token_id)\n","\n","            else:\n","                \n","                output.append(token_id)\n","                \n","                for i in range(len(token_id)):\n","                    \n","                    output_label.append(0)\n","\n","        output = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output]))\n","        output_label = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output_label]))\n","        \n","        assert len(output) == len(output_label)\n","        \n","        return output, output_label"]},{"cell_type":"markdown","id":"5e540f78","metadata":{"papermill":{"duration":0.023053,"end_time":"2023-06-06T08:29:32.045546","exception":false,"start_time":"2023-06-06T08:29:32.022493","status":"completed"},"tags":[]},"source":["Now we just get the `padded tokens` out "]},{"cell_type":"code","execution_count":36,"id":"b0039a64","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:32.092959Z","iopub.status.busy":"2023-06-06T08:29:32.092583Z","iopub.status.idle":"2023-06-06T08:29:32.115782Z","shell.execute_reply":"2023-06-06T08:29:32.114549Z"},"papermill":{"duration":0.050205,"end_time":"2023-06-06T08:29:32.118422","exception":false,"start_time":"2023-06-06T08:29:32.068217","status":"completed"},"tags":[]},"outputs":[],"source":["class BERTDataset(Dataset):\n","    def __init__(self, data_pair, tokenizer, seq_len=64):\n","\n","        self.tokenizer = tokenizer\n","        self.seq_len = seq_len\n","        self.corpus_lines = len(data_pair)\n","        self.lines = data_pair\n","\n","    __len__ = lambda self : self.corpus_lines\n","\n","    get_random_line = lambda self : self.lines[random.randrange(len(self.lines))][1]\n","    \n","    def get_corpus(self, item) : return self.lines[item][0], self.lines[item][1]\n","\n","    def get_sent(self, index):\n","\n","        t1, t2 = self.get_corpus(index)\n","\n","        if random.random() > 0.5 : return t1 , t2 , 1\n","        else : return t1, self.get_random_line() , 0\n","\n","    def random_word(self, sentence):\n","        \n","        tokens = sentence.split()\n","        output_label = []\n","        output = []\n","\n","        for i, token in enumerate(tokens):\n","            \n","            prob = random.random()\n","\n","            token_id = self.tokenizer(token)['input_ids'][1:-1]\n","\n","            if prob < 0.15:\n","                \n","                prob /= 0.15\n","\n","                if prob < 0.8:\n","                    \n","                    for i in range(len(token_id)):\n","                        \n","                        output.append(self.tokenizer.vocab['[MASK]'])\n","\n","                elif prob < 0.9:\n","                    \n","                    for i in range(len(token_id)):\n","                        \n","                        output.append(random.randrange(len(self.tokenizer.vocab)))\n","\n","                else:\n","                    \n","                    output.append(token_id)\n","\n","                output_label.append(token_id)\n","\n","            else:\n","                \n","                output.append(token_id)\n","                \n","                for i in range(len(token_id)):\n","                    \n","                    output_label.append(0)\n","\n","        output = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output]))\n","        output_label = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output_label]))\n","        \n","        assert len(output) == len(output_label)\n","        \n","        return output, output_label\n","\n","    def __getitem__(self, item):\n","\n","        t1, t2, is_next_label = self.get_sent(item)\n","\n","        t1_random, t1_label = self.random_word(t1)\n","        t2_random, t2_label = self.random_word(t2)\n","\n","\n","        t1 = [self.tokenizer.vocab['[CLS]']] + t1_random + [self.tokenizer.vocab['[SEP]']]\n","        t1_label = [self.tokenizer.vocab['[PAD]']] + t1_label + [self.tokenizer.vocab['[PAD]']]\n","        \n","        t2 = t2_random + [self.tokenizer.vocab['[SEP]']]\n","        t2_label = t2_label + [self.tokenizer.vocab['[PAD]']]\n","\n","        segment_label = (\n","            [\n","                1 for _ in range(len(t1))\n","            ] + \n","            [\n","                2 for _ in range(len(t2))\n","            ]\n","        )[:self.seq_len]\n","        \n","        bert_input = (t1 + t2)[:self.seq_len]\n","        bert_label = (t1_label + t2_label)[:self.seq_len]\n","        \n","        padding = [\n","            self.tokenizer.vocab['[PAD]'] \n","            for _ in range(self.seq_len - len(bert_input))\n","        ]\n","        \n","        bert_input.extend(padding), bert_label.extend(padding), segment_label.extend(padding)\n","\n","        output = {\n","            \"bert_input\": bert_input,\n","            \"bert_label\": bert_label,\n","            \"segment_label\": segment_label,\n","            \"is_next\": is_next_label\n","        }\n","\n","        return {\n","            key: torch.tensor(value) \n","            for key, value in output.items()\n","        }"]},{"cell_type":"markdown","id":"f2ee5275","metadata":{"papermill":{"duration":0.022278,"end_time":"2023-06-06T08:29:32.163566","exception":false,"start_time":"2023-06-06T08:29:32.141288","status":"completed"},"tags":[]},"source":["# 4 | Positional Embedding 💪\n","\n","So this is a sine curve, with just differnet varations"]},{"cell_type":"code","execution_count":37,"id":"bbe5db7f","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-06-06T08:29:32.210542Z","iopub.status.busy":"2023-06-06T08:29:32.20995Z","iopub.status.idle":"2023-06-06T08:29:32.213738Z","shell.execute_reply":"2023-06-06T08:29:32.213023Z"},"papermill":{"duration":0.029691,"end_time":"2023-06-06T08:29:32.215746","exception":false,"start_time":"2023-06-06T08:29:32.186055","status":"completed"},"tags":[]},"outputs":[],"source":["from IPython.display import IFrame\n","import torch"]},{"cell_type":"code","execution_count":38,"id":"c67bce8b","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-06-06T08:29:32.263587Z","iopub.status.busy":"2023-06-06T08:29:32.263169Z","iopub.status.idle":"2023-06-06T08:29:32.269938Z","shell.execute_reply":"2023-06-06T08:29:32.268965Z"},"papermill":{"duration":0.033328,"end_time":"2023-06-06T08:29:32.272329","exception":false,"start_time":"2023-06-06T08:29:32.239001","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["\n","        <iframe\n","            width=\"1000\"\n","            height=\"200\"\n","            src=\"https://www.desmos.com/calculator/hiipopla5u\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","            \n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.IFrame at 0x7e45cf723e20>"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["IFrame(\"https://www.desmos.com/calculator/hiipopla5u\" , 1000 , 200)"]},{"cell_type":"markdown","id":"3ccaeb28","metadata":{"papermill":{"duration":0.024196,"end_time":"2023-06-06T08:29:32.319525","exception":false,"start_time":"2023-06-06T08:29:32.295329","status":"completed"},"tags":[]},"source":["|_____|_____\n","|---|---\n","|$$sin(x)$$|Red\n","|$$sin(\\frac{x}{2})$$|Blue\n","|$$sin(2x)$$|Green\n","\n","One thisng that this shows is that the `squeeshing` of the `sine curve` is `directly dependent` on the value of $x$. \n","\n","So we can say that a point projected on $sin(69)$ will be closer to the same point if projected on $sin(88)$ and would be comparetivery farther to if the same point was projected on $sin(6969)$.\n","\n","Now lets talk with respect to our taks. We have converted a sentence to a list of numbers. What if we project those numbers on a $sin()$ curve. Words having similar number will be closer and numbers having different numbers will be farther. \n","\n","Suprisingly we have a similar curve like the $sin()$ which is $cosine()/cos()$. \n","\n","So we have $2$ facotrs for determining the positional embeddings of words in a sentence. \n","\n","So now we have the \n","* words as numbers\n","* Their positions in the form of $sin()/cosine()$ curves\n","\n","We use the formula $$sin(\\frac{position}{1000^{\\frac{2i}{dimension}}})$$\n","and $$cos(\\frac{position}{1000^{\\frac{2(i + 1)}{dimension}}})$$\n","\n","\n","The `PositionalEmbedding` class in `PyTorch` is a module that adds `positional information` to a sequence of tokens. \n","* We first create a `zero tensor of size` \n","```\n","(max_len , d_model)\n","```\n","where `max_len is the maximum length` of a sequence and `d_model is the dimension of the embedding space`. \n","* We then assign `each position` a `unique value` using a `sine and cosine function`. \n","* We then `add the positional embedding` to the `embedding of each token` in the sequence."]},{"cell_type":"code","execution_count":39,"id":"9780b180","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:32.368242Z","iopub.status.busy":"2023-06-06T08:29:32.367813Z","iopub.status.idle":"2023-06-06T08:29:32.376345Z","shell.execute_reply":"2023-06-06T08:29:32.375251Z"},"papermill":{"duration":0.036059,"end_time":"2023-06-06T08:29:32.378555","exception":false,"start_time":"2023-06-06T08:29:32.342496","status":"completed"},"tags":[]},"outputs":[],"source":["class PositionalEmbedding(torch.nn.Module):\n","\n","    def __init__(self, d_model, max_len=128):\n","        super().__init__()\n","\n","        pe = torch.zeros(max_len, d_model).float()\n","        pe.require_grad = False\n","\n","        for pos in range(max_len):   \n","\n","            for i in range(0, d_model, 2):   \n","                \n","                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n","                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n","\n","\n","        self.pe = pe.unsqueeze(0)   \n","\n","    def forward(self, x): return self.pe"]},{"cell_type":"markdown","id":"ccfa62a7","metadata":{"papermill":{"duration":0.022557,"end_time":"2023-06-06T08:29:32.424318","exception":false,"start_time":"2023-06-06T08:29:32.401761","status":"completed"},"tags":[]},"source":["# 5 | BERTEmbedding 🌐\n","\n","Embedding is like a mapping of a object into a numerical value. \n","\n","Assume we have the character `King`. And a factor `wealth`. If we see intuitevily, a connecting number between `King` and `Wealth` might be $10$. \n","\n","This is like defining a `non-numerical object` with $1$ factor. Lets say we have $2$ facotors, `wealth and poverty`. Again if we see intuitively, the connection might be like $[10 , 0]$. \n","\n","Similarly we can do this for a number of words, like might be `Advisor`, `Queen`. Making it a matrix like \n","\n","```\n","[[10 , 9 , 8] , \n"," [1 , 0 , 3]] \n","```\n","\n","Where $1$ column represents $1$ particular entity, and $1$ row represents $1$ attribute.\n","\n","Similary now we can increase the nummber of rows and number of column, according to our need.\n","\n","The same concept is applied to `Embedding Tables`. We can even say them `EMbedding Matrices`. The only difference is that they do not use partuclar defined facotrs like `wealth/poverty`. Rather a bunch of neural networks to create the `Matrix`\n","\n","Now lets try to understand this for a `larger set` of data of text. At the time of `intializing` we `do not know any relations` between any of the words, as we go through the corpus of data and `find the words that are used in a particular combination frequently`, we slowly change the `vector representation` of those words `to be close to each other`.\n"]},{"cell_type":"code","execution_count":40,"id":"134068a3","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:32.472059Z","iopub.status.busy":"2023-06-06T08:29:32.471663Z","iopub.status.idle":"2023-06-06T08:29:32.507984Z","shell.execute_reply":"2023-06-06T08:29:32.506893Z"},"papermill":{"duration":0.063307,"end_time":"2023-06-06T08:29:32.510391","exception":false,"start_time":"2023-06-06T08:29:32.447084","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Embedding(3, 2)"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["torch.nn.Embedding(3 , 2)"]},{"cell_type":"markdown","id":"edad138e","metadata":{"papermill":{"duration":0.024637,"end_time":"2023-06-06T08:29:32.558959","exception":false,"start_time":"2023-06-06T08:29:32.534322","status":"completed"},"tags":[]},"source":["\n","The `BERTEmbedding class` is a `PyTorch` class that implements the `Embedding Layer` for the `BERT model`. It takes three arguments in its constructor: \n","* Size of the Vocablary `vocab_size` \n","* Size of the Embedding `embed_size` \n","* Droput Rate `dropout`. \n","\n","The `forward method` of the BERTEmbedding class takes two arguments: \n","* Sequences `sequence` \n","* Segements `segment_label`. \n","The forward method  \n","* We first compute the `token embedding` , the `positional embedding` , and the `segment embedding`. \n","* We then sum these three embeddings and passe the result through a dropout layer. The output of the dropout layer is the embedding vector for the current token."]},{"cell_type":"code","execution_count":41,"id":"171c92ce","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:32.609453Z","iopub.status.busy":"2023-06-06T08:29:32.608714Z","iopub.status.idle":"2023-06-06T08:29:32.617418Z","shell.execute_reply":"2023-06-06T08:29:32.61631Z"},"papermill":{"duration":0.036493,"end_time":"2023-06-06T08:29:32.619977","exception":false,"start_time":"2023-06-06T08:29:32.583484","status":"completed"},"tags":[]},"outputs":[],"source":["class BERTEmbedding(torch.nn.Module):\n","\n","    def __init__(self, vocab_size, embed_size, seq_len=64, dropout=0.1):\n","\n","        super().__init__()\n","\n","        self.embed_size = embed_size\n","\n","        self.token = torch.nn.Embedding(vocab_size, embed_size, padding_idx=0)\n","        self.segment = torch.nn.Embedding(3, embed_size, padding_idx=0)\n","\n","        self.position = PositionalEmbedding(d_model=embed_size, max_len=seq_len)\n","        self.dropout = torch.nn.Dropout(p=dropout)\n","       \n","    def forward(self, sequence, segment_label):\n","\n","        x = self.token(sequence) + self.position(sequence) + self.segment(segment_label)\n","\n","        return self.dropout(x)"]},{"cell_type":"markdown","id":"15f57b41","metadata":{"papermill":{"duration":0.022891,"end_time":"2023-06-06T08:29:32.666898","exception":false,"start_time":"2023-06-06T08:29:32.644007","status":"completed"},"tags":[]},"source":["# 6 | MultiHeadedAttention 🔱\n","\n","<img src = \"https://miro.medium.com/v2/resize:fit:856/1*ZCFSvkKtppgew3cc7BIaug.png\" width = 400>\n","\n","Now we will talk in the terms of this image(it is easier). Focus on the right part of the diagram\n","\n","We have made our input the way we wanted, Now we need to apply `Masked Multi-Head Attention`\n","\n","What we do is we try to pass these embedding through $3$ different `networks/ Linear Layers` named as \n","\n","|Name|Symbol\n","|---|---\n","|$Key$|$K$\n","|$Query$|$Q$\n","|$Value$|$V$\n","\n","an then apply the formula \n","\n","$$f(x) = softmax(\\frac{QK^T}{\\sqrt{d_k}})$$\n","\n","This is what we call the `Multi Head Attention Mechanism`\n","\n","The `MultiHeadedAttention class` is a `PyTorch` module that `implements` the `multi-head attention mechanism`. It takes four arguments in its constructor: \n","* Number of Heads `heads`\n","* Size of the Heads `d_model`\n","* Dropout Rate `dropout` \n","* Masked Areas `mask`.\n","The `forward method` of the MultiHeadedAttention class takes four arguments: \n","* Query `query`\n","* Key `key`\n","* Value `value`\n","* Mask `mask`\n","\n","* We first compute the attention weights \n","* Then compute the attention output\n","* And finally passe the attention output through a linear layer. The output of the linear layer is the attention-weighted sum of the value vectors."]},{"cell_type":"code","execution_count":42,"id":"2f9631d5","metadata":{"execution":{"iopub.execute_input":"2023-06-06T08:29:32.715163Z","iopub.status.busy":"2023-06-06T08:29:32.714757Z","iopub.status.idle":"2023-06-06T08:29:32.728164Z","shell.execute_reply":"2023-06-06T08:29:32.72711Z"},"papermill":{"duration":0.040063,"end_time":"2023-06-06T08:29:32.730321","exception":false,"start_time":"2023-06-06T08:29:32.690258","status":"completed"},"tags":[]},"outputs":[],"source":["class MultiHeadedAttention(torch.nn.Module):\n","    \n","    def __init__(self, heads, d_model, dropout=0.1):\n","        \n","        super(MultiHeadedAttention, self).__init__()\n","        \n","        assert d_model % heads == 0\n","        \n","        self.d_k = d_model // heads\n","        \n","        self.heads = heads\n","        self.dropout = torch.nn.Dropout(dropout)\n","\n","        self.query = torch.nn.Linear(d_model, d_model)\n","        self.key = torch.nn.Linear(d_model, d_model)\n","        self.value = torch.nn.Linear(d_model, d_model)\n","        \n","        self.output_linear = torch.nn.Linear(d_model, d_model)\n","        \n","    def forward(self, query, key, value, mask):\n","\n","        query = self.query(query)\n","        key = self.key(key)        \n","        value = self.value(value)   \n","\n","        query = query.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)   \n","        key = key.view(key.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)  \n","        value = value.view(value.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)  \n","\n","        scores = torch.matmul(query, key.permute(0, 1, 3, 2)) / math.sqrt(query.size(-1))\n","\n","        scores = scores.masked_fill(mask == 0, -1e9)    \n","\n","        weights = F.softmax(scores, dim=-1)           \n","        weights = self.dropout(weights)\n","\n","        context = torch.matmul(weights, value)\n","\n","        context = context.permute(0, 2, 1, 3).contiguous().view(context.shape[0], -1, self.heads * self.d_k)\n","\n","        return self.output_linear(context)"]},{"cell_type":"markdown","id":"2b36d068","metadata":{"papermill":{"duration":0.022866,"end_time":"2023-06-06T08:29:32.776123","exception":false,"start_time":"2023-06-06T08:29:32.753257","status":"completed"},"tags":[]},"source":["This not the $BERT$. THis is just the starting of `Multi Head Attention`. We will cover up `BERT` in upcoming days \n","\n","# 7 | Ending\n","\n","**THAT IT FOR TODAY GUYS**\n","\n","**WE WILL IMPROVE THIS IN UPCOMING VERSIONS**\n","\n","**PLEASE COMMENT YOUR THOUGHTS, HIHGLY APPRICIATED**\n","\n","**DONT FORGET TO MAKE AN UPVOTE, IF YOU LIKED MY WORK**\n","\n","<img src = \"https://i.imgflip.com/19aadg.jpg\">\n","\n","**PEACE OUT $:)$**"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"papermill":{"default_parameters":{},"duration":24.140008,"end_time":"2023-06-06T08:29:34.323978","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-06-06T08:29:10.18397","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}
