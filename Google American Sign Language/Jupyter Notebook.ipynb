{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ayushs9020/understanding-the-competition-asl?scriptVersionId=129180290\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"bd09317d","metadata":{"papermill":{"duration":0.005285,"end_time":"2023-05-11T15:25:44.948947","exception":false,"start_time":"2023-05-11T15:25:44.943662","status":"completed"},"tags":[]},"source":["# Google American Sign Language\n","\n","So Google is again here with another great competition **`Google - American Sign Language Fingerspelling Recognition`**\n","\n","Lets first understand the competition in detail \n","\n","* **American Sign Language FingerSpelling** - $American$ $Sign$ $Language$ $FingerSpelling$ is a method used in sign language to spell out individual letters or words. It involves using specific handshapes and movements to represent each letter of the alphabet. $FingerSpelling$ is an important tool for communication and is often used to convey names, places, or unfamiliar words in $ASL$. It requires practice and skill to execute accurately and fluently, and NO!!, (middle finger is not included in this language)\n","\n","<img src = \"https://d.newsweek.com/en/full/1394686/asl-getty-images.jpg\">"]},{"cell_type":"code","execution_count":1,"id":"71a2244f","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-05-11T15:25:44.959807Z","iopub.status.busy":"2023-05-11T15:25:44.959397Z","iopub.status.idle":"2023-05-11T15:25:45.025219Z","shell.execute_reply":"2023-05-11T15:25:45.024091Z"},"papermill":{"duration":0.075258,"end_time":"2023-05-11T15:25:45.028924","exception":false,"start_time":"2023-05-11T15:25:44.953666","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/asl-fingerspelling/supplemental_metadata.csv\n","/kaggle/input/asl-fingerspelling/character_to_prediction_index.json\n","/kaggle/input/asl-fingerspelling/train.csv\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/371169664.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/369584223.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1682915129.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/775880548.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/2100073719.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1650637630.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1471096258.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/86446671.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/897287709.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/333606065.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/2057261717.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/971104021.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/471766624.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1881515495.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1857374937.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/293101677.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/595441814.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1279694894.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/756566775.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1471341722.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1112747136.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1756773911.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/33432165.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1779786322.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1755047076.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1624527344.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/597469033.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1505488209.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1144115867.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1249944812.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1118603411.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/676340265.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/716508881.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/736978972.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1579345709.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/285528514.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1047404576.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/697480828.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1032110484.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/440362090.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/924144755.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/639454452.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/236903981.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/636900267.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1176508147.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/131312512.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/778903889.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/193950599.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/442061898.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/95345213.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1407656790.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/680303484.parquet\n","/kaggle/input/asl-fingerspelling/supplemental_landmarks/1727438550.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1358493307.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/495378749.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/2118949241.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/5414471.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1133664520.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/433948159.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1920330615.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/683666742.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1365772051.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/939623093.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1405046009.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/450474571.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/149822653.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/152029243.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1552432300.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1365275733.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1880177496.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1021040628.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1557244878.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1497621680.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/522550314.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/649779897.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1905462118.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/175396851.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/638508439.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/532011803.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/2072296290.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1906357076.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/2026717426.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1967755728.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1785039512.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1643479812.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1134756332.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1019715464.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/566963657.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/568753759.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1726141437.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/296317215.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/234418913.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/614661748.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/654436541.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/474255203.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1662742697.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1099408314.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1341528257.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/105143404.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/527708222.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/882979387.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/933868835.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1969985709.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/425182931.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1098899348.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1255240050.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1997878546.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/128822441.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/388576474.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/546816846.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1320204318.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1448136004.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/349393104.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/2072876091.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/871280215.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1562234637.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1865557033.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1664666588.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/1647220008.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/2036580525.parquet\n","/kaggle/input/asl-fingerspelling/train_landmarks/169560558.parquet\n"]}],"source":["import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","execution_count":2,"id":"338432d5","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-05-11T15:25:45.040154Z","iopub.status.busy":"2023-05-11T15:25:45.039775Z","iopub.status.idle":"2023-05-11T15:26:21.758516Z","shell.execute_reply":"2023-05-11T15:26:21.756998Z"},"papermill":{"duration":36.727285,"end_time":"2023-05-11T15:26:21.760933","exception":false,"start_time":"2023-05-11T15:25:45.033648","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in links: https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html\r\n","Collecting torcharrow\r\n","  Downloading https://download.pytorch.org/whl/nightly/torcharrow-0.2.0a0.dev20230511-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hCollecting typing\r\n","  Downloading typing-3.7.4.3.tar.gz (78 kB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n","\u001b[?25hCollecting numpy==1.21.4\r\n","  Downloading numpy-1.21.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hRequirement already satisfied: arrow in /opt/conda/lib/python3.10/site-packages (from torcharrow) (1.2.3)\r\n","Requirement already satisfied: cffi in /opt/conda/lib/python3.10/site-packages (from torcharrow) (1.15.1)\r\n","Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from torcharrow) (0.9.0)\r\n","Requirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from torcharrow) (9.0.0)\r\n","Requirement already satisfied: typing-inspect in /opt/conda/lib/python3.10/site-packages (from torcharrow) (0.8.0)\r\n","Collecting pandas<=1.3.5\r\n","  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.10/site-packages (from pandas<=1.3.5->torcharrow) (2023.3)\r\n","Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.10/site-packages (from pandas<=1.3.5->torcharrow) (2.8.2)\r\n","Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi->torcharrow) (2.21)\r\n","Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.10/site-packages (from typing-inspect->torcharrow) (4.5.0)\r\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect->torcharrow) (1.0.0)\r\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7.3->pandas<=1.3.5->torcharrow) (1.16.0)\r\n","Building wheels for collected packages: typing\r\n","  Building wheel for typing (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n","\u001b[?25h  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26324 sha256=a21c010332e503d7ec579c7859af4921d2a487252decc42c2458e8af248e2f4b\r\n","  Stored in directory: /root/.cache/pip/wheels/7c/d0/9e/1f26ebb66d9e1732e4098bc5a6c2d91f6c9a529838f0284890\r\n","Successfully built typing\r\n","Installing collected packages: typing, numpy, pandas, torcharrow\r\n","  Attempting uninstall: numpy\r\n","    Found existing installation: numpy 1.23.5\r\n","    Uninstalling numpy-1.23.5:\r\n","      Successfully uninstalled numpy-1.23.5\r\n","  Attempting uninstall: pandas\r\n","    Found existing installation: pandas 1.5.3\r\n","    Uninstalling pandas-1.5.3:\r\n","      Successfully uninstalled pandas-1.5.3\r\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n","xarray 2023.4.1 requires pandas>=1.4, but you have pandas 1.3.5 which is incompatible.\r\n","woodwork 0.23.0 requires pandas<2.0.0,>=1.4.3, but you have pandas 1.3.5 which is incompatible.\r\n","tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\r\n","tensorflow-serving-api 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\r\n","pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.9.3 which is incompatible.\r\n","librosa 0.10.0.post2 requires soundfile>=0.12.1, but you have soundfile 0.11.0 which is incompatible.\r\n","featuretools 1.25.0 requires pandas<2.0.0,>=1.5.0, but you have pandas 1.3.5 which is incompatible.\r\n","beatrix-jupyterlab 2023.46.184821 requires jupyter-server~=1.16, but you have jupyter-server 2.5.0 which is incompatible.\r\n","apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\u001b[0m\u001b[31m\r\n","\u001b[0mSuccessfully installed numpy-1.21.4 pandas-1.3.5 torcharrow-0.2.0a0.dev20230511 typing-3.7.4.3\r\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install --pre torcharrow -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html"]},{"cell_type":"code","execution_count":3,"id":"bc4d85d7","metadata":{"execution":{"iopub.execute_input":"2023-05-11T15:26:21.781874Z","iopub.status.busy":"2023-05-11T15:26:21.781473Z","iopub.status.idle":"2023-05-11T15:26:26.457115Z","shell.execute_reply":"2023-05-11T15:26:26.455902Z"},"papermill":{"duration":4.689764,"end_time":"2023-05-11T15:26:26.459984","exception":false,"start_time":"2023-05-11T15:26:21.77022","status":"completed"},"tags":[]},"outputs":[],"source":["import pandas as pd \n","import torchdata\n","import torcharrow"]},{"cell_type":"markdown","id":"4fde3924","metadata":{"papermill":{"duration":0.009254,"end_time":"2023-05-11T15:26:26.479352","exception":false,"start_time":"2023-05-11T15:26:26.470098","status":"completed"},"tags":[]},"source":["# 1 | Train \n","\n","So this our `train data`, this data contains all the information related to the the `training` and `target` values. As of I think `file_id` , `sequence_id` , `participant_id`, are not that important for the model, and thus it would be better if we just remove them"]},{"cell_type":"code","execution_count":4,"id":"e799e52f","metadata":{"execution":{"iopub.execute_input":"2023-05-11T15:26:26.500471Z","iopub.status.busy":"2023-05-11T15:26:26.499706Z","iopub.status.idle":"2023-05-11T15:26:26.703929Z","shell.execute_reply":"2023-05-11T15:26:26.702694Z"},"papermill":{"duration":0.217773,"end_time":"2023-05-11T15:26:26.70661","exception":false,"start_time":"2023-05-11T15:26:26.488837","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>path</th>\n","      <th>file_id</th>\n","      <th>sequence_id</th>\n","      <th>participant_id</th>\n","      <th>phrase</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_landmarks/5414471.parquet</td>\n","      <td>5414471</td>\n","      <td>1816796431</td>\n","      <td>217</td>\n","      <td>3 creekhouse</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_landmarks/5414471.parquet</td>\n","      <td>5414471</td>\n","      <td>1816825349</td>\n","      <td>107</td>\n","      <td>scales/kuhaylah</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_landmarks/5414471.parquet</td>\n","      <td>5414471</td>\n","      <td>1816862427</td>\n","      <td>0</td>\n","      <td>hentaihubs.com</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_landmarks/5414471.parquet</td>\n","      <td>5414471</td>\n","      <td>1816909464</td>\n","      <td>1</td>\n","      <td>1383 william lanier</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_landmarks/5414471.parquet</td>\n","      <td>5414471</td>\n","      <td>1816967051</td>\n","      <td>63</td>\n","      <td>988 franklin lane</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>67282</th>\n","      <td>train_landmarks/2118949241.parquet</td>\n","      <td>2118949241</td>\n","      <td>388192924</td>\n","      <td>88</td>\n","      <td>431-366-2913</td>\n","    </tr>\n","    <tr>\n","      <th>67283</th>\n","      <td>train_landmarks/2118949241.parquet</td>\n","      <td>2118949241</td>\n","      <td>388225542</td>\n","      <td>154</td>\n","      <td>994-392-3850</td>\n","    </tr>\n","    <tr>\n","      <th>67284</th>\n","      <td>train_landmarks/2118949241.parquet</td>\n","      <td>2118949241</td>\n","      <td>388232076</td>\n","      <td>95</td>\n","      <td>https://www.tianjiagenomes.com</td>\n","    </tr>\n","    <tr>\n","      <th>67285</th>\n","      <td>train_landmarks/2118949241.parquet</td>\n","      <td>2118949241</td>\n","      <td>388235284</td>\n","      <td>36</td>\n","      <td>90 kerwood circle</td>\n","    </tr>\n","    <tr>\n","      <th>67286</th>\n","      <td>train_landmarks/2118949241.parquet</td>\n","      <td>2118949241</td>\n","      <td>388332538</td>\n","      <td>176</td>\n","      <td>802 co 66b</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>67287 rows × 5 columns</p>\n","</div>"],"text/plain":["                                     path     file_id  sequence_id  \\\n","0         train_landmarks/5414471.parquet     5414471   1816796431   \n","1         train_landmarks/5414471.parquet     5414471   1816825349   \n","2         train_landmarks/5414471.parquet     5414471   1816862427   \n","3         train_landmarks/5414471.parquet     5414471   1816909464   \n","4         train_landmarks/5414471.parquet     5414471   1816967051   \n","...                                   ...         ...          ...   \n","67282  train_landmarks/2118949241.parquet  2118949241    388192924   \n","67283  train_landmarks/2118949241.parquet  2118949241    388225542   \n","67284  train_landmarks/2118949241.parquet  2118949241    388232076   \n","67285  train_landmarks/2118949241.parquet  2118949241    388235284   \n","67286  train_landmarks/2118949241.parquet  2118949241    388332538   \n","\n","       participant_id                          phrase  \n","0                 217                    3 creekhouse  \n","1                 107                 scales/kuhaylah  \n","2                   0                  hentaihubs.com  \n","3                   1             1383 william lanier  \n","4                  63               988 franklin lane  \n","...               ...                             ...  \n","67282              88                    431-366-2913  \n","67283             154                    994-392-3850  \n","67284              95  https://www.tianjiagenomes.com  \n","67285              36               90 kerwood circle  \n","67286             176                      802 co 66b  \n","\n","[67287 rows x 5 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["train = pd.read_csv(\"/kaggle/input/asl-fingerspelling/train.csv\")\n","train"]},{"cell_type":"markdown","id":"4f8c9744","metadata":{"papermill":{"duration":0.009438,"end_time":"2023-05-11T15:26:26.725875","exception":false,"start_time":"2023-05-11T15:26:26.716437","status":"completed"},"tags":[]},"source":["The `path` shows where the `parquet file` is located. You could also have just used the `file_id` for lacating the corresponding `parquet_file`, as if we split the `path` into `train_landmarks/` and the other part, we basically get the same value. \n","\n","We used `path` instead of the `file_id`. As file paths are easier to process when we try to find the data\n","\n","The other column `phrase` is the target column, we will train for \n","\n","# 2 | Supplemental MetData\n","\n","Suplement data looks like the same, its just we will test our model on this data "]},{"cell_type":"code","execution_count":5,"id":"dee4165a","metadata":{"execution":{"iopub.execute_input":"2023-05-11T15:26:26.74697Z","iopub.status.busy":"2023-05-11T15:26:26.746543Z","iopub.status.idle":"2023-05-11T15:26:26.917324Z","shell.execute_reply":"2023-05-11T15:26:26.916268Z"},"papermill":{"duration":0.184227,"end_time":"2023-05-11T15:26:26.919757","exception":false,"start_time":"2023-05-11T15:26:26.73553","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>path</th>\n","      <th>file_id</th>\n","      <th>sequence_id</th>\n","      <th>participant_id</th>\n","      <th>phrase</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>supplemental_landmarks/33432165.parquet</td>\n","      <td>33432165</td>\n","      <td>1535467051</td>\n","      <td>251</td>\n","      <td>coming up with killer sound bites</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>supplemental_landmarks/33432165.parquet</td>\n","      <td>33432165</td>\n","      <td>1535499058</td>\n","      <td>239</td>\n","      <td>we better investigate this</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>supplemental_landmarks/33432165.parquet</td>\n","      <td>33432165</td>\n","      <td>1535530550</td>\n","      <td>245</td>\n","      <td>interesting observation was made</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>supplemental_landmarks/33432165.parquet</td>\n","      <td>33432165</td>\n","      <td>1535545499</td>\n","      <td>38</td>\n","      <td>victims deserve more redress</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>supplemental_landmarks/33432165.parquet</td>\n","      <td>33432165</td>\n","      <td>1535585216</td>\n","      <td>254</td>\n","      <td>knee bone is connected to the thigh bone</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>52953</th>\n","      <td>supplemental_landmarks/2100073719.parquet</td>\n","      <td>2100073719</td>\n","      <td>1090866442</td>\n","      <td>239</td>\n","      <td>want to join us for lunch</td>\n","    </tr>\n","    <tr>\n","      <th>52954</th>\n","      <td>supplemental_landmarks/2100073719.parquet</td>\n","      <td>2100073719</td>\n","      <td>1090966452</td>\n","      <td>95</td>\n","      <td>this phenomenon will never occur</td>\n","    </tr>\n","    <tr>\n","      <th>52955</th>\n","      <td>supplemental_landmarks/2100073719.parquet</td>\n","      <td>2100073719</td>\n","      <td>1091005846</td>\n","      <td>40</td>\n","      <td>the winner of the race</td>\n","    </tr>\n","    <tr>\n","      <th>52956</th>\n","      <td>supplemental_landmarks/2100073719.parquet</td>\n","      <td>2100073719</td>\n","      <td>1091011550</td>\n","      <td>241</td>\n","      <td>are you sure you want this</td>\n","    </tr>\n","    <tr>\n","      <th>52957</th>\n","      <td>supplemental_landmarks/2100073719.parquet</td>\n","      <td>2100073719</td>\n","      <td>1091039755</td>\n","      <td>122</td>\n","      <td>every saturday he folds the laundry</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>52958 rows × 5 columns</p>\n","</div>"],"text/plain":["                                            path     file_id  sequence_id  \\\n","0        supplemental_landmarks/33432165.parquet    33432165   1535467051   \n","1        supplemental_landmarks/33432165.parquet    33432165   1535499058   \n","2        supplemental_landmarks/33432165.parquet    33432165   1535530550   \n","3        supplemental_landmarks/33432165.parquet    33432165   1535545499   \n","4        supplemental_landmarks/33432165.parquet    33432165   1535585216   \n","...                                          ...         ...          ...   \n","52953  supplemental_landmarks/2100073719.parquet  2100073719   1090866442   \n","52954  supplemental_landmarks/2100073719.parquet  2100073719   1090966452   \n","52955  supplemental_landmarks/2100073719.parquet  2100073719   1091005846   \n","52956  supplemental_landmarks/2100073719.parquet  2100073719   1091011550   \n","52957  supplemental_landmarks/2100073719.parquet  2100073719   1091039755   \n","\n","       participant_id                                    phrase  \n","0                 251         coming up with killer sound bites  \n","1                 239                we better investigate this  \n","2                 245          interesting observation was made  \n","3                  38              victims deserve more redress  \n","4                 254  knee bone is connected to the thigh bone  \n","...               ...                                       ...  \n","52953             239                 want to join us for lunch  \n","52954              95          this phenomenon will never occur  \n","52955              40                    the winner of the race  \n","52956             241                are you sure you want this  \n","52957             122       every saturday he folds the laundry  \n","\n","[52958 rows x 5 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["supplemental_metdata = pd.read_csv(\"/kaggle/input/asl-fingerspelling/supplemental_metadata.csv\")\n","supplemental_metdata"]},{"cell_type":"code","execution_count":6,"id":"ca5a0019","metadata":{"execution":{"iopub.execute_input":"2023-05-11T15:26:26.941836Z","iopub.status.busy":"2023-05-11T15:26:26.941453Z","iopub.status.idle":"2023-05-11T15:26:26.956919Z","shell.execute_reply":"2023-05-11T15:26:26.95578Z"},"papermill":{"duration":0.029391,"end_time":"2023-05-11T15:26:26.959386","exception":false,"start_time":"2023-05-11T15:26:26.929995","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>path</th>\n","      <th>phrase</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>supplemental_landmarks/33432165.parquet</td>\n","      <td>coming up with killer sound bites</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>supplemental_landmarks/33432165.parquet</td>\n","      <td>we better investigate this</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>supplemental_landmarks/33432165.parquet</td>\n","      <td>interesting observation was made</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>supplemental_landmarks/33432165.parquet</td>\n","      <td>victims deserve more redress</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>supplemental_landmarks/33432165.parquet</td>\n","      <td>knee bone is connected to the thigh bone</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>52953</th>\n","      <td>supplemental_landmarks/2100073719.parquet</td>\n","      <td>want to join us for lunch</td>\n","    </tr>\n","    <tr>\n","      <th>52954</th>\n","      <td>supplemental_landmarks/2100073719.parquet</td>\n","      <td>this phenomenon will never occur</td>\n","    </tr>\n","    <tr>\n","      <th>52955</th>\n","      <td>supplemental_landmarks/2100073719.parquet</td>\n","      <td>the winner of the race</td>\n","    </tr>\n","    <tr>\n","      <th>52956</th>\n","      <td>supplemental_landmarks/2100073719.parquet</td>\n","      <td>are you sure you want this</td>\n","    </tr>\n","    <tr>\n","      <th>52957</th>\n","      <td>supplemental_landmarks/2100073719.parquet</td>\n","      <td>every saturday he folds the laundry</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>52958 rows × 2 columns</p>\n","</div>"],"text/plain":["                                            path  \\\n","0        supplemental_landmarks/33432165.parquet   \n","1        supplemental_landmarks/33432165.parquet   \n","2        supplemental_landmarks/33432165.parquet   \n","3        supplemental_landmarks/33432165.parquet   \n","4        supplemental_landmarks/33432165.parquet   \n","...                                          ...   \n","52953  supplemental_landmarks/2100073719.parquet   \n","52954  supplemental_landmarks/2100073719.parquet   \n","52955  supplemental_landmarks/2100073719.parquet   \n","52956  supplemental_landmarks/2100073719.parquet   \n","52957  supplemental_landmarks/2100073719.parquet   \n","\n","                                         phrase  \n","0             coming up with killer sound bites  \n","1                    we better investigate this  \n","2              interesting observation was made  \n","3                  victims deserve more redress  \n","4      knee bone is connected to the thigh bone  \n","...                                         ...  \n","52953                 want to join us for lunch  \n","52954          this phenomenon will never occur  \n","52955                    the winner of the race  \n","52956                are you sure you want this  \n","52957       every saturday he folds the laundry  \n","\n","[52958 rows x 2 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["supplemental_metdata.drop([\"file_id\" , \"sequence_id\" , \"participant_id\"] , axis = 1 , inplace = True)\n","supplemental_metdata"]},{"cell_type":"markdown","id":"2218edcf","metadata":{"papermill":{"duration":0.010365,"end_time":"2023-05-11T15:26:26.980243","exception":false,"start_time":"2023-05-11T15:26:26.969878","status":"completed"},"tags":[]},"source":["# 3 | Parquet Files\n","Parquet files are a little bit complicated to work with. But you can find particular methods in `pandas` and `tensorflow`. \n","\n","`Pytorch` has a specialised library for **loading parquet data from pipelines/paths**. You can find it **[torch.datapipes.iter.ParquetDataFrameLoader](https://pytorch.org/data/main/generated/torchdata.datapipes.iter.ParquetDataFrameLoader.html)**, You need to install `torcharrow` to use this library, `torcharrow` is not in stable release, but you can still install it using \n","```\n","! pip install --pre torcharrow -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html\n","import torcharraow\n","```\n","Though even after installing it is showing error to me, I dont know if it is the problem with my system only or not. If you find any leads, please tell me :)\n","\n","Here is the **[Github](https://github.com/pytorch/torcharrow)** for `torcharrow`\n","\n","Here is the code for loading the data\n","```\n","torchdata.datapipes.iter.ParquetDataFrameLoader(train[\"path\"])\n","```\n","\n","Now lets see how we are given the data \n","\n","I dont know but the `sample_data` is not shown in the actual release of the notebook. but can be seen in the `edit` mode. \n","\n","It has $1,73,385$ rows and $1,630$ columns"]},{"cell_type":"code","execution_count":7,"id":"0f7e513a","metadata":{"execution":{"iopub.execute_input":"2023-05-11T15:26:27.006583Z","iopub.status.busy":"2023-05-11T15:26:27.006197Z","iopub.status.idle":"2023-05-11T15:26:27.558885Z","shell.execute_reply":"2023-05-11T15:26:27.557215Z"},"papermill":{"duration":0.567599,"end_time":"2023-05-11T15:26:27.561451","exception":true,"start_time":"2023-05-11T15:26:26.993852","status":"failed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Unexpected exception formatting exception. Falling back to standard exception\n"]},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"/tmp/ipykernel_20/658195339.py\", line 1, in <module>\n","    sample_data = pd.read_parquet(\"/kaggle/input/asl-fingerspelling/supplemental_landmarks/1032110484.parquet\")\n","  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/parquet.py\", line 501, in read_parquet\n","    )\n","  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/parquet.py\", line 52, in get_engine\n","ImportError: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\n","A suitable version of pyarrow or fastparquet is required for parquet support.\n","Trying to import the above resulted in these errors:\n"," - No module named 'pandas.core.arrays.arrow.extension_types'\n"," - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(\n","  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 978, in format_exception_as_a_whole\n","    frames.append(self.format_record(record))\n","  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 878, in format_record\n","    frame_info.lines, Colors, self.has_colors, lvals\n","  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 712, in lines\n","    return self._sd.lines\n","  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n","    value = obj.__dict__[self.func.__name__] = self.func(obj)\n","  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n","    pieces = self.included_pieces\n","  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n","    value = obj.__dict__[self.func.__name__] = self.func(obj)\n","  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n","    pos = scope_pieces.index(self.executing_piece)\n","  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n","    value = obj.__dict__[self.func.__name__] = self.func(obj)\n","  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n","    return only(\n","  File \"/opt/conda/lib/python3.10/site-packages/executing/executing.py\", line 190, in only\n","    raise NotOneValueFound('Expected one value, found 0')\n","executing.executing.NotOneValueFound: Expected one value, found 0\n"]}],"source":["sample_data = pd.read_parquet(\"/kaggle/input/asl-fingerspelling/supplemental_landmarks/1032110484.parquet\")\n","sample_data"]},{"cell_type":"markdown","id":"d1c50130","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["# 4 | Advisory\n","\n","This data has both `video` as an `input` and `language` as `output`. One lead (as of I think) is we can use R-CNN(Reccurent-Convolution Neural Network). Video data works great on these types of models. \n","\n","Also we need to reduce the training time as much as possible. As of the competition says. \n","\n","**THAT IT FOR TODAY GUYS**\n","\n","**WE WILL GO DEEPER INTO THE DATA IN THE UPCOMING VERSIONS**\n","\n","**PLEASE COMMENT YOUR THOUGHTS, HIHGLY APPRICIATED**\n","\n","**DONT FORGET TO MAKE AN UPVOTE, IF YOU LIKED MY WORK**\n","\n","<img src = \"https://i.imgflip.com/19aadg.jpg\">\n","\n","**PEACE OUT!!!**\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"papermill":{"default_parameters":{},"duration":56.546205,"end_time":"2023-05-11T15:26:29.198842","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-05-11T15:25:32.652637","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}
