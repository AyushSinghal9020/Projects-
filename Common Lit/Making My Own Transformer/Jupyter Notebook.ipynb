{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ayushs9020/making-my-own-transformer?scriptVersionId=138762831\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"a3f90755","metadata":{"papermill":{"duration":0.014202,"end_time":"2023-08-03T07:15:16.742083","exception":false,"start_time":"2023-08-03T07:15:16.727881","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#00B9F7; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #00B9F7\">Transformers</p>"]},{"cell_type":"code","execution_count":1,"id":"50555530","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-08-03T07:15:16.768545Z","iopub.status.busy":"2023-08-03T07:15:16.767749Z","iopub.status.idle":"2023-08-03T07:15:16.779233Z","shell.execute_reply":"2023-08-03T07:15:16.778069Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.027389,"end_time":"2023-08-03T07:15:16.781547","exception":false,"start_time":"2023-08-03T07:15:16.754158","status":"completed"},"tags":[]},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"66981452","metadata":{"papermill":{"duration":0.011571,"end_time":"2023-08-03T07:15:16.80513","exception":false,"start_time":"2023-08-03T07:15:16.793559","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00B9F7 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","<img src = 'https://media.tenor.com/LStfD5yI5SsAAAAC/transformers-darkofthemoon.gif'>\n","    \n","## So what the hell is this **`Transformers`** $...?$\n","    \n","Yes we have been asking this question from an whole eternity. When we search on $Google$/or any other search engine, we find the same answer\n","```\n","A transformer is a type of neural network architecture that is blah blah blah blah\n","```\n","But what it actually is and why do we even need this \n","    \n","<img src = 'https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png' width = 400>"]},{"cell_type":"markdown","id":"0e53c6ef","metadata":{"papermill":{"duration":0.011557,"end_time":"2023-08-03T07:15:16.828503","exception":false,"start_time":"2023-08-03T07:15:16.816946","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#8E24AA; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #8E24AA\">1 | Self Attention üëÄ</p>"]},{"cell_type":"code","execution_count":2,"id":"d06ac507","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:15:16.854246Z","iopub.status.busy":"2023-08-03T07:15:16.853785Z","iopub.status.idle":"2023-08-03T07:15:20.480762Z","shell.execute_reply":"2023-08-03T07:15:20.479426Z"},"papermill":{"duration":3.643106,"end_time":"2023-08-03T07:15:20.483544","exception":false,"start_time":"2023-08-03T07:15:16.840438","status":"completed"},"tags":[]},"outputs":[],"source":["import torch.nn as nn\n","import torch\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","id":"973dd57a","metadata":{"papermill":{"duration":0.011872,"end_time":"2023-08-03T07:15:20.507667","exception":false,"start_time":"2023-08-03T07:15:20.495795","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","<IMG SRC = 'https://media.tenor.com/AleRU5nZSasAAAAC/attention-notice-me.gif' WIDTH = 400>\n","    \n","Society says that the best way to understand `Transformer Architechture`, is to first understand `Self-Attention Mechanism`. \n","\n","I dont know who are the actual people in society, and why do these people do not show up individually, why they cover up themselves with the word `Society`\n","\n","**LEAVE IT !!!**\n","\n","Lets assume we have this sentence `Radhe Krishn`\n","\n","Lets assume we pass this to an `Embedding Layer` to get `Embeddings`. These `Embeddings` will be `Random`, but lets dive it in "]},{"cell_type":"code","execution_count":3,"id":"c266f1cb","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:15:20.534447Z","iopub.status.busy":"2023-08-03T07:15:20.533828Z","iopub.status.idle":"2023-08-03T07:15:20.57712Z","shell.execute_reply":"2023-08-03T07:15:20.576069Z"},"papermill":{"duration":0.05925,"end_time":"2023-08-03T07:15:20.579319","exception":false,"start_time":"2023-08-03T07:15:20.520069","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Embedding(2, 12)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["Embedding_Layer = nn.Embedding(2 , 12)\n","Embedding_Layer"]},{"cell_type":"markdown","id":"94da7d74","metadata":{"papermill":{"duration":0.011943,"end_time":"2023-08-03T07:15:20.603613","exception":false,"start_time":"2023-08-03T07:15:20.59167","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","As our corpus only consists of $2$ distinct words, we can label them as `[0,1]`\n","\n","Passing this to an Embedding Layer, "]},{"cell_type":"code","execution_count":4,"id":"d0ca636f","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:15:20.631313Z","iopub.status.busy":"2023-08-03T07:15:20.629946Z","iopub.status.idle":"2023-08-03T07:15:20.719431Z","shell.execute_reply":"2023-08-03T07:15:20.717935Z"},"papermill":{"duration":0.106483,"end_time":"2023-08-03T07:15:20.722323","exception":false,"start_time":"2023-08-03T07:15:20.61584","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(tensor([[-1.5767,  2.0108, -0.1173, -0.4099, -1.1066, -0.0295, -2.2496, -1.0099,\n","           1.3667, -1.1732,  1.2535,  0.8923],\n","         [-0.1703,  1.9785,  1.0846,  1.0113,  2.0160, -0.9814, -0.1768,  0.8472,\n","           1.0253,  0.1415, -0.7323, -1.4763]], grad_fn=<EmbeddingBackward0>),\n"," torch.Size([2, 12]))"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["inputs = Embedding_Layer(torch.tensor([0 , 1] , dtype = torch.long))\n","inputs , inputs.shape"]},{"cell_type":"markdown","id":"be860505","metadata":{"papermill":{"duration":0.012528,"end_time":"2023-08-03T07:15:20.748408","exception":false,"start_time":"2023-08-03T07:15:20.73588","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Suppose we could be able to know, how much these words affect each other "]},{"cell_type":"code","execution_count":5,"id":"bd49eb22","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-08-03T07:15:20.776045Z","iopub.status.busy":"2023-08-03T07:15:20.775475Z","iopub.status.idle":"2023-08-03T07:15:21.052151Z","shell.execute_reply":"2023-08-03T07:15:21.050703Z"},"papermill":{"duration":0.293718,"end_time":"2023-08-03T07:15:21.054765","exception":false,"start_time":"2023-08-03T07:15:20.761047","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f1f584c3b20>"]},"execution_count":5,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.imshow(inputs.detach().numpy())"]},{"cell_type":"markdown","id":"7e0434b0","metadata":{"papermill":{"duration":0.012425,"end_time":"2023-08-03T07:15:21.080144","exception":false,"start_time":"2023-08-03T07:15:21.067719","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","By human instincts we know that these $2$ words highle corresponds to each other\n","\n","But how can we make a machine understand this \n","\n","So how can we do this$...?$\n","\n","The whole concept, where `distinct words` of a `chunk of text` show some `focus`/`effect`/`attention` to `other words` is called `Self Attention`\n","\n","We do this by using $3$ $Major$ $Neural$ $Networks$. For making things more complicated we give them names\n","* $Query$ - What I am Looking for\n","* $Key$ - What I can offer\n","* $Value$ - What I actually offer(I was bluffing before)\n","\n","We will think of these as $3$ $Linear$ $Layers$\n","\n","We know that at the starting $Linear$ $Layers$ are just bunch of random numbers hanging out together like this\n","    \n","<img src = 'https://i.scdn.co/image/ab67616d0000b2732a517799858bf32fe736c2ca' width = 300>\n","\n","So lets just intialize some random $Linear$ $Layers$"]},{"cell_type":"markdown","id":"dfcc89c7","metadata":{"papermill":{"duration":0.01234,"end_time":"2023-08-03T07:15:21.105263","exception":false,"start_time":"2023-08-03T07:15:21.092923","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","As we have $2$ characters, so our `sequence_len == 2`/`vocab_size == 2`"]},{"cell_type":"code","execution_count":6,"id":"a586a394","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:15:21.133556Z","iopub.status.busy":"2023-08-03T07:15:21.132617Z","iopub.status.idle":"2023-08-03T07:15:21.141152Z","shell.execute_reply":"2023-08-03T07:15:21.139884Z"},"papermill":{"duration":0.025682,"end_time":"2023-08-03T07:15:21.143735","exception":false,"start_time":"2023-08-03T07:15:21.118053","status":"completed"},"tags":[]},"outputs":[],"source":["sequence_len , vocab_size = 2 , 2\n","embed_layer = nn.Embedding(sequence_len , vocab_size)\n","\n","inputs = embed_layer(torch.tensor([0 , 1]))"]},{"cell_type":"code","execution_count":7,"id":"fd85c022","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:15:21.171473Z","iopub.status.busy":"2023-08-03T07:15:21.170802Z","iopub.status.idle":"2023-08-03T07:15:21.181221Z","shell.execute_reply":"2023-08-03T07:15:21.179878Z"},"papermill":{"duration":0.027044,"end_time":"2023-08-03T07:15:21.183575","exception":false,"start_time":"2023-08-03T07:15:21.156531","status":"completed"},"tags":[]},"outputs":[],"source":["queries = torch.rand((sequence_len , vocab_size) , dtype = torch.float32)\n","keys = torch.rand((sequence_len , vocab_size) , dtype = torch.float32)\n","values = torch.rand((sequence_len , vocab_size) , dtype = torch.float32)"]},{"cell_type":"markdown","id":"f38dc412","metadata":{"papermill":{"duration":0.012816,"end_time":"2023-08-03T07:15:21.209371","exception":false,"start_time":"2023-08-03T07:15:21.196555","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","So what we do is we simply multiply `queries` and `keys`"]},{"cell_type":"code","execution_count":8,"id":"0e8c0c2d","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:15:21.238569Z","iopub.status.busy":"2023-08-03T07:15:21.237815Z","iopub.status.idle":"2023-08-03T07:15:21.247386Z","shell.execute_reply":"2023-08-03T07:15:21.246184Z"},"papermill":{"duration":0.02691,"end_time":"2023-08-03T07:15:21.250071","exception":false,"start_time":"2023-08-03T07:15:21.223161","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[0.4999, 0.7776],\n","        [0.1692, 0.0874]])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["queries * keys"]},{"cell_type":"markdown","id":"89eeb521","metadata":{"papermill":{"duration":0.013835,"end_time":"2023-08-03T07:15:21.277455","exception":false,"start_time":"2023-08-03T07:15:21.26362","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","So why we did this$...?$\n","\n","Think it like this. We have to complete the sentence `He became ___ Universe`. Now we need to fill in the blank. Lets assume we have the information of future tokens. A model when searches for information in the back-tokens, it needs `He` to be highlighted. That what `queries * keys` do. When the \n","* Queries - What you want\n","* Key - What I can offer\n","\n","When these $2$(Question and answer) meet they show `high iffinity`. Thats why we multiply both of them\n","\n","But how can we get the index with `highest iffinity` $...?$\n","\n","One way is to do a `Softmax` on all of these"]},{"cell_type":"code","execution_count":9,"id":"44ac9d9f","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:15:21.308589Z","iopub.status.busy":"2023-08-03T07:15:21.307815Z","iopub.status.idle":"2023-08-03T07:15:21.322479Z","shell.execute_reply":"2023-08-03T07:15:21.321125Z"},"papermill":{"duration":0.033711,"end_time":"2023-08-03T07:15:21.325252","exception":false,"start_time":"2023-08-03T07:15:21.291541","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[0.4310, 0.5690],\n","        [0.5204, 0.4796]])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["softmax = nn.Softmax()\n","\n","softmax(queries * keys)"]},{"cell_type":"markdown","id":"bd540cc4","metadata":{"papermill":{"duration":0.012769,"end_time":"2023-08-03T07:15:21.351424","exception":false,"start_time":"2023-08-03T07:15:21.338655","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","But these values are very huge and thus can make big variations in the model, thus we will divide them with something"]},{"cell_type":"code","execution_count":10,"id":"187ce444","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:15:21.380581Z","iopub.status.busy":"2023-08-03T07:15:21.379879Z","iopub.status.idle":"2023-08-03T07:15:21.385316Z","shell.execute_reply":"2023-08-03T07:15:21.384077Z"},"papermill":{"duration":0.022937,"end_time":"2023-08-03T07:15:21.387855","exception":false,"start_time":"2023-08-03T07:15:21.364918","status":"completed"},"tags":[]},"outputs":[],"source":["weights = softmax((queries * keys) / keys.shape[-1])"]},{"cell_type":"markdown","id":"ed724a34","metadata":{"papermill":{"duration":0.012621,"end_time":"2023-08-03T07:15:21.413622","exception":false,"start_time":"2023-08-03T07:15:21.401001","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now this is kind of good \n","\n","We then multiply this with our `values` to get outputs"]},{"cell_type":"code","execution_count":11,"id":"97e19cec","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:15:21.442333Z","iopub.status.busy":"2023-08-03T07:15:21.441945Z","iopub.status.idle":"2023-08-03T07:15:21.456116Z","shell.execute_reply":"2023-08-03T07:15:21.455146Z"},"papermill":{"duration":0.031228,"end_time":"2023-08-03T07:15:21.458265","exception":false,"start_time":"2023-08-03T07:15:21.427037","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[0.6661, 0.4862],\n","        [0.6552, 0.4610]])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["torch.matmul(weights , values)"]},{"cell_type":"markdown","id":"087984c5","metadata":{"papermill":{"duration":0.012562,"end_time":"2023-08-03T07:15:21.483947","exception":false,"start_time":"2023-08-03T07:15:21.471385","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","And these are our final output from `Self-Attention`."]},{"cell_type":"markdown","id":"37bc3f58","metadata":{"papermill":{"duration":0.012851,"end_time":"2023-08-03T07:15:21.510164","exception":false,"start_time":"2023-08-03T07:15:21.497313","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#F2C464; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #F2C464\">2 | Multi Head Attention üß†‚Äçüß†‚Äçüß†</p>\n","\n","<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","What we did is a implimaentation of `Single Head`. We use multiple heads to gather multiple information of the corpus\n","\n","So how do we handle `Multiple Heads`$...?$\n","\n","Assume we have the same sentence but this time we have increased our Output of Embedding Layer"]},{"cell_type":"code","execution_count":12,"id":"88cc5a89","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:15:21.539044Z","iopub.status.busy":"2023-08-03T07:15:21.53839Z","iopub.status.idle":"2023-08-03T07:15:21.548082Z","shell.execute_reply":"2023-08-03T07:15:21.546872Z"},"papermill":{"duration":0.027625,"end_time":"2023-08-03T07:15:21.551089","exception":false,"start_time":"2023-08-03T07:15:21.523464","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[-0.4091,  0.3547,  0.2561,  1.0563, -0.2104, -0.2062, -0.7631,  0.2990,\n","          0.6452, -1.3421],\n","        [-0.8412, -0.2357, -0.0982,  0.9053,  0.2191,  0.6934,  1.5271, -1.3503,\n","          0.2988,  0.1785]], grad_fn=<EmbeddingBackward0>)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["Embedding_Layer = nn.Embedding(2 , 10)\n","\n","inputs = Embedding_Layer(torch.tensor([0 , 1]))\n","inputs"]},{"cell_type":"markdown","id":"df69d42d","metadata":{"papermill":{"duration":0.013672,"end_time":"2023-08-03T07:15:21.578856","exception":false,"start_time":"2023-08-03T07:15:21.565184","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Lets assume we are making $5$ Heads. \n","\n","What we do is we break this matrix into $5$ parts and then seperately work on them. Lets assume the indices of our matrix is like\n","```\n","[(0 , 0) , (0 , 1) , (0 , 2) , (0 , 3) , (0 , 4) , (0 , 5) , (0 , 6) , (0 , 7) , (0 , 8) , (0 , 9) , \n","(1 , 0) , (1 , 1) , (1 , 2) , (1 , 3) , (1 , 4) , (1 , 5) , (1 , 6) , (1 , 7) , (1 . 8) , (1 , 9)]\n","```\n","By breaking it in $5$ parts \n","```\n","[(0 , 0) , (0 , 1) , \n","(1 , 0) , (1 , 1)]\n","\n","[(0 , 2) , (0 , 3) ,\n","(1 , 2) , (1 , 3)]\n","\n","[(0 , 4) , (0 , 5) ,\n","(1 , 4) , (1 , 5)]\n","\n","[(0 , 6) , (0 , 7) ,\n","(1 , 6) , (1 , 7)]\n","\n","[(0 , 8) , (0 , 9) , \n","(1 . 8) , (1 , 9)]\n","```\n","\n","So how do we do this$...?$\n","\n","One way is to make $5$ different `Linear Layers` and compute them, which can be expensive\n","\n","One way is somehow we can break this thing up, pass into Neural Networks and then re-concatenate them. This can be computationaly expensive "]},{"cell_type":"markdown","id":"c62cfda8","metadata":{"papermill":{"duration":0.014038,"end_time":"2023-08-03T07:15:21.606913","exception":false,"start_time":"2023-08-03T07:15:21.592875","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","First we will `reshape` this array"]},{"cell_type":"code","execution_count":13,"id":"6818b9ea","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:15:21.637144Z","iopub.status.busy":"2023-08-03T07:15:21.636729Z","iopub.status.idle":"2023-08-03T07:15:21.644851Z","shell.execute_reply":"2023-08-03T07:15:21.643939Z"},"papermill":{"duration":0.025851,"end_time":"2023-08-03T07:15:21.647228","exception":false,"start_time":"2023-08-03T07:15:21.621377","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[[[-0.4091,  0.3547],\n","          [ 0.2561,  1.0563],\n","          [-0.2104, -0.2062],\n","          [-0.7631,  0.2990],\n","          [ 0.6452, -1.3421]],\n","\n","         [[-0.8412, -0.2357],\n","          [-0.0982,  0.9053],\n","          [ 0.2191,  0.6934],\n","          [ 1.5271, -1.3503],\n","          [ 0.2988,  0.1785]]]], grad_fn=<ReshapeAliasBackward0>)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["inputs = torch.reshape(inputs, (1, 2 , 5 , 2))\n","inputs"]},{"cell_type":"markdown","id":"dd82469a","metadata":{"papermill":{"duration":0.013009,"end_time":"2023-08-03T07:15:21.673836","exception":false,"start_time":"2023-08-03T07:15:21.660827","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now we need to `permute` this "]},{"cell_type":"code","execution_count":14,"id":"3fe89051","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:15:21.703066Z","iopub.status.busy":"2023-08-03T07:15:21.702221Z","iopub.status.idle":"2023-08-03T07:15:21.710407Z","shell.execute_reply":"2023-08-03T07:15:21.70954Z"},"papermill":{"duration":0.025272,"end_time":"2023-08-03T07:15:21.712451","exception":false,"start_time":"2023-08-03T07:15:21.687179","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[[[-0.4091,  0.3547]],\n","\n","         [[-0.8412, -0.2357]]],\n","\n","\n","        [[[ 0.2561,  1.0563]],\n","\n","         [[-0.0982,  0.9053]]],\n","\n","\n","        [[[-0.2104, -0.2062]],\n","\n","         [[ 0.2191,  0.6934]]],\n","\n","\n","        [[[-0.7631,  0.2990]],\n","\n","         [[ 1.5271, -1.3503]]],\n","\n","\n","        [[[ 0.6452, -1.3421]],\n","\n","         [[ 0.2988,  0.1785]]]], grad_fn=<PermuteBackward0>)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["inputs = inputs.permute(2 , 1 , 0 , 3)\n","inputs"]},{"cell_type":"markdown","id":"bc735fb7","metadata":{"papermill":{"duration":0.013115,"end_time":"2023-08-03T07:15:21.739072","exception":false,"start_time":"2023-08-03T07:15:21.725957","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","And this is the same as we wanted"]},{"cell_type":"markdown","id":"4f5684f5","metadata":{"papermill":{"duration":0.014081,"end_time":"2023-08-03T07:15:21.766596","exception":false,"start_time":"2023-08-03T07:15:21.752515","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Lets now start connecting things up \n","\n","<img src = 'https://production-media.paperswithcode.com/methods/Screen_Shot_2020-07-08_at_12.17.05_AM_st5S0XV.png' width = 400>\n","\n","* We first intialize $3$ $Linear$ $Layers$ \n","* * $Query$ - What I am looking for\n","* * $Key$ - What I can offer\n","* * $Values$ - What I actually offer\n","* We pass the $Query$ and $Keys$ into a dot product\n","* We then calculate the softmax of the product\n","* Then we dot product with $Values$\n","* Then we concatenate \n","* (We have left the Linear Layers for this time)\n","\n","We do the same thing for a number of heads"]},{"cell_type":"markdown","id":"eb3cc047","metadata":{"papermill":{"duration":0.01295,"end_time":"2023-08-03T07:15:21.792921","exception":false,"start_time":"2023-08-03T07:15:21.779971","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#FF69B4; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #FF69B4\">3 | Mutli Head Self Attention Class üåé</p>\n","\n","<div style=\"border-radius:10px; border:#FF69B4 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","<IMG SRC = 'https://cleanmemes.files.wordpress.com/2014/10/35multiheaddog1.jpg?w=640' WIDTH = 400>\n","    \n","Now lets just make a simple class for this\n","    \n","A really great explanantion to the code by **[Hugging Chat](https://huggingface.co/chat/)**\n","\n","### __init__\n","```\n","def __init__(self , vocab_size , num_heads):\n","\n","    super(MultiHeadSelfAttention , self).__init__()\n","\n","    self.num_heads = num_heads\n","    self.vocab_size = vocab_size\n","\n","    self.queries = nn.Linear(self.vocab_size , self.vocab_size)\n","    self.keys = nn.Linear(self.vocab_size , self.vocab_size)\n","    self.values = nn.Linear(self.vocab_size , self.vocab_size)\n","\n","    self.softmax = torch.nn.Softmax()\n","```\n","\n","The `Constructor` takes two arguments\n","* $Vocablary$ $Size$ `vocab_size` - Size of the Vocablury\n","* $Number$ $of$ $Heads$ `num_heads`\n","\n","It `initializes` the `instance variables` `num_heads`/`vocab_size`, and $3$ $Linear$ $Layers$ - `queries`/`keys`/`values`. The linear layers have a `single hidden layer` with a `dimensionality` of `vocab_size`.\n","\n","### Split Heads\n","```\n","def split_heads(self , gate):\n","\n","#         batch_size = gate.shape[0]\n","\n","    split_gates = torch.reshape(gate, (1 , \n","                                    self.num_heads , \n","                                    int(self.vocab_size / self.num_heads) , \n","                                    self.num_heads)).permute(2 , 1 , 0 , 3)\n","\n","    return split_gates\n","```\n","\n","This method takes a `gate` `(a tensor of shape (batch_size, vocab_size))` and `splits` it into `multiple heads`, each with a `size` of `(batch_size, vocab_size // num_heads)`. It does this by `reshaping` the gate into a $4D$ `tensor`, `permuting the dimensions`, and then `splitting` it along the `second dimension`.\n","\n","### Forward\n","```\n","def forward(self , key , query , value , mask = None):\n","\n","    query_output = self.queries(query)\n","    key_output = self.keys(key)\n","    value_output = self.values(value)\n","\n","    query_output = self.split_heads(query_output)\n","    key_output = self.split_heads(key_output)\n","    value_output = self.split_heads(value_output)\n","\n","    attention = (query_output * key_output) / (key_output.shape[-1] ** (1/2)) \n","\n","    if mask : attention = tf.where(mask == 0 , float('-inf') , attention)\n","\n","    weights = self.softmax(attention)\n","    weights = torch.reshape(weights , (weights.shape[2] , int(self.vocab_size / self.num_heads) , \n","                                       self.num_heads , self.num_heads))\n","    value_output = torch.reshape(value_output , (value_output.shape[2] , int(self.vocab_size / self.num_heads) , \n","                                                 self.num_heads , self.num_heads))\n","    output = torch.matmul(weights , value_output)\n","\n","    output = torch.reshape(output , (self.num_heads , self.vocab_size))\n","\n","    return output , weights\n","```\n","\n","This `method` `computes` the `attention scores` and `outputs` the final output. It takes four arguments - `key`/`query`/`value`/`mask` (an optional binary mask indicating which elements should be ignored).\n","* `Pass` the `query`/`key`/`value` tensors through their `corresponding linear layers` to get the `query`/`key`/`value` `embeddings`.\n","* `Split` the `query`/`key` `embeddings` into `multiple heads` using the `split_heads method`.\n","* `Compute` the `attention` scores by taking the `dot product` of the `query`/`key` `embeddings` and `dividing` the result by the `square root` of the `key embedding's dimensionality`.\n","* If a `mask` is `provided`, `zero` out the `attention scores` for the `masked elements`.\n","* `Apply` a `Softmax function` to the `attention scores` to get the weights.\n","* `Compute` the `output` by taking the `weighted sum` of the `value embeddings` using the weights computed earlier.\n","* `Reshape` the `output tensor` to have the `original vocabulary size`."]},{"cell_type":"code","execution_count":15,"id":"dde04f24","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:15:21.822065Z","iopub.status.busy":"2023-08-03T07:15:21.821527Z","iopub.status.idle":"2023-08-03T07:15:21.837911Z","shell.execute_reply":"2023-08-03T07:15:21.836516Z"},"papermill":{"duration":0.034633,"end_time":"2023-08-03T07:15:21.840983","exception":false,"start_time":"2023-08-03T07:15:21.80635","status":"completed"},"tags":[]},"outputs":[],"source":["class MultiHeadSelfAttention(nn.Module):\n","    \n","    def __init__(self , vocab_size , num_heads):\n","        \n","        super(MultiHeadSelfAttention , self).__init__()\n","    \n","        self.num_heads = num_heads\n","        self.vocab_size = vocab_size\n","        \n","        self.queries = nn.Linear(self.vocab_size , self.vocab_size)\n","        self.keys = nn.Linear(self.vocab_size , self.vocab_size)\n","        self.values = nn.Linear(self.vocab_size , self.vocab_size)\n","        \n","        self.softmax = torch.nn.Softmax()\n","        \n","    def split_heads(self , gate):\n","        \n","#         batch_size = gate.shape[0]\n","        \n","        split_gates = torch.reshape(gate, (1 , # -----> batch_size \n","                                        self.num_heads , \n","                                        int(self.vocab_size / self.num_heads) , \n","                                        self.num_heads)).permute(2 , 1 , 0 , 3)\n","        \n","        return split_gates\n","    \n","    def forward(self , key , query , value , mask = None):\n","        \n","        query_output = self.queries(query)\n","        key_output = self.keys(key)\n","        value_output = self.values(value)\n","\n","        query_output = self.split_heads(query_output)\n","        key_output = self.split_heads(key_output)\n","        value_output = self.split_heads(value_output)\n","\n","        attention = (query_output * key_output) / (key_output.shape[-1] ** (1/2)) \n","        \n","        if mask : attention = tf.where(mask == 0 , float('-inf') , attention)\n","\n","        weights = self.softmax(attention)\n","        weights = torch.reshape(weights , (weights.shape[2] , int(self.vocab_size / self.num_heads) , \n","                                           self.num_heads , self.num_heads))\n","        value_output = torch.reshape(value_output , (value_output.shape[2] , int(self.vocab_size / self.num_heads) , \n","                                                     self.num_heads , self.num_heads))\n","        output = torch.matmul(weights , value_output)\n","        \n","        output = torch.reshape(output , (self.num_heads , self.vocab_size))\n","\n","        return output , weights"]},{"cell_type":"markdown","id":"845c6a79","metadata":{"execution":{"iopub.execute_input":"2023-08-02T15:01:59.721131Z","iopub.status.busy":"2023-08-02T15:01:59.720628Z","iopub.status.idle":"2023-08-02T15:01:59.73755Z","shell.execute_reply":"2023-08-02T15:01:59.736092Z","shell.execute_reply.started":"2023-08-02T15:01:59.721095Z"},"papermill":{"duration":0.014587,"end_time":"2023-08-03T07:15:21.87096","exception":false,"start_time":"2023-08-03T07:15:21.856373","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF69B4 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","If we pass a sample input like this "]},{"cell_type":"code","execution_count":16,"id":"06d6e55a","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:15:21.902884Z","iopub.status.busy":"2023-08-03T07:15:21.902419Z","iopub.status.idle":"2023-08-03T07:15:21.927717Z","shell.execute_reply":"2023-08-03T07:15:21.926594Z"},"papermill":{"duration":0.044319,"end_time":"2023-08-03T07:15:21.930455","exception":false,"start_time":"2023-08-03T07:15:21.886136","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(tensor([[-0.0023,  0.4321,  0.0053,  0.4289, -0.6862, -0.3971, -0.7582, -0.4371,\n","          -0.0396, -0.0595],\n","         [-0.0579, -0.0256,  0.4170, -0.0593,  0.4225, -0.0600, -0.4452,  0.5320,\n","          -0.4708,  0.5597]], grad_fn=<ReshapeAliasBackward0>),\n"," tensor([[[[0.5661, 0.4313],\n","           [0.4339, 0.5687]],\n"," \n","          [[0.4732, 0.4758],\n","           [0.5268, 0.5242]],\n"," \n","          [[0.5451, 0.5930],\n","           [0.4549, 0.4070]],\n"," \n","          [[0.4972, 0.4960],\n","           [0.5028, 0.5040]],\n"," \n","          [[0.5150, 0.4847],\n","           [0.4850, 0.5153]]]], grad_fn=<ReshapeAliasBackward0>))"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["mhsa = MultiHeadSelfAttention(vocab_size = 10 , num_heads = 2)\n","inputs = Embedding_Layer(torch.tensor([0 , 1]))\n","mhsa(inputs , inputs , inputs , None)"]},{"cell_type":"markdown","id":"76faa71a","metadata":{"papermill":{"duration":0.015036,"end_time":"2023-08-03T07:15:21.960953","exception":false,"start_time":"2023-08-03T07:15:21.945917","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF69B4 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","What we just made is the small part in this diagram\n","\n","$Multi$ $Head$ $Self$ $Attention$ (Orange Part )\n","\n","<img src = 'https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png' width = 300>"]},{"cell_type":"markdown","id":"f316f9c4","metadata":{"papermill":{"duration":0.014067,"end_time":"2023-08-03T07:15:21.989797","exception":false,"start_time":"2023-08-03T07:15:21.97573","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#FF0000; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #FF0000\">4 | Encoder Block ‚öôÔ∏è</p>\n","\n","<div style=\"border-radius:10px; border:#FF0000 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","### __init__\n","```\n","def __init__(self , vocab_size , num_heads):\n","\n","    super(Encoder , self).__init__()\n","\n","    self.vocab_size = vocab_size\n","    self.num_heads = num_heads\n","\n","    self.mhsa = MultiHeadSelfAttention(self.vocab_size , self.num_heads)\n","\n","    self.layer_norm_1 = nn.LayerNorm(self.vocab_size)\n","    self.layer_norm_2 = nn.LayerNorm(self.vocab_size)\n","\n","    self.dropout_1 = nn.Dropout(0.05)\n","    self.dropout_2 = nn.Dropout(0.05)\n","\n","    self.linear_1 = nn.Linear(self.vocab_size , self.vocab_size)\n","```\n","\n","The `constructor` function takes $2$ `arguments`\n","* $Vocabluray$ $Size$ `vocab_size` - size of the vocablury\n","* $Num$ $Heads$ `num_heads` - number of heads\n","\n","It then creates the following layers\n","* $Multi$ $Heads$ $Self$ $Attention$ `mhsa` layer with the `vocab_size` and `num_heads` parameters. \n","* $Layer$ $Normalization$ `layer_norm_1`/`layer_norm_2`  with the same dimension as the `vocab_size`. \n","* $Droput$ `dropout_1`/`dropout_2` with a `dropout rate` of $0.05$. \n","* $Linaer$ `linear_1` with an `input dimension` equal to the `vocab_size` and an `output dimension` also equal to the `vocab_size`\n","\n","### Forward \n","```\n","def forward(self , inps):\n","\n","    attention , weights = self.mhsa(inps , inps , inps , mask = None)\n","\n","    attention = self.dropout_1(attention)\n","    attention = self.layer_norm_1(inps + attention)\n","\n","    linear_attention = self.linear_1(attention)\n","\n","    linear_attention = self.layer_norm_2(linear_attention)\n","    attention = self.dropout_2(linear_attention + attention)\n","\n","    return attention , weights\n","```\n","The `forward function` takes an `input tensor inps` and passes it through the `MultiHeadSelfAttention layer`=>, $2$ `Layer Normalization layers` => $2$ `Dropout layers` => `Linear layer`"]},{"cell_type":"code","execution_count":17,"id":"4dd5b3bc","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:15:22.022829Z","iopub.status.busy":"2023-08-03T07:15:22.022109Z","iopub.status.idle":"2023-08-03T07:15:22.031904Z","shell.execute_reply":"2023-08-03T07:15:22.030738Z"},"papermill":{"duration":0.029489,"end_time":"2023-08-03T07:15:22.034715","exception":false,"start_time":"2023-08-03T07:15:22.005226","status":"completed"},"tags":[]},"outputs":[],"source":["class Encoder(nn.Module):\n","    \n","    def __init__(self , vocab_size , num_heads):\n","        \n","        super(Encoder , self).__init__()\n","        \n","        self.vocab_size = vocab_size\n","        self.num_heads = num_heads\n","        \n","        self.mhsa = MultiHeadSelfAttention(self.vocab_size , self.num_heads)\n","        \n","        self.layer_norm_1 = nn.LayerNorm(self.vocab_size)\n","        self.layer_norm_2 = nn.LayerNorm(self.vocab_size)\n","        \n","        self.dropout_1 = nn.Dropout(0.05)\n","        self.dropout_2 = nn.Dropout(0.05)\n","        \n","        self.linear_1 = nn.Linear(self.vocab_size , self.vocab_size)\n","        \n","    def forward(self , inps):\n","        \n","        attention , weights = self.mhsa(inps , inps , inps , mask = None)\n","\n","        attention = self.dropout_1(attention)\n","        attention = self.layer_norm_1(inps + attention)\n","        \n","        linear_attention = self.linear_1(attention)\n","        \n","        linear_attention = self.layer_norm_2(linear_attention)\n","        attention = self.dropout_2(linear_attention + attention)\n","        \n","        return attention , weights "]},{"cell_type":"code","execution_count":18,"id":"328de031","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:15:22.066488Z","iopub.status.busy":"2023-08-03T07:15:22.065596Z","iopub.status.idle":"2023-08-03T07:15:22.090278Z","shell.execute_reply":"2023-08-03T07:15:22.089374Z"},"papermill":{"duration":0.043463,"end_time":"2023-08-03T07:15:22.092875","exception":false,"start_time":"2023-08-03T07:15:22.049412","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(tensor([[-2.2792,  1.8172, -0.4408,  1.4964,  0.2584,  0.2562,  0.7465, -2.3416,\n","           0.6538, -0.1668],\n","         [-2.9043,  0.3458,  0.8130,  2.8128, -0.4729,  1.5066,  0.5939, -0.0000,\n","          -0.5055,  0.5786]], grad_fn=<MulBackward0>),\n"," tensor([[[[0.4568, 0.5105],\n","           [0.5432, 0.4895]],\n"," \n","          [[0.4536, 0.3958],\n","           [0.5464, 0.6042]],\n"," \n","          [[0.5445, 0.4760],\n","           [0.4555, 0.5240]],\n"," \n","          [[0.4899, 0.5471],\n","           [0.5101, 0.4529]],\n"," \n","          [[0.4944, 0.4879],\n","           [0.5056, 0.5121]]]], grad_fn=<ReshapeAliasBackward0>))"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["Enc = Encoder(vocab_size = 10 , num_heads = 2)\n","Enc(inputs)"]},{"cell_type":"markdown","id":"d9a177ec","metadata":{"papermill":{"duration":0.014344,"end_time":"2023-08-03T07:15:22.123008","exception":false,"start_time":"2023-08-03T07:15:22.108664","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF0000 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","What we just did was this \n","\n","<img src = 'https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/Transformer-neural-network-13.png' width = 400>"]},{"cell_type":"markdown","id":"28071902","metadata":{"papermill":{"duration":0.01435,"end_time":"2023-08-03T07:15:22.152162","exception":false,"start_time":"2023-08-03T07:15:22.137812","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#E77200; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #E77200\">5 | TO DO LIST üìë</p>\n","\n","<div style=\"border-radius:10px; border:#E77200 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","* $TO$ $DO$ $1$ $:$ $MAKE$ $ENCODER$ $BLOCK$\n","* $TO$ $DO$ $2$ $:$ $MAKE$ $DECODER$ $BLOCK$\n","* $TO$ $DO$ $3$ $:$ $MAKE$ $TRANSFORER$ $BLOCK$\n","* $TO$ $DO$ $4$ $:$ $TRAIN$ $TRANSFORER$\n","* $TO$ $DO$ $5$ $:$ $DANCE$"]},{"cell_type":"markdown","id":"efada065","metadata":{"papermill":{"duration":0.015479,"end_time":"2023-08-03T07:15:22.182416","exception":false,"start_time":"2023-08-03T07:15:22.166937","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#FF9980; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #FF9980\">6 | Ending üé≠</p>\n","\n","<div style=\"border-radius:10px; border:#FF9980 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","**THAT IT FOR TODAY GUYS**\n","\n","**WE WILL GO DEEPER INTO THE DATA IN THE UPCOMING VERSIONS**\n","\n","**PLEASE COMMENT YOUR THOUGHTS, HIHGLY APPRICIATED**\n","\n","**DONT FORGET TO MAKE AN UPVOTE, IF YOU LIKED MY WORK $:)$**\n","    \n","<img src = \"https://i.imgflip.com/19aadg.jpg\">\n","    \n","**PEACE OUT $!!!$**"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":18.169352,"end_time":"2023-08-03T07:15:23.624946","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-08-03T07:15:05.455594","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}
